{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5137200,"sourceType":"datasetVersion","datasetId":2984453}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip show tensorflow tensorflow-probability\n!pip install tensorflow-probability==0.24.0\n!pip install --upgrade keras-tuner\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n!pip install mne #The MNE Package is installed\nFILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n!unzip MI_EEG_ClassMeth.zip -y #Package with useful functions for motor imagery classification based in EEG.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n!dir","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-06-19T20:42:22.271201Z","iopub.execute_input":"2025-06-19T20:42:22.271864Z","iopub.status.idle":"2025-06-19T20:43:15.847394Z","shell.execute_reply.started":"2025-06-19T20:42:22.271837Z","shell.execute_reply":"2025-06-19T20:43:15.846639Z"}},"outputs":[{"name":"stdout","text":"Name: tensorflow\nVersion: 2.18.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\nRequired-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n---\nName: tensorflow-probability\nVersion: 0.25.0\nSummary: Probabilistic modeling and statistical inference in TensorFlow\nHome-page: http://github.com/tensorflow/probability\nAuthor: Google LLC\nAuthor-email: no-reply@google.com\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: absl-py, cloudpickle, decorator, dm-tree, gast, numpy, six\nRequired-by: dopamine_rl\nCollecting tensorflow-probability==0.24.0\n  Downloading tensorflow_probability-0.24.0-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.4.0)\nRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.17.0)\nRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.26.4)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (4.4.2)\nRequirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (3.1.1)\nRequirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (0.6.0)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (0.1.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2.4.1)\nRequirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.24.0) (25.3.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.24.0) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nDownloading tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow-probability\n  Attempting uninstall: tensorflow-probability\n    Found existing installation: tensorflow-probability 0.25.0\n    Uninstalling tensorflow-probability-0.25.0:\n      Successfully uninstalled tensorflow-probability-0.25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-probability-0.24.0\nRequirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\nRequirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\nRequirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras->keras-tuner) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras->keras-tuner) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras->keras-tuner) (2024.2.0)\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.databases\n  Cloning https://github.com/UN-GCPDS/python-gcpds.databases to /tmp/pip-req-build-5jg6t9m2\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.databases /tmp/pip-req-build-5jg6t9m2\n  Resolved https://github.com/UN-GCPDS/python-gcpds.databases to commit d174df9958b6638156dcfe03996a6307e631a6a2\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.15.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (3.7.2)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.9.0)\nRequirement already satisfied: tables in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (3.10.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (4.67.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (2.2.3)\nRequirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (2.32.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2.4.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (0.4)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (1.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gcpds-databases==0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gcpds-databases==0.2) (2025.2)\nRequirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (2.10.2)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (9.0.0)\nRequirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (3.2.1)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (4.13.2)\nRequirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.9.2)\nRequirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.1.0)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (4.3.8)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->gcpds-databases==0.2) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->gcpds-databases==0.2) (2.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne->gcpds-databases==0.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-databases==0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-databases==0.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->gcpds-databases==0.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->gcpds-databases==0.2) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2025.4.26)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->gcpds-databases==0.2) (2024.2.0)\nBuilding wheels for collected packages: gcpds-databases\n  Building wheel for gcpds-databases (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gcpds-databases: filename=gcpds_databases-0.2-py3-none-any.whl size=32972809 sha256=98cf7cf14f22ab4e2c995b01cb81abec0d79bdec758e109f5451858c00e901f3\n  Stored in directory: /tmp/pip-ephem-wheel-cache-x5q9vwya/wheels/ae/48/8d/edf617d5fe8f03b17aa26306a04abdfcc605b218d8e6deac83\nSuccessfully built gcpds-databases\nInstalling collected packages: gcpds-databases\nSuccessfully installed gcpds-databases-0.2\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n  Cloning https://github.com/UN-GCPDS/python-gcpds.visualizations.git to /tmp/pip-req-build-g6ap6k01\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.visualizations.git /tmp/pip-req-build-g6ap6k01\n  Resolved https://github.com/UN-GCPDS/python-gcpds.visualizations.git to commit 162dbeac141a7472d3b0bd7f005932241b4663a5\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting python-circos (from gcpds-visualizations==0.6)\n  Downloading python_circos-0.3.0-py3-none-any.whl.metadata (766 bytes)\nRequirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (1.26.4)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (1.9.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2.4.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (0.4)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (4.67.1)\nCollecting biopython>=1.78 (from python-circos->gcpds-visualizations==0.6)\n  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (2.32.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne->gcpds-visualizations==0.6) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-visualizations==0.6) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->gcpds-visualizations==0.6) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (2025.4.26)\nDownloading python_circos-0.3.0-py3-none-any.whl (27 kB)\nDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: gcpds-visualizations\n  Building wheel for gcpds-visualizations (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gcpds-visualizations: filename=gcpds_visualizations-0.6-py3-none-any.whl size=12440 sha256=b9a363fe03b59261ee01ae9375eb1d936e61a35bc727379d1f55b893f691618c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-jba50l4f/wheels/12/e9/11/f7246de13d1d668c154d68fb1260be82dbfbc166301807d756\nSuccessfully built gcpds-visualizations\nInstalling collected packages: biopython, python-circos, gcpds-visualizations\nSuccessfully installed biopython-1.85 gcpds-visualizations-0.6 python-circos-0.3.0\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\nRequirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.7.2)\nRequirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (25.0)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->mne) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.23->mne) (2024.2.0)\n--2025-06-19 20:43:03--  https://docs.google.com/uc?export=download&confirm=&id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\nResolving docs.google.com (docs.google.com)... 108.177.121.139, 108.177.121.101, 108.177.121.102, ...\nConnecting to docs.google.com (docs.google.com)|108.177.121.139|:443... connected.\nHTTP request sent, awaiting response... 303 See Other\nLocation: https://drive.usercontent.google.com/download?id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7&export=download [following]\n--2025-06-19 20:43:03--  https://drive.usercontent.google.com/download?id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7&export=download\nResolving drive.usercontent.google.com (drive.usercontent.google.com)... 172.217.214.132, 2607:f8b0:4001:c05::84\nConnecting to drive.usercontent.google.com (drive.usercontent.google.com)|172.217.214.132|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 86900 (85K) [application/octet-stream]\nSaving to: ‘MI_EEG_ClassMeth.zip’\n\nMI_EEG_ClassMeth.zi 100%[===================>]  84.86K  --.-KB/s    in 0.001s  \n\n2025-06-19 20:43:04 (65.0 MB/s) - ‘MI_EEG_ClassMeth.zip’ saved [86900/86900]\n\nArchive:  MI_EEG_ClassMeth.zip\ncaution: filename not matched:  -y\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n  Cloning https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to /tmp/pip-req-build-luudjfoh\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git /tmp/pip-req-build-luudjfoh\n  Resolved https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to commit 0c791f236d503dac4829adb78cdba759c5843417\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting braindecode==0.7 (from EEG_Tensorflow_models==0.2)\n  Downloading Braindecode-0.7-py3-none-any.whl.metadata (6.8 kB)\nCollecting moabb (from EEG_Tensorflow_models==0.2)\n  Downloading moabb-1.2.0-py3-none-any.whl.metadata (14 kB)\nCollecting tensorflow-addons (from EEG_Tensorflow_models==0.2)\n  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: tensorflow>=2.8 in /usr/local/lib/python3.11/dist-packages (from EEG_Tensorflow_models==0.2) (2.18.0)\nCollecting tf-keras-vis (from EEG_Tensorflow_models==0.2)\n  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.15.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.7.2)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.13.0)\nCollecting skorch (from braindecode==0.7->EEG_Tensorflow_models==0.2)\n  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.8.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.37.1)\nRequirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (6.0.2)\nRequirement already satisfied: coverage<8.0.0,>=7.0.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (7.8.0)\nCollecting edfio<0.5.0,>=0.4.2 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading edfio-0.4.9-py3-none-any.whl.metadata (3.9 kB)\nCollecting edflib-python<2.0.0,>=1.0.6 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\nCollecting memory-profiler<0.62.0,>=0.61.0 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\nCollecting mne-bids>=0.14 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading mne_bids-0.16.0-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (1.8.2)\nCollecting pyriemann<0.8,>=0.7 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading pyriemann-0.7-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: scikit-learn<1.6 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (1.2.2)\nRequirement already satisfied: seaborn<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (0.12.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (4.67.1)\nCollecting urllib3<2.0.0,>=1.26.15 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->EEG_Tensorflow_models==0.2)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (11.1.0)\nRequirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (1.2.18)\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (2.37.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.14.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.9.0.post0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory-profiler<0.62.0,>=0.61.0->moabb->EEG_Tensorflow_models==0.2) (7.0.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.2)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch<2.0.0,>=1.6.0->moabb->EEG_Tensorflow_models==0.2) (4.3.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pyriemann<0.8,>=0.7->moabb->EEG_Tensorflow_models==0.2) (1.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2025.4.26)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6->moabb->EEG_Tensorflow_models==0.2) (3.6.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.1.3)\nRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.9.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.1.2)\nDownloading Braindecode-0.7-py3-none-any.whl (184 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading moabb-1.2.0-py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading edfio-0.4.9-py3-none-any.whl (27 kB)\nDownloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\nDownloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\nDownloading mne_bids-0.16.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyriemann-0.7-py2.py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading skorch-1.1.0-py3-none-any.whl (228 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: EEG_Tensorflow_models\n  Building wheel for EEG_Tensorflow_models (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for EEG_Tensorflow_models: filename=EEG_Tensorflow_models-0.2-py3-none-any.whl size=29287 sha256=991124a8e862b66fca9c13189cc5f44743276fcdad603bce1d53c95f6c81b73f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-nl93v91u/wheels/ec/2b/bd/488f6c2631523174d34618ee5e61f72194b1389c81838cfd71\nSuccessfully built EEG_Tensorflow_models\nInstalling collected packages: urllib3, typeguard, memory-profiler, tensorflow-addons, skorch, pyriemann, mne-bids, edflib-python, edfio, tf-keras-vis, moabb, braindecode, EEG_Tensorflow_models\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.4.0\n    Uninstalling urllib3-2.4.0:\n      Successfully uninstalled urllib3-2.4.0\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.4.2\n    Uninstalling typeguard-4.4.2:\n      Successfully uninstalled typeguard-4.4.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ninflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed EEG_Tensorflow_models-0.2 braindecode-0.7 edfio-0.4.9 edflib-python-1.0.8 memory-profiler-0.61.0 mne-bids-0.16.0 moabb-1.2.0 pyriemann-0.7 skorch-1.1.0 tensorflow-addons-0.23.0 tf-keras-vis-0.8.7 typeguard-2.13.3 urllib3-1.26.20\nMI_EEG_ClassMeth.zip\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport os\nimport itertools\nimport random\nimport pickle\nimport mne\nimport h5py\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport matplotlib.pyplot as plt\nimport keras_tuner as kt\n\n\nfrom gcpds.databases.BCI_Competition_IV import Dataset_2a\nfrom typing import Sequence, Tuple\nfrom scipy.signal import iirnotch, filtfilt, butter, freqz\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\nimport networkx as nx\nfrom tqdm import tqdm\nfrom mne.preprocessing import compute_current_source_density\nfrom mne.channels import make_standard_montage, read_custom_montage\nfrom scipy.signal import butter, filtfilt, resample, iirnotch\nfrom gcpds.visualizations.series import plot_eeg\nfrom scipy.stats import norm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score\nfrom tqdm import tqdm\n\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom gcpds.databases import GIGA_MI_ME\nfrom sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom tensorflow.keras.utils import register_keras_serializable\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import LeavePGroupsOut, StratifiedGroupKFold\nfrom tensorflow.keras.models import Model\nfrom scipy.spatial.distance import cdist\nfrom sklearn.model_selection import GroupKFold\nfrom tensorflow.keras.models import load_model\n\nfrom keras_tuner import Objective\nfrom keras_tuner import HyperModel\nfrom keras.layers import Layer, Activation\nfrom keras_tuner import BayesianOptimization\nfrom keras_tuner.engine.hyperparameters import HyperParameters\nfrom tensorflow.keras.metrics import BinaryAccuracy, Recall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T20:43:52.868945Z","iopub.execute_input":"2025-06-19T20:43:52.869949Z","iopub.status.idle":"2025-06-19T20:43:52.877531Z","shell.execute_reply.started":"2025-06-19T20:43:52.869921Z","shell.execute_reply":"2025-06-19T20:43:52.876886Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_BCICIV2a(db, sbj: int, mode: str, fs: float) -> tuple:\n    \"\"\"\n    Carga los datos EEG para un sujeto específico con preprocesamiento, incluyendo filtrado y laplaciano superficial.\n    Se recorta el tiempo entre los segundos 2 y 4.\n    \n    Args:\n        db (Dataset_2a): Objeto del dataset.\n        sbj (int): Identificador del sujeto (1-9).\n        mode (str): 'training' o 'testing'.\n        fs (float): Frecuencia de muestreo.\n\n    Returns:\n        tuple: Datos EEG preprocesados con laplaciano superficial y recortados en el tiempo (X), etiquetas (y).\n    \"\"\"\n    # Cargar los datos del sujeto\n    db.load_subject(sbj, mode=mode)\n    X, y = db.get_data()  # Datos y etiquetas\n    X = X[:, :-3, :]  # Seleccionar solo los canales EEG (22 canales)\n    X = X * 1e6  # Convertir a microvoltios\n\n    # Aplicar filtro Notch (50 Hz)\n    notch_freq = 50.0\n    q_factor = 30.0\n    b_notch, a_notch = iirnotch(w0=notch_freq, Q=q_factor, fs=fs)\n    X = filtfilt(b_notch, a_notch, X, axis=2)\n\n    # Aplicar filtro pasa banda (0.5 - 100 Hz)\n    lowcut = 0.5\n    highcut = 100.0\n    b_band, a_band = butter(N=4, Wn=[lowcut, highcut], btype='bandpass', fs=fs)\n    X = filtfilt(b_band, a_band, X, axis=2)\n\n    # Recortar los datos entre el segundo 2 y el segundo 4\n    start_sample = int(2 * fs)  # Inicio en el segundo 2\n    end_sample = int(4 * fs)    # Fin en el segundo 4\n    X = X[:, :, start_sample:end_sample]\n\n    # Lista de nombres de los 22 canales EEG (sin EOG)\n    eeg_channel_names = [\n        'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4',\n        'C6', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'P1', 'Pz', 'P2', 'POz'\n    ]\n\n    # Crear información para los canales EEG\n    info = mne.create_info(\n        ch_names=eeg_channel_names,\n        sfreq=fs,  # Usar la frecuencia original\n        ch_types=[\"eeg\"] * len(eeg_channel_names)  # Todos los canales son EEG\n    )\n\n    # Cargar un montaje estándar basado en el sistema 10/20\n    montage = mne.channels.make_standard_montage('standard_1020')\n    info.set_montage(montage)\n\n    # Aplicar el cálculo del laplaciano superficial \n    laplacian_X = []\n    for trial in X:\n        # Crear un objeto RawArray para cada prueba\n        raw = mne.io.RawArray(trial, info)\n        # Calcular el laplaciano superficial\n        raw = mne.preprocessing.compute_current_source_density(raw)\n        # Obtener los datos con el laplaciano aplicado\n        laplacian_X.append(raw.get_data())\n\n    # Reconvertir a un array numpy con la misma forma original\n    X = np.stack(laplacian_X)\n\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T20:44:00.566724Z","iopub.execute_input":"2025-06-19T20:44:00.567015Z","iopub.status.idle":"2025-06-19T20:44:00.575701Z","shell.execute_reply.started":"2025-06-19T20:44:00.566993Z","shell.execute_reply":"2025-06-19T20:44:00.574940Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def load_BCICIV2a(db, sbj: int, mode: str, fs: float) -> tuple:\n    \"\"\"\n    Carga los datos EEG para un sujeto específico con preprocesamiento, incluyendo filtrado y laplaciano superficial.\n    Se recorta el tiempo entre los segundos 2 y 4 y solo se incluyen las clases 'mano izquierda' (1) y 'mano derecha' (2).\n    \n    Args:\n        db (Dataset_2a): Objeto del dataset.\n        sbj (int): Identificador del sujeto (1-9).\n        mode (str): 'training' o 'testing'.\n        fs (float): Frecuencia de muestreo.\n\n    Returns:\n        tuple: Datos EEG preprocesados con laplaciano superficial y recortados en el tiempo (X), etiquetas (y).\n    \"\"\"\n    # Cargar los datos del sujeto\n    db.load_subject(sbj, mode=mode)\n    X, y = db.get_data()  # Datos y etiquetas\n    X = X[:, :-3, :]  # Seleccionar solo los canales EEG (22 canales)\n    X = X * 1e6  # Convertir a microvoltios\n\n    # Aplicar filtro Notch (50 Hz)\n    notch_freq = 50.0\n    q_factor = 30.0\n    b_notch, a_notch = iirnotch(w0=notch_freq, Q=q_factor, fs=fs)\n    X = filtfilt(b_notch, a_notch, X, axis=2)\n\n    # Aplicar filtro pasa banda (0.5 - 100 Hz)\n    lowcut = 0.5\n    highcut = 100.0\n    b_band, a_band = butter(N=4, Wn=[lowcut, highcut], btype='bandpass', fs=fs)\n    X = filtfilt(b_band, a_band, X, axis=2)\n\n    # Recortar los datos entre el segundo 2 y el segundo 4\n    start_sample = int(2 * fs)  # Inicio en el segundo 2\n    end_sample = int(4 * fs)    # Fin en el segundo 4\n    X = X[:, :, start_sample:end_sample]\n\n    # Filtrar solo las clases de interés (1: mano izquierda, 2: mano derecha)\n    clases = [0, 1]\n    mask = np.isin(y, clases)\n    X = X[mask]\n    y = y[mask]\n\n    # Lista de nombres de los 22 canales EEG (sin EOG)\n    eeg_channel_names = [\n        'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4',\n        'C6', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'P1', 'Pz', 'P2', 'POz'\n    ]\n\n    # Crear información para los canales EEG\n    info = mne.create_info(\n        ch_names=eeg_channel_names,\n        sfreq=fs,  # Usar la frecuencia original\n        ch_types=[\"eeg\"] * len(eeg_channel_names)  # Todos los canales son EEG\n    )\n\n    # Cargar un montaje estándar basado en el sistema 10/20\n    montage = mne.channels.make_standard_montage('standard_1020')\n    info.set_montage(montage)\n\n    # Aplicar el cálculo del laplaciano superficial \n    laplacian_X = []\n    for trial in X:\n        # Crear un objeto RawArray para cada prueba\n        raw = mne.io.RawArray(trial, info)\n        # Calcular el laplaciano superficial\n        raw = mne.preprocessing.compute_current_source_density(raw)\n        # Obtener los datos con el laplaciano aplicado\n        laplacian_X.append(raw.get_data())\n\n    # Reconvertir a un array numpy con la misma forma original\n    X = np.stack(laplacian_X)\n\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T20:44:04.922775Z","iopub.execute_input":"2025-06-19T20:44:04.923348Z","iopub.status.idle":"2025-06-19T20:44:04.932262Z","shell.execute_reply.started":"2025-06-19T20:44:04.923321Z","shell.execute_reply":"2025-06-19T20:44:04.931283Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"@register_keras_serializable(package=\"CustomLayers\")\nclass TakensConv1D(tf.keras.layers.Layer):\n    def __init__(self, dx=5, dy=5, tau=1, mu=4, **kwargs):\n        super().__init__(**kwargs)\n        self.dx = int(dx)\n        self.dy = int(dy)\n        self.tau = int(tau)\n        self.mu = int(mu)\n        self.num_filters = self.dx + self.dy + 1\n\n    def build(self, input_shape):\n        kernel_size = self.mu + (self.dx - 1) * self.tau + 1\n        kernel_shape = (kernel_size, 1, self.num_filters)\n        kernel = tf.zeros(kernel_shape, dtype=tf.float32)\n\n        offsets_x = self.mu + tf.range(self.dx) * self.tau\n        offsets_y = tf.range(1, self.dy + 1) * self.tau\n        offset_y_t = tf.constant([0], dtype=tf.int32)\n\n        filas_x = tf.range(self.dx)\n        filas_y = self.dx + tf.range(self.dy)\n        fila_y_t = tf.constant([self.dx + self.dy])\n\n        cols_x = filas_x\n        cols_y = filas_y\n        col_y_t = fila_y_t\n\n        idx_x = tf.stack([filas_x, offsets_x, cols_x], axis=1)\n        idx_y = tf.stack([filas_y, offsets_y, cols_y], axis=1)\n        idx_yt = tf.stack([fila_y_t, offset_y_t, col_y_t], axis=1)\n\n        indices_total = tf.concat([idx_x, idx_y, idx_yt], axis=0)\n        updates = tf.ones([tf.shape(indices_total)[0]], dtype=tf.float32)\n\n        sort_order = tf.argsort(indices_total[:, 0])\n        indices_sorted = tf.gather(indices_total, sort_order)\n\n        row_for_scatter = tf.cast(indices_sorted[:, 1], tf.int32)\n        col_for_scatter = tf.cast(indices_sorted[:, 2], tf.int32)\n\n        final_indices = tf.stack([row_for_scatter,\n                                  tf.zeros_like(row_for_scatter),\n                                  col_for_scatter], axis=1)\n\n        kernel = tf.scatter_nd(final_indices, updates, kernel_shape)\n        self.kernel = kernel.numpy()[::-1]\n\n        self.conv1d = tf.keras.layers.Conv1D(\n            filters=self.num_filters,\n            kernel_size=kernel_size,\n            strides=self.tau,\n            padding=\"valid\",\n            use_bias=False\n        )\n        self.conv1d.build((None, input_shape[2], 1))\n        self.conv1d.set_weights([self.kernel])\n        self.conv1d.trainable=False\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        channels = tf.shape(inputs)[1]\n        time_steps = tf.shape(inputs)[2]\n\n        reshaped = tf.reshape(inputs, (-1, time_steps, 1))\n        conv_output = self.conv1d(reshaped)\n        new_time = tf.shape(conv_output)[1]\n\n        output = tf.reshape(conv_output, \n                            (batch_size, channels, new_time, self.num_filters))\n\n        x_sub_t_minus_mu = output[..., :self.dx]\n        y_sub_t_minus_1 = output[..., self.dx:self.dx + self.dy]\n        y_sub_t = output[..., -1:]\n\n        return x_sub_t_minus_mu, y_sub_t_minus_1, y_sub_t\n       \n\n@register_keras_serializable(package=\"CustomLayers\")\nclass KernelLayer(tf.keras.layers.Layer):\n    def __init__(self, \n                 amplitude=1.0,\n                 trainable_amplitude=False, \n                 length_scale=1.0,\n                 trainable_length_scale=False,\n                 alpha=1.0,  # Solo usado para Rational Quadratic\n                 trainable_alpha=False,\n                 kernel_type=\"gaussian\",  # \"gaussian\" o \"rational_quadratic\"\n                 **kwargs):\n        super(KernelLayer, self).__init__(**kwargs)\n\n        self.init_amplitude = amplitude\n        self.trainable_amplitude = trainable_amplitude\n        self.init_length_scale = length_scale\n        self.trainable_length_scale = trainable_length_scale\n        self.init_alpha = alpha\n        self.trainable_alpha = trainable_alpha\n        self.kernel_type = kernel_type.lower()\n\n    def build(self, input_shape):\n        self.amplitude = self.add_weight(\n            name=\"amplitude\",\n            shape=(),\n            initializer=tf.constant_initializer(self.init_amplitude),\n            trainable=self.trainable_amplitude,\n            dtype=self.dtype\n        )\n\n        self.length_scale = self.add_weight(\n            name=\"length_scale\",\n            shape=(),\n            initializer=tf.constant_initializer(self.init_length_scale),\n            trainable=self.trainable_length_scale,\n            dtype=self.dtype\n        )\n\n        if self.kernel_type == \"rational_quadratic\":\n            self.alpha = self.add_weight(\n                name=\"alpha\",\n                shape=(),\n                initializer=tf.constant_initializer(self.init_alpha),\n                trainable=self.trainable_alpha,\n                dtype=self.dtype\n            )\n\n        super(KernelLayer, self).build(input_shape)\n\n    def call(self, X):\n        if self.kernel_type == \"gaussian\":\n            kernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n                amplitude=self.amplitude,\n                length_scale=self.length_scale\n            )\n        elif self.kernel_type == \"rational_quadratic\":\n            kernel = tfp.math.psd_kernels.RationalQuadratic(\n                amplitude=self.amplitude,\n                length_scale=self.length_scale,\n                scale_mixture_rate=self.alpha\n            )\n        else:\n            raise ValueError(f\"Unsupported kernel_type: {self.kernel_type}\")\n        \n        return kernel.matrix(X, X)\n       \n@register_keras_serializable(package=\"CustomLayers\")\nclass TransferEntropyLayer(tf.keras.layers.Layer):\n    def __init__(self, alpha=2, **kwargs):\n\n        super().__init__(**kwargs)\n        self.alpha = int(alpha)\n\n    def compute_entropy(self, K_hadamard):\n        \n        trace_hadamard = tf.reduce_sum(tf.linalg.diag_part(K_hadamard), axis=-1) \n        trace_hadamard = tf.expand_dims(tf.expand_dims(trace_hadamard, axis=-1), axis=-1)\n        K_normalized = K_hadamard / trace_hadamard\n\n        K_power = tf.linalg.matmul( K_normalized , K_normalized, grad_a=True, grad_b=True ) \n        trace_power = tf.reduce_sum(tf.linalg.diag_part(K_power), axis=-1)  \n        H_alpha = (1 / (1 - self.alpha)) * tf.math.log(trace_power)\n        return H_alpha\n\n    def call(self, K_x, K_y_minus_1, K_y):\n        \n        K_x_exp = tf.expand_dims(K_x, axis=2)\n        \n        K_y_minus_1_exp = tf.expand_dims(K_y_minus_1, axis=1)\n        K_y_exp = tf.expand_dims(K_y, axis=1)\n\n        \n        H_1 = self.compute_entropy(K_y_minus_1_exp * K_x_exp)\n        H_2 = self.compute_entropy(K_y_exp * K_y_minus_1_exp * K_x_exp)\n        H_3 = self.compute_entropy(K_y_exp * K_y_minus_1_exp)\n        H_4 = self.compute_entropy(K_y_minus_1_exp)\n\n        TE = H_1 - H_2 + H_3 - H_4\n        \n        return TE\n        \n@register_keras_serializable(package=\"CustomLayers\")      \nclass RemoveDiagonalFlatten(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n    \n        super().__init__(**kwargs)\n\n    def call(self, inputs):\n        \n        shape_dyn = tf.shape(inputs)  \n        batch_size = shape_dyn[0]\n        c = tf.shape(inputs)[1]\n\n        \n        tf.debugging.assert_equal(\n            tf.shape(inputs)[1], tf.shape(inputs)[2],\n            message=\"RemoveDiagonalFlatten: la matriz de entrada no es cuadrada.\"\n        )  \n        diag_mask = tf.eye(c, dtype=inputs.dtype)  \n        inputs_no_diag = inputs * (1 - diag_mask) \n        flattened = tf.reshape(inputs_no_diag, [batch_size, -1])  \n        non_diag = tf.boolean_mask(flattened, tf.reshape(1 - diag_mask, [-1]), axis=1)\n        num_features = c * (c - 1)  \n        result = tf.reshape(non_diag, [batch_size, num_features])  \n\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T20:44:12.625302Z","iopub.execute_input":"2025-06-19T20:44:12.625797Z","iopub.status.idle":"2025-06-19T20:44:12.647986Z","shell.execute_reply.started":"2025-06-19T20:44:12.625774Z","shell.execute_reply":"2025-06-19T20:44:12.647395Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from tensorflow.keras.metrics import Metric\n@register_keras_serializable(package=\"CustomMetrics\")\nclass Sensitivity(Metric):\n    def __init__(self, name='sensitivity', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = tf.keras.metrics.TruePositives()\n        self.fn = tf.keras.metrics.FalseNegatives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tp.update_state(y_true, y_pred, sample_weight)\n        self.fn.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        return self.tp.result() / (self.tp.result() + self.fn.result() + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.reset_states()\n        self.fn.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config\n\n\n@register_keras_serializable(package=\"CustomMetrics\")\nclass Accuracy(Metric):\n    def __init__(self, name='accuracy', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = tf.keras.metrics.TruePositives()\n        self.tn = tf.keras.metrics.TrueNegatives()\n        self.fp = tf.keras.metrics.FalsePositives()\n        self.fn = tf.keras.metrics.FalseNegatives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tp.update_state(y_true, y_pred, sample_weight)\n        self.tn.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n        self.fn.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        num = self.tp.result() + self.tn.result()\n        den = num + self.fp.result() + self.fn.result() + tf.keras.backend.epsilon()\n        return num / den\n\n    def reset_states(self):\n        self.tp.reset_states()\n        self.tn.reset_states()\n        self.fp.reset_states()\n        self.fn.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config\n\n\n@register_keras_serializable(package=\"CustomMetrics\")\nclass F1Score(Metric):\n    def __init__(self, name='f1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = tf.keras.metrics.TruePositives()\n        self.fp = tf.keras.metrics.FalsePositives()\n        self.fn = tf.keras.metrics.FalseNegatives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tp.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n        self.fn.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        precision = self.tp.result() / (self.tp.result() + self.fp.result() + tf.keras.backend.epsilon())\n        recall = self.tp.result() / (self.tp.result() + self.fn.result() + tf.keras.backend.epsilon())\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.reset_states()\n        self.fp.reset_states()\n        self.fn.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config\n\n\n@register_keras_serializable(package=\"CustomMetrics\")\nclass Specificity(Metric):\n    def __init__(self, name='specificity', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tn = tf.keras.metrics.TrueNegatives()\n        self.fp = tf.keras.metrics.FalsePositives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tn.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        return self.tn.result() / (self.tn.result() + self.fp.result() + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tn.reset_states()\n        self.fp.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T20:44:18.073867Z","iopub.execute_input":"2025-06-19T20:44:18.074408Z","iopub.status.idle":"2025-06-19T20:44:18.088772Z","shell.execute_reply.started":"2025-06-19T20:44:18.074383Z","shell.execute_reply":"2025-06-19T20:44:18.088012Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Crear instancia del dataset\ndb = Dataset_2a('/kaggle/input/dataset-2a')\nfs = 250.0 \n\n# Cargar los datos del sujeto en modo 'training'\nX, y = load_BCICIV2a(db, sbj=5, mode='training', fs=fs)\nprint(f'tamaño de X:', X.shape)\nprint(f'tamaño de y:', y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T20:44:21.632941Z","iopub.execute_input":"2025-06-19T20:44:21.633532Z","iopub.status.idle":"2025-06-19T20:44:28.170898Z","shell.execute_reply.started":"2025-06-19T20:44:21.633508Z","shell.execute_reply":"2025-06-19T20:44:28.170138Z"}},"outputs":[{"name":"stdout","text":"tamaño de X: (129, 22, 500)\ntamaño de y: (129,)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"train_data, val_data, train_labels, val_labels = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=72,\n    stratify=y\n)\n\ndef create_tunable_model(dx, dy, tau, mu,\n                         kernel_type, learning_rate,\n                         kernel_size):\n    input_eeg = tf.keras.Input(shape=(22, 500), name='input_eeg')\n\n    # Bloque 1 con kernel_size buscable\n    x = tf.keras.layers.DepthwiseConv1D(\n        kernel_size=kernel_size, \n        strides=1,\n        padding='valid',\n        activation='relu',\n        depth_multiplier=1,\n        data_format=\"channels_first\",\n        name='block1_depthwise_conv1d'\n    )(input_eeg)\n\n    x = tf.keras.layers.AveragePooling1D(\n        pool_size=4,\n        strides=4,\n        padding='valid',\n        data_format=\"channels_first\",\n        name='block1_avg_pooling'\n    )(x)\n\n    x = tf.keras.layers.BatchNormalization(\n        axis=1,\n        name='block1_batch_norm'\n    )(x)\n\n    # Bloque 2: TakensConv1D\n    takens = TakensConv1D(dx=dx, dy=dy, tau=tau, mu=mu,\n                          name='takens_conv1d')(x)\n    x_sub, y_minus_1, y_t = takens\n\n    # Proyecciones densas\n    x_sub     = tf.keras.layers.Dense(dx, activation=None,\n                                       use_bias=False,\n                                       name='dense_proj_x')(x_sub)\n    y_minus_1 = tf.keras.layers.Dense(dy, activation=None,\n                                       use_bias=False,\n                                       name='dense_proj_y_1')(y_minus_1)\n    y_t       = tf.keras.layers.Dense(1, activation=None,\n                                       use_bias=False,\n                                       name='dense_proj_y')(y_t)\n\n    # Kernel layers fijos\n    def fixed_kernel(name):\n        layer = KernelLayer(\n            amplitude=1.0, trainable_amplitude=False,\n            length_scale=1.0, trainable_length_scale=False,\n            alpha=1.0, trainable_alpha=False,\n            kernel_type=kernel_type,\n            name=name\n        )\n        layer.trainable = False\n        return layer\n\n    Kx  = fixed_kernel('kernel_x')(x_sub)\n    Ky1 = fixed_kernel('kernel_y_minus_1')(y_minus_1)\n    Ky  = fixed_kernel('kernel_y')(y_t)\n\n    # Transferencia de entropía + aplanado\n    TE   = TransferEntropyLayer(alpha=2,\n                                name='transfer_entropy')(Kx, Ky1, Ky)\n    flat = RemoveDiagonalFlatten(name='remove_diag_flatten')(TE)\n\n    # Salida\n    h   = tf.keras.layers.Dense(10, activation='relu',\n                                name='dense_1')(flat)\n    out = tf.keras.layers.Dense(1, activation='sigmoid',\n                                name='output')(h)\n\n    model = tf.keras.Model(inputs=input_eeg, outputs=out)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss='binary_crossentropy',\n        metrics=[\n            BinaryAccuracy(name='accuracy'),\n            F1Score(name='f1_score'),\n            Recall(name='sensitivity'),\n            Specificity(name='specificity')\n        ]\n    )\n    return model\n\ndef build_model(hp):\n    # Hiperparámetros a buscar\n    dx          = hp.Int('dx',    min_value=1,  max_value=10, step=1)\n    dy          = hp.Int('dy',    min_value=1,  max_value=10, step=1)\n    tau         = hp.Int('tau',   min_value=1,  max_value=5,  step=1)\n    mu          = hp.Int('mu',    min_value=0,  max_value=10, step=1)\n    lr          = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n    kernel_type = 'rational_quadratic'\n\n    # Nuevo: rango buscable para kernel_size\n    kernel_size = hp.Int(\n        'kernel_size',\n        min_value=3,      # ventanas muy pequeñas (3 muestras)\n        max_value=125,    # hasta ~125 muestras (~0.25 s a 500 Hz)\n        step=2            # sólo impares\n    )\n\n    # Validación de que el embedding window quepa tras Conv+Pool\n    conv_len = 500 - kernel_size + 1\n    pool_len = (conv_len - 4) // 4 + 1\n    window   = mu + (dx - 1) * tau + 1\n    if window > pool_len:\n        # Trial inválido: modelo trivial\n        m = tf.keras.Sequential([\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(1, activation='sigmoid')\n        ])\n        m.compile('adam', 'binary_crossentropy', ['accuracy'])\n        return m\n\n    # Construcción del modelo real\n    return create_tunable_model(\n        dx, dy, tau, mu,\n        kernel_type, lr,\n        kernel_size\n    )\n\n# Configuración del tuner\ntuner = kt.BayesianOptimization(\n    hypermodel=build_model,\n    objective=kt.Objective(\"val_f1_score\", direction=\"max\"),\n    max_trials=50,\n    executions_per_trial=2,\n    directory=\"tuner_dir5\",\n    project_name=\"takens_te_tuning_5\"\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=1\n)\n\n# Inicio de la búsqueda\ntuner.search(\n    x=train_data,\n    y=train_labels,\n    validation_data=(val_data, val_labels),\n    epochs=200,\n    callbacks=[stop_early]\n)\n\n# Extracción del mejor resultado\nbest_hp    = tuner.get_best_hyperparameters(num_trials=1)[0]\nbest_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\nbest_score = best_trial.score  # val_f1_score\n\n# Guardado en DataFrame y CSV\nimport pandas as pd\n\nbest_dict = {\n    'dx':             best_hp.get('dx'),\n    'dy':             best_hp.get('dy'),\n    'tau':            best_hp.get('tau'),\n    'mu':             best_hp.get('mu'),\n    'kernel_size':    best_hp.get('kernel_size'),\n    'learning_rate':  best_hp.get('learning_rate'),\n    'val_f1_score':   best_score\n}\n\ndf_best = pd.DataFrame([best_dict])\nprint(df_best)\ndf_best.to_csv('best_hyperparameters_with_score5.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:01:09.974300Z","iopub.execute_input":"2025-06-19T18:01:09.974922Z","iopub.status.idle":"2025-06-19T18:50:52.087418Z","shell.execute_reply.started":"2025-06-19T18:01:09.974895Z","shell.execute_reply":"2025-06-19T18:50:52.086861Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Trial 50 Complete [00h 01m 00s]\nval_f1_score: 0.6754385530948639\n\nBest val_f1_score So Far: 0.7510775327682495\nTotal elapsed time: 00h 49m 39s\n   dx  dy  tau  mu  kernel_size  learning_rate  val_f1_score\n0   6   1    3   6          123           0.01      0.751078\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 1) Obtener el modelo ya entrenado con los mejores hiperparámetros\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# 2) Guardarlo en /kaggle/working\nbest_model.save(\"best_hp_model5.keras\") \n\n\n# Crear instancia del dataset\ndb = Dataset_2a('/kaggle/input/dataset-2a')\nfs = 250.0 \n\n# Cargar los datos del sujeto en modo 'training'\nX, y = load_BCICIV2a(db, sbj=5, mode='evaluation', fs=fs)\nprint(f'tamaño de X:', X.shape)\nprint(f'tamaño de X:', y.shape)\n\nresults = best_model.evaluate(X, y, return_dict=True)\n\nprint(\"Resultados evaluación:\")\nprint(f\"  Accuracy:     {results['accuracy']:.4f}\")\nprint(f\"  F1 Score:     {results['f1_score']:.4f}\")\nprint(f\"  Loss:         {results['loss']:.4f}\")\nprint(f\"  Sensitivity:  {results['sensitivity']:.4f}\")\nprint(f\"  Specificity:  {results['specificity']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:51:14.546302Z","iopub.execute_input":"2025-06-19T18:51:14.547214Z","iopub.status.idle":"2025-06-19T18:51:32.576796Z","shell.execute_reply.started":"2025-06-19T18:51:14.547190Z","shell.execute_reply":"2025-06-19T18:51:32.576106Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 24 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"tamaño de X: (135, 22, 500)\ntamaño de X: (135,)\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 487ms/step - accuracy: 0.4892 - f1_score: 0.5474 - loss: 0.7084 - sensitivity: 0.7123 - specificity: 0.3188\nResultados evaluación:\n  Accuracy:     0.4963\n  F1 Score:     0.5641\n  Loss:         0.7071\n  Sensitivity:  0.6769\n  Specificity:  0.3286\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 1) Recuperar los mejores HyperParameters y Trial\nbest_hp    = tuner.get_best_hyperparameters(num_trials=1)[0]\nbest_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n\n# 2) Extraer puntuación de validación (F1)\nbest_score = best_trial.score  # corresponde a val_f1_score\n\n# 3) Construir DataFrame con todos los valores\nimport pandas as pd\n\nbest_dict = {\n    'dx':             best_hp.get('dx'),\n    'dy':             best_hp.get('dy'),\n    'tau':            best_hp.get('tau'),\n    'mu':             best_hp.get('mu'),\n    'kernel_size':    best_hp.get('kernel_size'),\n    'learning_rate':  best_hp.get('learning_rate'), \n    'val_f1_score':   best_score\n}\n\ndf_best = pd.DataFrame([best_dict])\nprint(df_best)\n\n# 4) Guardar a CSV\ndf_best.to_csv('best_hyperparameters_with_score5.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:52:43.758459Z","iopub.execute_input":"2025-06-19T18:52:43.758809Z","iopub.status.idle":"2025-06-19T18:52:43.770408Z","shell.execute_reply.started":"2025-06-19T18:52:43.758786Z","shell.execute_reply":"2025-06-19T18:52:43.769644Z"}},"outputs":[{"name":"stdout","text":"   dx  dy  tau  mu  kernel_size  learning_rate  val_f1_score\n0   6   1    3   6          123           0.01      0.751078\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# 1) Recorremos todos los trials guardados en el tuner\nrecords = []\nfor trial in tuner.oracle.trials.values():\n    # Cada trial tiene un objeto HyperParameters donde .values es un dict de {hp_name: value}\n    hp_dict = trial.hyperparameters.values.copy()\n    # Añadimos el score (val_f1_score) de este trial\n    hp_dict['val_f1_score'] = trial.score\n    # Opcional: identifica el trial\n    hp_dict['trial_id'] = trial.trial_id\n    records.append(hp_dict)\n\n# 2) Creamos el DataFrame\ndf_all = pd.DataFrame(records)\n\n# 3) Ordenamos por la métrica descendente para ver primero los mejores\ndf_all = df_all.sort_values('val_f1_score', ascending=False).reset_index(drop=True)\n\n# 4) Mostramos y guardamos\nprint(df_all)\ndf_all.to_csv('all_trials_hyperparameters5.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:52:49.341788Z","iopub.execute_input":"2025-06-19T18:52:49.342783Z","iopub.status.idle":"2025-06-19T18:52:49.361420Z","shell.execute_reply.started":"2025-06-19T18:52:49.342750Z","shell.execute_reply":"2025-06-19T18:52:49.360572Z"}},"outputs":[{"name":"stdout","text":"    dx  dy  tau  mu  learning_rate  kernel_size  val_f1_score trial_id\n0    6   1    3   6         0.0100          123      0.751078       03\n1   10   1    1   1         0.0010          117      0.739583       30\n2    8   1    1   0         0.0010           93      0.718264       34\n3    7   1    1   0         0.0100          125      0.717857       18\n4    1   6    1   2         0.0100          125      0.715950       38\n5    1   4    2   3         0.0100           99      0.708333       04\n6    7   2    1   2         0.0010          119      0.704762       28\n7    8  10    3  10         0.0100           75      0.696970       05\n8    4   3    1   3         0.0100           99      0.696970       26\n9    8  10    4   5         0.0100           91      0.694444       00\n10   7   2    1   1         0.0100           91      0.693333       27\n11   1   5    1   4         0.0100           71      0.688172       14\n12  10   1    1   2         0.0001          103      0.684685       33\n13  10   5    4   1         0.0100           89      0.684685       01\n14  10   1    1   3         0.0010           83      0.684685       45\n15   7   9    2   0         0.0010           35      0.678161       17\n16   9   1    1   7         0.0010          103      0.677083       06\n17   2  10    4   8         0.0100           75      0.676190       02\n18   1   4    1   5         0.0100          121      0.676190       48\n19   7   2    4   0         0.0010           71      0.675439       07\n20   7  10    5   8         0.0100           57      0.675439       49\n21  10   4    1   0         0.0010          125      0.675439       37\n22   6   1    2   5         0.0100          125      0.675439       24\n23   4   1    1   0         0.0010          109      0.675439       35\n24   3   1    1   8         0.0100          125      0.667227       20\n25   7   3    2   4         0.0100           43      0.666667       11\n26   4   1    3   7         0.0100          125      0.666667       47\n27   8   1    1   0         0.0001          125      0.666667       43\n28   3   7    1   2         0.0100           95      0.666667       46\n29  10   3    2   1         0.0010           79      0.666667       31\n30   8   1    3   6         0.0100          125      0.666667       25\n31   8   2    1   5         0.0100          115      0.666667       22\n32   6   9    3   0         0.0100           35      0.666667       09\n33   6   8    1   6         0.0100          125      0.666667       19\n34   5   6    1   0         0.0010           67      0.666667       42\n35   1   9    2   2         0.0100           95      0.666667       40\n36   7   5    1   1         0.0100          125      0.666667       29\n37   1   3    1   0         0.0100          101      0.657658       39\n38   8  10    2   5         0.0100           57      0.649123       36\n39   2   9    2   0         0.0001           17      0.638402       13\n40   7   4    1   8         0.0001           47      0.637815       10\n41   1   2    4   7         0.0001            7      0.627826       08\n42  10   1    1   0         0.0100          121      0.614583       32\n43   1   4    1   5         0.0010          123      0.613333       41\n44  10  10    4   1         0.0100           75      0.519345       44\n45   9   6    5  10         0.0001           69      0.456989       12\n46   1   1    5   8         0.0010           61      0.433333       16\n47   6   4    3   8         0.0100          103      0.400000       23\n48   5   1    4   0         0.0100          125      0.333333       21\n49   7   8    5   9         0.0001          117      0.304348       15\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Entrenando con Quadratic","metadata":{}},{"cell_type":"code","source":"model = load_model(\"/kaggle/working/best_hp_model5.keras\", compile=True)\n\n# Callbacks\nearly_stopping = EarlyStopping(\n    monitor=\"val_loss\",\n    mode=\"min\",\n    patience=100,\n    restore_best_weights=True,\n    verbose=1\n)\ncsv_logger = CSVLogger(\"continued_training.log\", append=True)\n\n# 3) Carga los datos de BCI Competition IV-2a\ndb = Dataset_2a('/kaggle/input/dataset-2a')\nfs = 250.0\n\n#    – Split de entrenamiento\nX_full, y_full = load_BCICIV2a(db, sbj=5, mode='training',   fs=fs)\n#    – Split de evaluación (test final)\nX_test, y_test = load_BCICIV2a(db, sbj=5, mode='evaluation', fs=fs)\n\n# 4) Divide el set de entrenamiento en train/val (80/20)\ntrain_data, val_data, train_labels, val_labels = train_test_split(\n    X_full, y_full,\n    test_size=0.2,\n    random_state=42,\n    stratify=y_full\n)\n\nprint(f\"Train: {train_data.shape}, {train_labels.shape}\")\nprint(f\"Val:   {val_data.shape}, {val_labels.shape}\")\nprint(f\"Test:  {X_test.shape}, {y_test.shape}\")\n\n# 5) Continúa el entrenamiento\nhistory = model.fit(\n    x=train_data,\n    y=train_labels,\n    validation_data=(val_data, val_labels),\n    epochs=1000,\n    callbacks=[early_stopping, csv_logger]\n)\n\n# 6) Evalúa en el conjunto de evaluación\nresults = model.evaluate(X_test, y_test, return_dict=True)\nprint(\"Resultados en test:\")\nfor name, value in results.items():\n    print(f\"  {name}: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T18:53:50.952909Z","iopub.execute_input":"2025-06-19T18:53:50.953210Z","iopub.status.idle":"2025-06-19T18:54:42.714324Z","shell.execute_reply.started":"2025-06-19T18:53:50.953190Z","shell.execute_reply":"2025-06-19T18:54:42.713666Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"Train: (103, 22, 500), (103,)\nVal:   (26, 22, 500), (26,)\nTest:  (135, 22, 500), (135,)\nEpoch 1/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5649 - f1_score: 0.6549 - loss: 0.6921 - sensitivity: 0.7568 - specificity: 0.3625 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7051 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 2/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7483 - f1_score: 0.7350 - loss: 0.6625 - sensitivity: 0.6749 - specificity: 0.8286 - val_accuracy: 0.6538 - val_f1_score: 0.6667 - val_loss: 0.6774 - val_sensitivity: 0.6923 - val_specificity: 0.6154\nEpoch 3/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7589 - f1_score: 0.6492 - loss: 0.6541 - sensitivity: 0.4891 - specificity: 0.9920 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.9181 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 4/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6902 - f1_score: 0.7779 - loss: 0.6163 - sensitivity: 1.0000 - specificity: 0.3420 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.3322 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 5/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6523 - f1_score: 0.7459 - loss: 0.5870 - sensitivity: 1.0000 - specificity: 0.2878 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.9433 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 6/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8867 - f1_score: 0.8832 - loss: 0.5566 - sensitivity: 0.9115 - specificity: 0.8679 - val_accuracy: 0.4615 - val_f1_score: 0.6316 - val_loss: 1.0232 - val_sensitivity: 0.9231 - val_specificity: 0.0000e+00\nEpoch 7/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8325 - f1_score: 0.8552 - loss: 0.5119 - sensitivity: 0.9530 - specificity: 0.7040 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.5490 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 8/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7747 - f1_score: 0.8191 - loss: 0.4631 - sensitivity: 0.9823 - specificity: 0.5510 - val_accuracy: 0.4615 - val_f1_score: 0.6316 - val_loss: 1.1301 - val_sensitivity: 0.9231 - val_specificity: 0.0000e+00\nEpoch 9/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9629 - f1_score: 0.9660 - loss: 0.3744 - sensitivity: 0.9885 - specificity: 0.9327 - val_accuracy: 0.3846 - val_f1_score: 0.5556 - val_loss: 1.1660 - val_sensitivity: 0.7692 - val_specificity: 0.0000e+00\nEpoch 10/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9790 - f1_score: 0.9792 - loss: 0.3068 - sensitivity: 0.9596 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.0182 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 11/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9727 - f1_score: 0.9738 - loss: 0.2575 - sensitivity: 0.9494 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5882 - val_loss: 1.1467 - val_sensitivity: 0.7692 - val_specificity: 0.1538\nEpoch 12/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9940 - f1_score: 0.9942 - loss: 0.1777 - sensitivity: 0.9885 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.0543 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 13/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9787 - f1_score: 0.9785 - loss: 0.1466 - sensitivity: 0.9580 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5714 - val_loss: 1.5153 - val_sensitivity: 0.7692 - val_specificity: 0.0769\nEpoch 14/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1163 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.5100 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 15/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0666 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5882 - val_loss: 1.8729 - val_sensitivity: 0.7692 - val_specificity: 0.1538\nEpoch 16/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9940 - f1_score: 0.9942 - loss: 0.0624 - sensitivity: 1.0000 - specificity: 0.9877 - val_accuracy: 0.4231 - val_f1_score: 0.4828 - val_loss: 1.3974 - val_sensitivity: 0.5385 - val_specificity: 0.3077\nEpoch 17/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9909 - f1_score: 0.9912 - loss: 0.0571 - sensitivity: 0.9826 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.6486 - val_loss: 2.2887 - val_sensitivity: 0.9231 - val_specificity: 0.0769\nEpoch 18/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0468 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.2379 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 19/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0373 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.3947 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 20/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0128 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6471 - val_loss: 1.7480 - val_sensitivity: 0.8462 - val_specificity: 0.2308\nEpoch 21/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0128 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.4584 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 22/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0094 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.3874 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 23/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0080 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 1.6542 - val_sensitivity: 0.8462 - val_specificity: 0.3846\nEpoch 24/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0054 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 1.9466 - val_sensitivity: 0.8462 - val_specificity: 0.3077\nEpoch 25/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0079 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6250 - val_loss: 1.6675 - val_sensitivity: 0.7692 - val_specificity: 0.3077\nEpoch 26/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0034 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.5754 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 27/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0028 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6097 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 28/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0028 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6381 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 29/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0021 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6403 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 30/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6416 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 31/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6566 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 32/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.6656 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 33/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6335 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 34/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.5571 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 35/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.5320 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 36/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 1.5319 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 37/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.5441 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 38/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.9705e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.5534 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 39/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.7224e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.5766 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 40/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.5798 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 41/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.2016e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.5433 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 42/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5742e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.5067 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 43/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4938e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 1.5016 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 44/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.7815e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 1.4853 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 45/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5451e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.4742 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 46/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8830e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.4640 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 47/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0193e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.4576 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 48/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0847e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4535 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 49/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1580e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4585 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 50/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9574e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4639 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 51/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.7537e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4725 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 52/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9768e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4871 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 53/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4105e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4919 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 54/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5722e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4845 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 55/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3792e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4751 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 56/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0384e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4565 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 57/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9945e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4479 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 58/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5717e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4464 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 59/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4957e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4277 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 60/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1385e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.3784 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 61/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8800e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.5833 - val_loss: 1.3653 - val_sensitivity: 0.5385 - val_specificity: 0.6923\nEpoch 62/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2160e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.3713 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 63/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5029e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.3884 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 64/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2491e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4025 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 65/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8331e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4086 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 66/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0471e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4133 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 67/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9780e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4152 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 68/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6182e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4142 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 69/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5181e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.5833 - val_loss: 1.4167 - val_sensitivity: 0.5385 - val_specificity: 0.6923\nEpoch 70/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4155e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.5833 - val_loss: 1.4216 - val_sensitivity: 0.5385 - val_specificity: 0.6923\nEpoch 71/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1190e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4259 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 72/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9559e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4312 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 73/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1494e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4357 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 74/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0701e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4325 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 75/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7949e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4176 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 76/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0080e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.5833 - val_loss: 1.4144 - val_sensitivity: 0.5385 - val_specificity: 0.6923\nEpoch 77/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8672e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4134 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 78/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7022e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4149 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 79/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5097e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4184 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 80/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4690e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4199 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 81/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4427e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4254 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 82/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5342e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4277 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 83/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4285e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4277 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 84/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4780e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4229 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 85/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2071e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4208 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 86/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4000e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4194 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 87/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6170e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4244 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 88/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1452e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.5833 - val_loss: 1.4333 - val_sensitivity: 0.5385 - val_specificity: 0.6923\nEpoch 89/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0319e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.5833 - val_loss: 1.4385 - val_sensitivity: 0.5385 - val_specificity: 0.6923\nEpoch 90/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2109e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4433 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 91/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9590e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4483 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 92/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8054e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4554 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 93/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8695e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4602 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 94/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0983e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4643 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 95/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8096e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4660 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 96/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8728e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4663 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 97/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8021e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4635 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 98/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8043e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4583 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 99/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7787e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4550 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 100/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9544e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4525 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 101/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6508e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4529 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 102/1000\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6576e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.4524 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 102: early stopping\nRestoring model weights from the end of the best epoch: 2.\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 505ms/step - accuracy: 0.4937 - f1_score: 0.5034 - loss: 0.7021 - sensitivity: 0.5919 - specificity: 0.4114\nResultados en test:\n  accuracy: 0.4889\n  f1_score: 0.5175\n  loss: 0.7076\n  sensitivity: 0.5692\n  specificity: 0.4143\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Validación cruzada 5 Folds ","metadata":{}},{"cell_type":"code","source":"# 1) Parámetros generales\nN_SPLITS = 5\nRANDOM_STATE = 42\nEPOCHS = 1000\nMODEL_PATH = \"/kaggle/working/best_hp_model5.keras\"\n\n# 2) Función para crear callbacks de cada fold\ndef get_callbacks(fold):\n    return [\n        EarlyStopping(\n            monitor=\"val_loss\", mode=\"min\", patience=100,\n            restore_best_weights=True, verbose=1\n        ),\n        CSVLogger(f\"continued_training_fold{fold}.log\", append=True),\n        ModelCheckpoint(\n            filepath=f\"best_model_fold{fold}.keras\",\n            monitor=\"val_loss\",               # o cambia a \"val_accuracy\" u otra métrica\n            mode=\"min\",                       # \"min\" si monitoreas pérdidas, \"max\" si monitoreas accuracy/F1\n            save_best_only=True,\n            save_weights_only=False,\n            verbose=1\n        )\n    ]\n\n# 3) Carga de datos\ndb = Dataset_2a('/kaggle/input/dataset-2a')\nfs = 250.0\nX_full, y_full = load_BCICIV2a(db, sbj=5, mode='training',   fs=fs)\nX_test, y_test = load_BCICIV2a(db, sbj=5, mode='evaluation', fs=fs)\n\nprint(f\"Full train set: {X_full.shape}, {y_full.shape}\")\nprint(f\"Evaluation set: {X_test.shape}, {y_test.shape}\")\n\n# 4) Cross‐validation estratificada\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n\n# 5) Loop de folds\nfold_results = []\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X_full, y_full), start=1):\n    print(f\"\\n\\n=== Fold {fold}/{N_SPLITS} ===\")\n    # 5.1) Carga modelo fresco con los pesos previos\n    model = load_model(MODEL_PATH, compile=True)\n\n    # 5.2) Split train/val para este fold\n    X_train, y_train = X_full[train_idx], y_full[train_idx]\n    X_val,   y_val   = X_full[val_idx],   y_full[val_idx]\n    print(f\"  Train: {X_train.shape}, {y_train.shape}\")\n    print(f\"  Val:   {X_val.shape},   {y_val.shape}\")\n\n    # 5.3) Entrena y guarda el mejor modelo del fold\n    history = model.fit(\n        x=X_train, y=y_train,\n        validation_data=(X_val, y_val),\n        epochs=EPOCHS,\n        callbacks=get_callbacks(fold),\n        verbose=2\n    )\n\n    # 5.4) Carga el mejor modelo guardado antes de evaluar\n    best_model = load_model(f\"best_model_fold{fold}.keras\", compile=True)\n    results = best_model.evaluate(X_test, y_test, return_dict=True, verbose=0)\n    print(f\"  Eval (best model fold{fold}): \" +\n          \", \".join(f\"{k}={v:.4f}\" for k, v in results.items()))\n\n    fold_results.append(results)\n\n# 6) Resumen de performance promedio\nmetrics = fold_results[0].keys()\nprint(\"\\n=== Resumen Cross‐Validation ===\")\nfor m in metrics:\n    vals = [r[m] for r in fold_results]\n    print(f\"{m:12s}: {np.mean(vals):.4f} ± {np.std(vals, ddof=1):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T19:15:55.796097Z","iopub.execute_input":"2025-06-19T19:15:55.796433Z","iopub.status.idle":"2025-06-19T19:19:51.704400Z","shell.execute_reply.started":"2025-06-19T19:15:55.796411Z","shell.execute_reply":"2025-06-19T19:19:51.703650Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Full train set: (129, 22, 500), (129,)\nEvaluation set: (135, 22, 500), (135,)\n\n\n=== Fold 1/5 ===\n  Train: (103, 22, 500), (103,)\n  Val:   (26, 22, 500),   (26,)\nEpoch 1/1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 0.83920, saving model to best_model_fold1.keras\n4/4 - 17s - 4s/step - accuracy: 0.5825 - f1_score: 0.6667 - loss: 0.6837 - sensitivity: 0.8113 - specificity: 0.3400 - val_accuracy: 0.5000 - val_f1_score: 0.0000e+00 - val_loss: 0.8392 - val_sensitivity: 0.0000e+00 - val_specificity: 1.0000\nEpoch 2/1000\n\nEpoch 2: val_loss improved from 0.83920 to 0.72496, saving model to best_model_fold1.keras\n4/4 - 0s - 58ms/step - accuracy: 0.5631 - f1_score: 0.3077 - loss: 0.6554 - sensitivity: 0.1887 - specificity: 0.9600 - val_accuracy: 0.5000 - val_f1_score: 0.6486 - val_loss: 0.7250 - val_sensitivity: 0.9231 - val_specificity: 0.0769\nEpoch 3/1000\n\nEpoch 3: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 0.7961 - f1_score: 0.8264 - loss: 0.5888 - sensitivity: 0.9434 - specificity: 0.6400 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.8793 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 4/1000\n\nEpoch 4: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.8252 - f1_score: 0.8548 - loss: 0.5245 - sensitivity: 1.0000 - specificity: 0.6400 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 0.8444 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 5/1000\n\nEpoch 5: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.7961 - f1_score: 0.7640 - loss: 0.4772 - sensitivity: 0.6415 - specificity: 0.9600 - val_accuracy: 0.4231 - val_f1_score: 0.4828 - val_loss: 0.8965 - val_sensitivity: 0.5385 - val_specificity: 0.3077\nEpoch 6/1000\n\nEpoch 6: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 0.8932 - f1_score: 0.8911 - loss: 0.3807 - sensitivity: 0.8491 - specificity: 0.9400 - val_accuracy: 0.4615 - val_f1_score: 0.6111 - val_loss: 1.1865 - val_sensitivity: 0.8462 - val_specificity: 0.0769\nEpoch 7/1000\n\nEpoch 7: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.8932 - f1_score: 0.9009 - loss: 0.3363 - sensitivity: 0.9434 - specificity: 0.8400 - val_accuracy: 0.3846 - val_f1_score: 0.3846 - val_loss: 1.1802 - val_sensitivity: 0.3846 - val_specificity: 0.3846\nEpoch 8/1000\n\nEpoch 8: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.9515 - f1_score: 0.9524 - loss: 0.2482 - sensitivity: 0.9434 - specificity: 0.9600 - val_accuracy: 0.4615 - val_f1_score: 0.5882 - val_loss: 1.4847 - val_sensitivity: 0.7692 - val_specificity: 0.1538\nEpoch 9/1000\n\nEpoch 9: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.9612 - f1_score: 0.9623 - loss: 0.2078 - sensitivity: 0.9623 - specificity: 0.9600 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.2570 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 10/1000\n\nEpoch 10: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.9806 - f1_score: 0.9811 - loss: 0.1558 - sensitivity: 0.9811 - specificity: 0.9800 - val_accuracy: 0.4231 - val_f1_score: 0.5946 - val_loss: 1.7809 - val_sensitivity: 0.8462 - val_specificity: 0.0000e+00\nEpoch 11/1000\n\nEpoch 11: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.9612 - f1_score: 0.9636 - loss: 0.1714 - sensitivity: 1.0000 - specificity: 0.9200 - val_accuracy: 0.4615 - val_f1_score: 0.3636 - val_loss: 1.3181 - val_sensitivity: 0.3077 - val_specificity: 0.6154\nEpoch 12/1000\n\nEpoch 12: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0973 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.6286 - val_loss: 1.7025 - val_sensitivity: 0.8462 - val_specificity: 0.1538\nEpoch 13/1000\n\nEpoch 13: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.0906 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.4615 - val_f1_score: 0.2222 - val_loss: 1.8446 - val_sensitivity: 0.1538 - val_specificity: 0.7692\nEpoch 14/1000\n\nEpoch 14: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 0.9806 - f1_score: 0.9808 - loss: 0.1301 - sensitivity: 0.9623 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.6286 - val_loss: 2.1231 - val_sensitivity: 0.8462 - val_specificity: 0.1538\nEpoch 15/1000\n\nEpoch 15: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0651 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.6057 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 16/1000\n\nEpoch 16: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 0.9903 - f1_score: 0.9905 - loss: 0.0608 - sensitivity: 0.9811 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.7087 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 17/1000\n\nEpoch 17: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0435 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 2.1552 - val_sensitivity: 0.8462 - val_specificity: 0.3077\nEpoch 18/1000\n\nEpoch 18: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0190 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5000 - val_loss: 1.8718 - val_sensitivity: 0.5385 - val_specificity: 0.3846\nEpoch 19/1000\n\nEpoch 19: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0221 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9199 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 20/1000\n\nEpoch 20: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0096 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 2.2732 - val_sensitivity: 0.8462 - val_specificity: 0.3077\nEpoch 21/1000\n\nEpoch 21: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0160 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 2.0351 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 22/1000\n\nEpoch 22: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0069 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 1.9393 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 23/1000\n\nEpoch 23: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0090 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9557 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 24/1000\n\nEpoch 24: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0054 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 2.0397 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 25/1000\n\nEpoch 25: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0062 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 2.1306 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 26/1000\n\nEpoch 26: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0042 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 2.0508 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 27/1000\n\nEpoch 27: val_loss did not improve from 0.72496\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0039 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.0831 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 28/1000\n\nEpoch 28: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0043 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.0495 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 29/1000\n\nEpoch 29: val_loss did not improve from 0.72496\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0039 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 2.0415 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 30/1000\n\nEpoch 30: val_loss did not improve from 0.72496\n4/4 - 0s - 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0035 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 2.0378 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 31/1000\n\nEpoch 31: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0024 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.0687 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 32/1000\n\nEpoch 32: val_loss did not improve from 0.72496\n4/4 - 0s - 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.3636 - val_loss: 2.1034 - val_sensitivity: 0.3077 - val_specificity: 0.6154\nEpoch 33/1000\n\nEpoch 33: val_loss did not improve from 0.72496\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.0354 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 34/1000\n\nEpoch 34: val_loss did not improve from 0.72496\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 1.9726 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 35/1000\n\nEpoch 35: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.9614 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 36/1000\n\nEpoch 36: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 1.9900 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 37/1000\n\nEpoch 37: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 2.0095 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 38/1000\n\nEpoch 38: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 2.0258 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 39/1000\n\nEpoch 39: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 2.0377 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 40/1000\n\nEpoch 40: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 2.0580 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 41/1000\n\nEpoch 41: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 2.0930 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 42/1000\n\nEpoch 42: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 2.1866 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 43/1000\n\nEpoch 43: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 2.2545 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 44/1000\n\nEpoch 44: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 2.2962 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 45/1000\n\nEpoch 45: val_loss did not improve from 0.72496\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 2.3177 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 46/1000\n\nEpoch 46: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 2.2924 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 47/1000\n\nEpoch 47: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.2344e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 2.2765 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 48/1000\n\nEpoch 48: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.5941e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 2.2617 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 49/1000\n\nEpoch 49: val_loss did not improve from 0.72496\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.7955e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2593 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 50/1000\n\nEpoch 50: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.2430e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2541 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 51/1000\n\nEpoch 51: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8842e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.2437 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 52/1000\n\nEpoch 52: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6059e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.2394 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 53/1000\n\nEpoch 53: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9804e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.2291 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 54/1000\n\nEpoch 54: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5641e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2231 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 55/1000\n\nEpoch 55: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5422e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2283 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 56/1000\n\nEpoch 56: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3247e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2327 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 57/1000\n\nEpoch 57: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.7150e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2272 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 58/1000\n\nEpoch 58: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.6907e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2251 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 59/1000\n\nEpoch 59: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8159e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2205 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 60/1000\n\nEpoch 60: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9796e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2193 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 61/1000\n\nEpoch 61: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4240e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.2130 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 62/1000\n\nEpoch 62: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9126e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.2035 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 63/1000\n\nEpoch 63: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0641e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.2039 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 64/1000\n\nEpoch 64: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2389e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2102 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 65/1000\n\nEpoch 65: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1247e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4000 - val_loss: 2.2181 - val_sensitivity: 0.3846 - val_specificity: 0.4615\nEpoch 66/1000\n\nEpoch 66: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6070e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2295 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 67/1000\n\nEpoch 67: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1469e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2405 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 68/1000\n\nEpoch 68: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5527e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2396 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 69/1000\n\nEpoch 69: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7317e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2381 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 70/1000\n\nEpoch 70: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7656e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2377 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 71/1000\n\nEpoch 71: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1441e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2351 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 72/1000\n\nEpoch 72: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1596e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2380 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 73/1000\n\nEpoch 73: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8002e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2355 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 74/1000\n\nEpoch 74: val_loss did not improve from 0.72496\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9489e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2376 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 75/1000\n\nEpoch 75: val_loss did not improve from 0.72496\n4/4 - 0s - 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6499e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2423 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 76/1000\n\nEpoch 76: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0264e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2485 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 77/1000\n\nEpoch 77: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1002e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2537 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 78/1000\n\nEpoch 78: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2309e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2556 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 79/1000\n\nEpoch 79: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1573e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2594 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 80/1000\n\nEpoch 80: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6531e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2591 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 81/1000\n\nEpoch 81: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9539e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2589 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 82/1000\n\nEpoch 82: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9746e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2658 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 83/1000\n\nEpoch 83: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6895e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2734 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 84/1000\n\nEpoch 84: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1324e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2774 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 85/1000\n\nEpoch 85: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9475e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2695 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 86/1000\n\nEpoch 86: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3596e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2740 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 87/1000\n\nEpoch 87: val_loss did not improve from 0.72496\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4049e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2801 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 88/1000\n\nEpoch 88: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4825e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2839 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 89/1000\n\nEpoch 89: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6415e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2885 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 90/1000\n\nEpoch 90: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4930e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2947 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 91/1000\n\nEpoch 91: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1252e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.3022 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 92/1000\n\nEpoch 92: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5158e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.3114 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 93/1000\n\nEpoch 93: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7404e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.3072 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 94/1000\n\nEpoch 94: val_loss did not improve from 0.72496\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1728e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2895 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 95/1000\n\nEpoch 95: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7885e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2833 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 96/1000\n\nEpoch 96: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3045e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.2850 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 97/1000\n\nEpoch 97: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2310e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.2955 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 98/1000\n\nEpoch 98: val_loss did not improve from 0.72496\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0393e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.3067 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 99/1000\n\nEpoch 99: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4036e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.3186 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 100/1000\n\nEpoch 100: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9694e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.3206 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 101/1000\n\nEpoch 101: val_loss did not improve from 0.72496\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1688e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.3478 - val_loss: 2.3171 - val_sensitivity: 0.3077 - val_specificity: 0.5385\nEpoch 102/1000\n\nEpoch 102: val_loss did not improve from 0.72496\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7814e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 2.3060 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 102: early stopping\nRestoring model weights from the end of the best epoch: 2.\n  Eval (best model fold1): accuracy=0.4741, f1_score=0.6077, loss=0.7347, sensitivity=0.8462, specificity=0.1286\n\n\n=== Fold 2/5 ===\n  Train: (103, 22, 500), (103,)\n  Val:   (26, 22, 500),   (26,)\nEpoch 1/1000\n\nEpoch 1: val_loss improved from inf to 0.86048, saving model to best_model_fold2.keras\n4/4 - 22s - 5s/step - accuracy: 0.5049 - f1_score: 0.5234 - loss: 0.6973 - sensitivity: 0.5283 - specificity: 0.4800 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.8605 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 2/1000\n\nEpoch 2: val_loss improved from 0.86048 to 0.63136, saving model to best_model_fold2.keras\n4/4 - 0s - 61ms/step - accuracy: 0.6117 - f1_score: 0.7260 - loss: 0.6504 - sensitivity: 1.0000 - specificity: 0.2000 - val_accuracy: 0.6923 - val_f1_score: 0.6923 - val_loss: 0.6314 - val_sensitivity: 0.6923 - val_specificity: 0.6923\nEpoch 3/1000\n\nEpoch 3: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 0.7476 - f1_score: 0.6750 - loss: 0.6504 - sensitivity: 0.5094 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.6486 - val_loss: 0.7142 - val_sensitivity: 0.9231 - val_specificity: 0.0769\nEpoch 4/1000\n\nEpoch 4: val_loss did not improve from 0.63136\n4/4 - 0s - 45ms/step - accuracy: 0.6311 - f1_score: 0.7324 - loss: 0.6244 - sensitivity: 0.9811 - specificity: 0.2600 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.1016 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 5/1000\n\nEpoch 5: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 0.7476 - f1_score: 0.7969 - loss: 0.5812 - sensitivity: 0.9623 - specificity: 0.5200 - val_accuracy: 0.6538 - val_f1_score: 0.7097 - val_loss: 0.6988 - val_sensitivity: 0.8462 - val_specificity: 0.4615\nEpoch 6/1000\n\nEpoch 6: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 0.8835 - f1_score: 0.8750 - loss: 0.5539 - sensitivity: 0.7925 - specificity: 0.9800 - val_accuracy: 0.5385 - val_f1_score: 0.6471 - val_loss: 0.7819 - val_sensitivity: 0.8462 - val_specificity: 0.2308\nEpoch 7/1000\n\nEpoch 7: val_loss did not improve from 0.63136\n4/4 - 0s - 45ms/step - accuracy: 0.8932 - f1_score: 0.9043 - loss: 0.5025 - sensitivity: 0.9811 - specificity: 0.8000 - val_accuracy: 0.5385 - val_f1_score: 0.6667 - val_loss: 0.8631 - val_sensitivity: 0.9231 - val_specificity: 0.1538\nEpoch 8/1000\n\nEpoch 8: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 0.9417 - f1_score: 0.9434 - loss: 0.4385 - sensitivity: 0.9434 - specificity: 0.9400 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 0.7887 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 9/1000\n\nEpoch 9: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.8835 - f1_score: 0.8723 - loss: 0.3948 - sensitivity: 0.7736 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.7059 - val_loss: 1.1797 - val_sensitivity: 0.9231 - val_specificity: 0.3077\nEpoch 10/1000\n\nEpoch 10: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.8835 - f1_score: 0.8983 - loss: 0.3431 - sensitivity: 1.0000 - specificity: 0.7600 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 0.9360 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 11/1000\n\nEpoch 11: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.8738 - f1_score: 0.8602 - loss: 0.3278 - sensitivity: 0.7547 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6857 - val_loss: 1.3474 - val_sensitivity: 0.9231 - val_specificity: 0.2308\nEpoch 12/1000\n\nEpoch 12: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.9417 - f1_score: 0.9464 - loss: 0.2449 - sensitivity: 1.0000 - specificity: 0.8800 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 1.2083 - val_sensitivity: 0.8462 - val_specificity: 0.3846\nEpoch 13/1000\n\nEpoch 13: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.9806 - f1_score: 0.9808 - loss: 0.1907 - sensitivity: 0.9623 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 1.1459 - val_sensitivity: 0.8462 - val_specificity: 0.5385\nEpoch 14/1000\n\nEpoch 14: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 0.9709 - f1_score: 0.9720 - loss: 0.1458 - sensitivity: 0.9811 - specificity: 0.9600 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 1.2582 - val_sensitivity: 0.8462 - val_specificity: 0.5385\nEpoch 15/1000\n\nEpoch 15: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.9903 - f1_score: 0.9905 - loss: 0.1124 - sensitivity: 0.9811 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 1.3738 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 16/1000\n\nEpoch 16: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0661 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7273 - val_loss: 1.7024 - val_sensitivity: 0.9231 - val_specificity: 0.3846\nEpoch 17/1000\n\nEpoch 17: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0478 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.4830 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 18/1000\n\nEpoch 18: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.9903 - f1_score: 0.9905 - loss: 0.0699 - sensitivity: 0.9811 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7273 - val_loss: 1.8500 - val_sensitivity: 0.9231 - val_specificity: 0.3846\nEpoch 19/1000\n\nEpoch 19: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0405 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7097 - val_loss: 1.6972 - val_sensitivity: 0.8462 - val_specificity: 0.4615\nEpoch 20/1000\n\nEpoch 20: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0220 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.5837 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 21/1000\n\nEpoch 21: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0142 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 2.0669 - val_sensitivity: 0.9231 - val_specificity: 0.4615\nEpoch 22/1000\n\nEpoch 22: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0285 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.6847 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 23/1000\n\nEpoch 23: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0331 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.5488 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 24/1000\n\nEpoch 24: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0165 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7097 - val_loss: 1.8320 - val_sensitivity: 0.8462 - val_specificity: 0.4615\nEpoch 25/1000\n\nEpoch 25: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0159 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.5307 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 26/1000\n\nEpoch 26: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 0.9903 - f1_score: 0.9905 - loss: 0.0428 - sensitivity: 0.9811 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 1.7530 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 27/1000\n\nEpoch 27: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0130 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7097 - val_loss: 2.1734 - val_sensitivity: 0.8462 - val_specificity: 0.4615\nEpoch 28/1000\n\nEpoch 28: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0174 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7840 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 29/1000\n\nEpoch 29: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0126 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7810 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 30/1000\n\nEpoch 30: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0062 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7097 - val_loss: 2.0639 - val_sensitivity: 0.8462 - val_specificity: 0.4615\nEpoch 31/1000\n\nEpoch 31: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0077 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7097 - val_loss: 1.9501 - val_sensitivity: 0.8462 - val_specificity: 0.4615\nEpoch 32/1000\n\nEpoch 32: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0042 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7968 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 33/1000\n\nEpoch 33: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0039 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.8114 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 34/1000\n\nEpoch 34: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0041 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.8897 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 35/1000\n\nEpoch 35: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0025 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.9461 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 36/1000\n\nEpoch 36: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.9252 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 37/1000\n\nEpoch 37: val_loss did not improve from 0.63136\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.8889 - val_sensitivity: 0.6923 - val_specificity: 0.4615\nEpoch 38/1000\n\nEpoch 38: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8482 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 39/1000\n\nEpoch 39: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8225 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 40/1000\n\nEpoch 40: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8250 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 41/1000\n\nEpoch 41: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8326 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 42/1000\n\nEpoch 42: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.8425 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 43/1000\n\nEpoch 43: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.8330 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 44/1000\n\nEpoch 44: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6542e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.8100 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 45/1000\n\nEpoch 45: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7870 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 46/1000\n\nEpoch 46: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.3130e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7806 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 47/1000\n\nEpoch 47: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.9882e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7754 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 48/1000\n\nEpoch 48: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5015e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7826 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 49/1000\n\nEpoch 49: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.6866e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7893 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 50/1000\n\nEpoch 50: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.2851e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7750 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 51/1000\n\nEpoch 51: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.8452e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7602 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 52/1000\n\nEpoch 52: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.9081e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7595 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 53/1000\n\nEpoch 53: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.5485e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7691 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 54/1000\n\nEpoch 54: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.2660e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7676 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 55/1000\n\nEpoch 55: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.4805e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7418 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 56/1000\n\nEpoch 56: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0399e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.7211 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 57/1000\n\nEpoch 57: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4863e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.7028 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 58/1000\n\nEpoch 58: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3016e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.6948 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 59/1000\n\nEpoch 59: val_loss did not improve from 0.63136\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0858e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.6968 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 60/1000\n\nEpoch 60: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6433e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.7196 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 61/1000\n\nEpoch 61: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3686e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7579 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 62/1000\n\nEpoch 62: val_loss did not improve from 0.63136\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6408e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7667 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 63/1000\n\nEpoch 63: val_loss did not improve from 0.63136\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8738e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7607 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 64/1000\n\nEpoch 64: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7546e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7441 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 65/1000\n\nEpoch 65: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4247e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.7244 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 66/1000\n\nEpoch 66: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0357e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.7309 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 67/1000\n\nEpoch 67: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4597e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.7991 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 68/1000\n\nEpoch 68: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3993e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.8302 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 69/1000\n\nEpoch 69: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5882e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8338 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 70/1000\n\nEpoch 70: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2875e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8176 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 71/1000\n\nEpoch 71: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1021e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7961 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 72/1000\n\nEpoch 72: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3181e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7911 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 73/1000\n\nEpoch 73: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4959e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 1.7935 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 74/1000\n\nEpoch 74: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8349e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.8007 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 75/1000\n\nEpoch 75: val_loss did not improve from 0.63136\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0291e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.8089 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 76/1000\n\nEpoch 76: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6324e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8192 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 77/1000\n\nEpoch 77: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7538e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8215 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 78/1000\n\nEpoch 78: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2192e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.8070 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 79/1000\n\nEpoch 79: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2609e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7687 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 80/1000\n\nEpoch 80: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0734e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 1.7400 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 81/1000\n\nEpoch 81: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4481e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 1.7349 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 82/1000\n\nEpoch 82: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3078e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 1.7300 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 83/1000\n\nEpoch 83: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9288e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 1.7293 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 84/1000\n\nEpoch 84: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9652e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7337 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 85/1000\n\nEpoch 85: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7376e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7349 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 86/1000\n\nEpoch 86: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1891e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7318 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 87/1000\n\nEpoch 87: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0193e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7269 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 88/1000\n\nEpoch 88: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3770e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7199 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 89/1000\n\nEpoch 89: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6439e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7177 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 90/1000\n\nEpoch 90: val_loss did not improve from 0.63136\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2460e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7189 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 91/1000\n\nEpoch 91: val_loss did not improve from 0.63136\n4/4 - 0s - 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2542e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7211 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 92/1000\n\nEpoch 92: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1470e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7235 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 93/1000\n\nEpoch 93: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8540e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 1.7188 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 94/1000\n\nEpoch 94: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2866e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 1.7047 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 95/1000\n\nEpoch 95: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1889e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 1.7025 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 96/1000\n\nEpoch 96: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8057e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 1.7058 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 97/1000\n\nEpoch 97: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3310e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 1.7136 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 98/1000\n\nEpoch 98: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3354e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7240 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 99/1000\n\nEpoch 99: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5877e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7331 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 100/1000\n\nEpoch 100: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1677e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7338 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 101/1000\n\nEpoch 101: val_loss did not improve from 0.63136\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5594e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.7324 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 102/1000\n\nEpoch 102: val_loss did not improve from 0.63136\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6663e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4800 - val_loss: 1.7411 - val_sensitivity: 0.4615 - val_specificity: 0.5385\nEpoch 102: early stopping\nRestoring model weights from the end of the best epoch: 2.\n  Eval (best model fold2): accuracy=0.4444, f1_score=0.4966, loss=0.7290, sensitivity=0.5692, specificity=0.3286\n\n\n=== Fold 3/5 ===\n  Train: (103, 22, 500), (103,)\n  Val:   (26, 22, 500),   (26,)\nEpoch 1/1000\n\nEpoch 1: val_loss improved from inf to 0.68265, saving model to best_model_fold3.keras\n4/4 - 18s - 5s/step - accuracy: 0.5049 - f1_score: 0.5984 - loss: 0.6941 - sensitivity: 0.7170 - specificity: 0.2800 - val_accuracy: 0.5000 - val_f1_score: 0.5806 - val_loss: 0.6827 - val_sensitivity: 0.6923 - val_specificity: 0.3077\nEpoch 2/1000\n\nEpoch 2: val_loss did not improve from 0.68265\n4/4 - 0s - 44ms/step - accuracy: 0.6893 - f1_score: 0.7143 - loss: 0.6482 - sensitivity: 0.7547 - specificity: 0.6200 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.1767 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 3/1000\n\nEpoch 3: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 0.6019 - f1_score: 0.7211 - loss: 0.6213 - sensitivity: 1.0000 - specificity: 0.1800 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.0346 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 4/1000\n\nEpoch 4: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 0.8350 - f1_score: 0.8468 - loss: 0.5652 - sensitivity: 0.8868 - specificity: 0.7800 - val_accuracy: 0.5000 - val_f1_score: 0.6286 - val_loss: 0.8100 - val_sensitivity: 0.8462 - val_specificity: 0.1538\nEpoch 5/1000\n\nEpoch 5: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 0.8932 - f1_score: 0.8932 - loss: 0.5100 - sensitivity: 0.8679 - specificity: 0.9200 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.5736 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 6/1000\n\nEpoch 6: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 0.7670 - f1_score: 0.8154 - loss: 0.4647 - sensitivity: 1.0000 - specificity: 0.5200 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 0.9168 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 7/1000\n\nEpoch 7: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 0.7961 - f1_score: 0.7586 - loss: 0.4439 - sensitivity: 0.6226 - specificity: 0.9800 - val_accuracy: 0.5385 - val_f1_score: 0.6842 - val_loss: 1.8524 - val_sensitivity: 1.0000 - val_specificity: 0.0769\nEpoch 8/1000\n\nEpoch 8: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 0.7961 - f1_score: 0.8346 - loss: 0.4349 - sensitivity: 1.0000 - specificity: 0.5800 - val_accuracy: 0.5000 - val_f1_score: 0.6486 - val_loss: 1.6395 - val_sensitivity: 0.9231 - val_specificity: 0.0769\nEpoch 9/1000\n\nEpoch 9: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 0.8835 - f1_score: 0.8750 - loss: 0.3295 - sensitivity: 0.7925 - specificity: 0.9800 - val_accuracy: 0.5000 - val_f1_score: 0.6061 - val_loss: 1.1422 - val_sensitivity: 0.7692 - val_specificity: 0.2308\nEpoch 10/1000\n\nEpoch 10: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 0.9612 - f1_score: 0.9615 - loss: 0.2577 - sensitivity: 0.9434 - specificity: 0.9800 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 2.3106 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 11/1000\n\nEpoch 11: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 0.9806 - f1_score: 0.9815 - loss: 0.2075 - sensitivity: 1.0000 - specificity: 0.9600 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.2162 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 12/1000\n\nEpoch 12: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 0.9806 - f1_score: 0.9808 - loss: 0.1789 - sensitivity: 0.9623 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6842 - val_loss: 1.8575 - val_sensitivity: 1.0000 - val_specificity: 0.0769\nEpoch 13/1000\n\nEpoch 13: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 0.9806 - f1_score: 0.9815 - loss: 0.1358 - sensitivity: 1.0000 - specificity: 0.9600 - val_accuracy: 0.5769 - val_f1_score: 0.7027 - val_loss: 2.0619 - val_sensitivity: 1.0000 - val_specificity: 0.1538\nEpoch 14/1000\n\nEpoch 14: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.0992 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 1.3940 - val_sensitivity: 0.8462 - val_specificity: 0.3077\nEpoch 15/1000\n\nEpoch 15: val_loss did not improve from 0.68265\n4/4 - 0s - 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0752 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.7222 - val_loss: 1.9212 - val_sensitivity: 1.0000 - val_specificity: 0.2308\nEpoch 16/1000\n\nEpoch 16: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0475 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6471 - val_loss: 1.9541 - val_sensitivity: 0.8462 - val_specificity: 0.2308\nEpoch 17/1000\n\nEpoch 17: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0345 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6471 - val_loss: 1.9331 - val_sensitivity: 0.8462 - val_specificity: 0.2308\nEpoch 18/1000\n\nEpoch 18: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0249 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6250 - val_loss: 1.7083 - val_sensitivity: 0.7692 - val_specificity: 0.3077\nEpoch 19/1000\n\nEpoch 19: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0211 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 1.9195 - val_sensitivity: 0.8462 - val_specificity: 0.3077\nEpoch 20/1000\n\nEpoch 20: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0167 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6857 - val_loss: 2.2222 - val_sensitivity: 0.9231 - val_specificity: 0.2308\nEpoch 21/1000\n\nEpoch 21: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0122 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7760 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 22/1000\n\nEpoch 22: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0116 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 2.0534 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 23/1000\n\nEpoch 23: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0082 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6250 - val_loss: 2.1734 - val_sensitivity: 0.7692 - val_specificity: 0.3077\nEpoch 24/1000\n\nEpoch 24: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0068 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 2.0016 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 25/1000\n\nEpoch 25: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0057 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8857 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 26/1000\n\nEpoch 26: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0052 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8478 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 27/1000\n\nEpoch 27: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0040 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.9234 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 28/1000\n\nEpoch 28: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0037 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6250 - val_loss: 2.0258 - val_sensitivity: 0.7692 - val_specificity: 0.3077\nEpoch 29/1000\n\nEpoch 29: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0034 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 2.1309 - val_sensitivity: 0.8462 - val_specificity: 0.3077\nEpoch 30/1000\n\nEpoch 30: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0034 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 2.0115 - val_sensitivity: 0.8462 - val_specificity: 0.3077\nEpoch 31/1000\n\nEpoch 31: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0024 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 1.8927 - val_sensitivity: 0.8462 - val_specificity: 0.3846\nEpoch 32/1000\n\nEpoch 32: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.8093 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 33/1000\n\nEpoch 33: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8267 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 34/1000\n\nEpoch 34: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8778 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 35/1000\n\nEpoch 35: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.9108 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 36/1000\n\nEpoch 36: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8827 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 37/1000\n\nEpoch 37: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8296 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 38/1000\n\nEpoch 38: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8294 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 39/1000\n\nEpoch 39: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8321 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 40/1000\n\nEpoch 40: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8053 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 41/1000\n\nEpoch 41: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7518 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 42/1000\n\nEpoch 42: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7425 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 43/1000\n\nEpoch 43: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7712 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 44/1000\n\nEpoch 44: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8417 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 45/1000\n\nEpoch 45: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.8072 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 46/1000\n\nEpoch 46: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7608 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 47/1000\n\nEpoch 47: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7320 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 48/1000\n\nEpoch 48: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.6325e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.6978 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 49/1000\n\nEpoch 49: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.0225e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7184 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 50/1000\n\nEpoch 50: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3124e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7440 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 51/1000\n\nEpoch 51: val_loss did not improve from 0.68265\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.7176e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7426 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 52/1000\n\nEpoch 52: val_loss did not improve from 0.68265\n4/4 - 0s - 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3389e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7577 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 53/1000\n\nEpoch 53: val_loss did not improve from 0.68265\n4/4 - 0s - 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.8511e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.7053 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 54/1000\n\nEpoch 54: val_loss did not improve from 0.68265\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0518e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6600 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 55/1000\n\nEpoch 55: val_loss did not improve from 0.68265\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.7457e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6411 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 56/1000\n\nEpoch 56: val_loss did not improve from 0.68265\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8878e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6803 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 57/1000\n\nEpoch 57: val_loss did not improve from 0.68265\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.4988e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6806 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 58/1000\n\nEpoch 58: val_loss did not improve from 0.68265\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8396e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6754 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 59/1000\n\nEpoch 59: val_loss did not improve from 0.68265\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3480e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6554 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 60/1000\n\nEpoch 60: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6001e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6702 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 61/1000\n\nEpoch 61: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.7724e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7239 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 62/1000\n\nEpoch 62: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6359e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7346 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 63/1000\n\nEpoch 63: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1476e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7444 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 64/1000\n\nEpoch 64: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8281e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7453 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 65/1000\n\nEpoch 65: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2798e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7355 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 66/1000\n\nEpoch 66: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7037e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6771 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 67/1000\n\nEpoch 67: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.6720e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6263 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 68/1000\n\nEpoch 68: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9640e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6184 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 69/1000\n\nEpoch 69: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0595e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6269 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 70/1000\n\nEpoch 70: val_loss did not improve from 0.68265\n4/4 - 0s - 48ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2877e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6397 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 71/1000\n\nEpoch 71: val_loss did not improve from 0.68265\n4/4 - 0s - 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5193e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6651 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 72/1000\n\nEpoch 72: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9613e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6882 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 73/1000\n\nEpoch 73: val_loss did not improve from 0.68265\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9240e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6930 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 74/1000\n\nEpoch 74: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2512e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6691 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 75/1000\n\nEpoch 75: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6240e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6811 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 76/1000\n\nEpoch 76: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5186e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6792 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 77/1000\n\nEpoch 77: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4898e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6515 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 78/1000\n\nEpoch 78: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5574e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6345 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 79/1000\n\nEpoch 79: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9590e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6170 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 80/1000\n\nEpoch 80: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4701e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6357 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 81/1000\n\nEpoch 81: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0584e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6571 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 82/1000\n\nEpoch 82: val_loss did not improve from 0.68265\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2022e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6824 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 83/1000\n\nEpoch 83: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3582e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6889 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 84/1000\n\nEpoch 84: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9889e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6912 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 85/1000\n\nEpoch 85: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7767e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6819 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 86/1000\n\nEpoch 86: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9587e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6501 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 87/1000\n\nEpoch 87: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7939e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6427 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 88/1000\n\nEpoch 88: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8048e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6479 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 89/1000\n\nEpoch 89: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5403e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6526 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 90/1000\n\nEpoch 90: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7530e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6623 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 91/1000\n\nEpoch 91: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8342e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6561 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 92/1000\n\nEpoch 92: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6337e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6391 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 93/1000\n\nEpoch 93: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6371e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6473 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 94/1000\n\nEpoch 94: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6809e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6387 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 95/1000\n\nEpoch 95: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4973e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6441 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 96/1000\n\nEpoch 96: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6313e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6630 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 97/1000\n\nEpoch 97: val_loss did not improve from 0.68265\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8054e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7009 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 98/1000\n\nEpoch 98: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4359e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7578 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 99/1000\n\nEpoch 99: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5980e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7595 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 100/1000\n\nEpoch 100: val_loss did not improve from 0.68265\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4605e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.7261 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 101/1000\n\nEpoch 101: val_loss did not improve from 0.68265\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3578e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.6885 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 101: early stopping\nRestoring model weights from the end of the best epoch: 1.\n  Eval (best model fold3): accuracy=0.4741, f1_score=0.5103, loss=0.7064, sensitivity=0.5692, specificity=0.3857\n\n\n=== Fold 4/5 ===\n  Train: (103, 22, 500), (103,)\n  Val:   (26, 22, 500),   (26,)\nEpoch 1/1000\n\nEpoch 1: val_loss improved from inf to 0.70331, saving model to best_model_fold4.keras\n4/4 - 19s - 5s/step - accuracy: 0.5049 - f1_score: 0.2154 - loss: 0.7026 - sensitivity: 0.1346 - specificity: 0.8824 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.7033 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 2/1000\n\nEpoch 2: val_loss did not improve from 0.70331\n4/4 - 0s - 46ms/step - accuracy: 0.5340 - f1_score: 0.6620 - loss: 0.6787 - sensitivity: 0.9038 - specificity: 0.1569 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 1.0561 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 3/1000\n\nEpoch 3: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.5825 - f1_score: 0.7075 - loss: 0.6436 - sensitivity: 1.0000 - specificity: 0.1569 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.7573 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 4/1000\n\nEpoch 4: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.8155 - f1_score: 0.8190 - loss: 0.6346 - sensitivity: 0.8269 - specificity: 0.8039 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.8649 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 5/1000\n\nEpoch 5: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.6893 - f1_score: 0.7576 - loss: 0.6058 - sensitivity: 0.9615 - specificity: 0.4118 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 1.2840 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 6/1000\n\nEpoch 6: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 0.6602 - f1_score: 0.7445 - loss: 0.5790 - sensitivity: 0.9808 - specificity: 0.3333 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.8496 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 7/1000\n\nEpoch 7: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.9029 - f1_score: 0.9000 - loss: 0.5597 - sensitivity: 0.8654 - specificity: 0.9412 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.8856 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 8/1000\n\nEpoch 8: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.7961 - f1_score: 0.8235 - loss: 0.5091 - sensitivity: 0.9423 - specificity: 0.6471 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 1.1758 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 9/1000\n\nEpoch 9: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.8932 - f1_score: 0.9009 - loss: 0.4269 - sensitivity: 0.9615 - specificity: 0.8235 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 0.7448 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 10/1000\n\nEpoch 10: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 0.9029 - f1_score: 0.8936 - loss: 0.3838 - sensitivity: 0.8077 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 1.3480 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 11/1000\n\nEpoch 11: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 0.8058 - f1_score: 0.8387 - loss: 0.3964 - sensitivity: 1.0000 - specificity: 0.6078 - val_accuracy: 0.5769 - val_f1_score: 0.7027 - val_loss: 0.9878 - val_sensitivity: 0.9286 - val_specificity: 0.1667\nEpoch 12/1000\n\nEpoch 12: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 0.9515 - f1_score: 0.9515 - loss: 0.2635 - sensitivity: 0.9423 - specificity: 0.9608 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 0.8230 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 13/1000\n\nEpoch 13: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 0.9612 - f1_score: 0.9608 - loss: 0.2353 - sensitivity: 0.9423 - specificity: 0.9804 - val_accuracy: 0.6154 - val_f1_score: 0.7222 - val_loss: 1.0767 - val_sensitivity: 0.9286 - val_specificity: 0.2500\nEpoch 14/1000\n\nEpoch 14: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.9806 - f1_score: 0.9808 - loss: 0.1917 - sensitivity: 0.9808 - specificity: 0.9804 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 0.9718 - val_sensitivity: 0.7857 - val_specificity: 0.4167\nEpoch 15/1000\n\nEpoch 15: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1390 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.7027 - val_loss: 1.2885 - val_sensitivity: 0.9286 - val_specificity: 0.1667\nEpoch 16/1000\n\nEpoch 16: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 0.9709 - f1_score: 0.9720 - loss: 0.1255 - sensitivity: 1.0000 - specificity: 0.9412 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 1.1353 - val_sensitivity: 0.5714 - val_specificity: 0.5000\nEpoch 17/1000\n\nEpoch 17: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1106 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 1.3420 - val_sensitivity: 0.7857 - val_specificity: 0.3333\nEpoch 18/1000\n\nEpoch 18: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0705 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 1.2561 - val_sensitivity: 0.7143 - val_specificity: 0.5000\nEpoch 19/1000\n\nEpoch 19: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0537 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7273 - val_loss: 1.4160 - val_sensitivity: 0.8571 - val_specificity: 0.4167\nEpoch 20/1000\n\nEpoch 20: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0381 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 1.5300 - val_sensitivity: 0.7857 - val_specificity: 0.3333\nEpoch 21/1000\n\nEpoch 21: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0274 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.5113 - val_sensitivity: 0.7143 - val_specificity: 0.4167\nEpoch 22/1000\n\nEpoch 22: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0248 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.5074 - val_sensitivity: 0.7143 - val_specificity: 0.4167\nEpoch 23/1000\n\nEpoch 23: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0191 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.7059 - val_loss: 1.6219 - val_sensitivity: 0.8571 - val_specificity: 0.3333\nEpoch 24/1000\n\nEpoch 24: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0158 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 1.4610 - val_sensitivity: 0.7857 - val_specificity: 0.4167\nEpoch 25/1000\n\nEpoch 25: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0117 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.4434 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 26/1000\n\nEpoch 26: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0099 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 1.5184 - val_sensitivity: 0.7857 - val_specificity: 0.4167\nEpoch 27/1000\n\nEpoch 27: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0087 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7273 - val_loss: 1.6070 - val_sensitivity: 0.8571 - val_specificity: 0.4167\nEpoch 28/1000\n\nEpoch 28: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0075 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.5802 - val_sensitivity: 0.7143 - val_specificity: 0.4167\nEpoch 29/1000\n\nEpoch 29: val_loss did not improve from 0.70331\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0056 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.5875 - val_sensitivity: 0.7143 - val_specificity: 0.4167\nEpoch 30/1000\n\nEpoch 30: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0053 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.6280 - val_sensitivity: 0.7143 - val_specificity: 0.4167\nEpoch 31/1000\n\nEpoch 31: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0045 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.6612 - val_sensitivity: 0.7143 - val_specificity: 0.4167\nEpoch 32/1000\n\nEpoch 32: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0041 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.6608 - val_sensitivity: 0.7143 - val_specificity: 0.4167\nEpoch 33/1000\n\nEpoch 33: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0039 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6750 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 34/1000\n\nEpoch 34: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0036 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.7230 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 35/1000\n\nEpoch 35: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0031 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.7369 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 36/1000\n\nEpoch 36: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0029 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.7447 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 37/1000\n\nEpoch 37: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0027 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.7369 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 38/1000\n\nEpoch 38: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.7152 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 39/1000\n\nEpoch 39: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 1.6918 - val_sensitivity: 0.6429 - val_specificity: 0.4167\nEpoch 40/1000\n\nEpoch 40: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6797 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 41/1000\n\nEpoch 41: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6562 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 42/1000\n\nEpoch 42: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6231 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 43/1000\n\nEpoch 43: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6058 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 44/1000\n\nEpoch 44: val_loss did not improve from 0.70331\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6090 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 45/1000\n\nEpoch 45: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6183 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 46/1000\n\nEpoch 46: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6264 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 47/1000\n\nEpoch 47: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6330 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 48/1000\n\nEpoch 48: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6380 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 49/1000\n\nEpoch 49: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6456 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 50/1000\n\nEpoch 50: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6578 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 51/1000\n\nEpoch 51: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6811 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 52/1000\n\nEpoch 52: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7016 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 53/1000\n\nEpoch 53: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7145 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 54/1000\n\nEpoch 54: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7290 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 55/1000\n\nEpoch 55: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7299 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 56/1000\n\nEpoch 56: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7271 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 57/1000\n\nEpoch 57: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1771e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7245 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 58/1000\n\nEpoch 58: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6580e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7126 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 59/1000\n\nEpoch 59: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1617e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6969 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 60/1000\n\nEpoch 60: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3766e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6908 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 61/1000\n\nEpoch 61: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5753e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6896 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 62/1000\n\nEpoch 62: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.2844e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6815 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 63/1000\n\nEpoch 63: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.1646e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6792 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 64/1000\n\nEpoch 64: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6685e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6806 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 65/1000\n\nEpoch 65: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4204e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6832 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 66/1000\n\nEpoch 66: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.9109e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6878 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 67/1000\n\nEpoch 67: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.3994e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6881 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 68/1000\n\nEpoch 68: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8378e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6896 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 69/1000\n\nEpoch 69: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6115e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6928 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 70/1000\n\nEpoch 70: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.7150e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6969 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 71/1000\n\nEpoch 71: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6253e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7022 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 72/1000\n\nEpoch 72: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5139e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7028 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 73/1000\n\nEpoch 73: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1745e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7030 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 74/1000\n\nEpoch 74: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9443e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.6999 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 75/1000\n\nEpoch 75: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0263e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7009 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 76/1000\n\nEpoch 76: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9971e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7046 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 77/1000\n\nEpoch 77: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2846e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7092 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 78/1000\n\nEpoch 78: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5692e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7094 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 79/1000\n\nEpoch 79: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6320e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7096 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 80/1000\n\nEpoch 80: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3917e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7091 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 81/1000\n\nEpoch 81: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2969e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7072 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 82/1000\n\nEpoch 82: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3524e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7069 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 83/1000\n\nEpoch 83: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6262e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7146 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 84/1000\n\nEpoch 84: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7305e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7210 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 85/1000\n\nEpoch 85: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7683e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7221 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 86/1000\n\nEpoch 86: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4449e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7226 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 87/1000\n\nEpoch 87: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7399e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7212 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 88/1000\n\nEpoch 88: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3840e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7252 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 89/1000\n\nEpoch 89: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1719e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7321 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 90/1000\n\nEpoch 90: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4645e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7376 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 91/1000\n\nEpoch 91: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0287e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7379 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 92/1000\n\nEpoch 92: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4362e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7345 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 93/1000\n\nEpoch 93: val_loss did not improve from 0.70331\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8912e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7268 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 94/1000\n\nEpoch 94: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9025e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7241 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 95/1000\n\nEpoch 95: val_loss did not improve from 0.70331\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2137e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7261 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 96/1000\n\nEpoch 96: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8982e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7270 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 97/1000\n\nEpoch 97: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4782e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7311 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 98/1000\n\nEpoch 98: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7192e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7353 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 99/1000\n\nEpoch 99: val_loss did not improve from 0.70331\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7008e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7405 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 100/1000\n\nEpoch 100: val_loss did not improve from 0.70331\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3005e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7469 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 101/1000\n\nEpoch 101: val_loss did not improve from 0.70331\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3375e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6207 - val_loss: 1.7539 - val_sensitivity: 0.6429 - val_specificity: 0.5000\nEpoch 101: early stopping\nRestoring model weights from the end of the best epoch: 1.\n  Eval (best model fold4): accuracy=0.4963, f1_score=0.6566, loss=0.7615, sensitivity=1.0000, specificity=0.0286\n\n\n=== Fold 5/5 ===\n  Train: (104, 22, 500), (104,)\n  Val:   (25, 22, 500),   (25,)\nEpoch 1/1000\n\nEpoch 1: val_loss improved from inf to 0.88951, saving model to best_model_fold5.keras\n4/4 - 19s - 5s/step - accuracy: 0.5962 - f1_score: 0.6316 - loss: 0.6766 - sensitivity: 0.6792 - specificity: 0.5098 - val_accuracy: 0.5200 - val_f1_score: 0.6842 - val_loss: 0.8895 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 2/1000\n\nEpoch 2: val_loss improved from 0.88951 to 0.84329, saving model to best_model_fold5.keras\n4/4 - 0s - 53ms/step - accuracy: 0.6154 - f1_score: 0.7260 - loss: 0.6407 - sensitivity: 1.0000 - specificity: 0.2157 - val_accuracy: 0.5200 - val_f1_score: 0.6842 - val_loss: 0.8433 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 3/1000\n\nEpoch 3: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 0.7404 - f1_score: 0.7939 - loss: 0.5922 - sensitivity: 0.9811 - specificity: 0.4902 - val_accuracy: 0.3600 - val_f1_score: 0.3333 - val_loss: 0.8481 - val_sensitivity: 0.3077 - val_specificity: 0.4167\nEpoch 4/1000\n\nEpoch 4: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 0.8558 - f1_score: 0.8421 - loss: 0.5595 - sensitivity: 0.7547 - specificity: 0.9608 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 0.8765 - val_sensitivity: 0.6154 - val_specificity: 0.2500\nEpoch 5/1000\n\nEpoch 5: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 0.9231 - f1_score: 0.9298 - loss: 0.4919 - sensitivity: 1.0000 - specificity: 0.8431 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 0.9018 - val_sensitivity: 0.6154 - val_specificity: 0.2500\nEpoch 6/1000\n\nEpoch 6: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 0.9519 - f1_score: 0.9541 - loss: 0.4151 - sensitivity: 0.9811 - specificity: 0.9216 - val_accuracy: 0.3600 - val_f1_score: 0.2000 - val_loss: 1.0775 - val_sensitivity: 0.1538 - val_specificity: 0.5833\nEpoch 7/1000\n\nEpoch 7: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 0.8942 - f1_score: 0.8866 - loss: 0.3648 - sensitivity: 0.8113 - specificity: 0.9804 - val_accuracy: 0.5600 - val_f1_score: 0.6667 - val_loss: 1.0100 - val_sensitivity: 0.8462 - val_specificity: 0.2500\nEpoch 8/1000\n\nEpoch 8: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 0.9423 - f1_score: 0.9455 - loss: 0.2900 - sensitivity: 0.9811 - specificity: 0.9020 - val_accuracy: 0.4000 - val_f1_score: 0.4444 - val_loss: 0.9816 - val_sensitivity: 0.4615 - val_specificity: 0.3333\nEpoch 9/1000\n\nEpoch 9: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 0.9808 - f1_score: 0.9815 - loss: 0.2212 - sensitivity: 1.0000 - specificity: 0.9608 - val_accuracy: 0.3600 - val_f1_score: 0.2727 - val_loss: 1.1076 - val_sensitivity: 0.2308 - val_specificity: 0.5000\nEpoch 10/1000\n\nEpoch 10: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 0.9423 - f1_score: 0.9400 - loss: 0.2248 - sensitivity: 0.8868 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.5625 - val_loss: 1.2530 - val_sensitivity: 0.6923 - val_specificity: 0.1667\nEpoch 11/1000\n\nEpoch 11: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 0.9904 - f1_score: 0.9907 - loss: 0.1655 - sensitivity: 1.0000 - specificity: 0.9804 - val_accuracy: 0.4800 - val_f1_score: 0.2353 - val_loss: 1.5989 - val_sensitivity: 0.1538 - val_specificity: 0.8333\nEpoch 12/1000\n\nEpoch 12: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 0.9615 - f1_score: 0.9608 - loss: 0.1663 - sensitivity: 0.9245 - specificity: 1.0000 - val_accuracy: 0.5200 - val_f1_score: 0.6471 - val_loss: 1.3585 - val_sensitivity: 0.8462 - val_specificity: 0.1667\nEpoch 13/1000\n\nEpoch 13: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 0.9327 - f1_score: 0.9381 - loss: 0.1577 - sensitivity: 1.0000 - specificity: 0.8627 - val_accuracy: 0.4000 - val_f1_score: 0.2857 - val_loss: 1.5406 - val_sensitivity: 0.2308 - val_specificity: 0.5833\nEpoch 14/1000\n\nEpoch 14: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 0.9327 - f1_score: 0.9293 - loss: 0.1673 - sensitivity: 0.8679 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.2727 - val_loss: 1.5691 - val_sensitivity: 0.2308 - val_specificity: 0.5000\nEpoch 15/1000\n\nEpoch 15: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 0.9904 - f1_score: 0.9907 - loss: 0.0771 - sensitivity: 1.0000 - specificity: 0.9804 - val_accuracy: 0.5200 - val_f1_score: 0.6250 - val_loss: 1.6123 - val_sensitivity: 0.7692 - val_specificity: 0.2500\nEpoch 16/1000\n\nEpoch 16: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0689 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.2857 - val_loss: 1.6517 - val_sensitivity: 0.2308 - val_specificity: 0.5833\nEpoch 17/1000\n\nEpoch 17: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0659 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.4711 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 18/1000\n\nEpoch 18: val_loss did not improve from 0.84329\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0436 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5517 - val_loss: 1.5793 - val_sensitivity: 0.6154 - val_specificity: 0.3333\nEpoch 19/1000\n\nEpoch 19: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0289 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.2857 - val_loss: 1.6331 - val_sensitivity: 0.2308 - val_specificity: 0.5833\nEpoch 20/1000\n\nEpoch 20: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0360 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.4803 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 21/1000\n\nEpoch 21: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0252 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5600 - val_f1_score: 0.6452 - val_loss: 1.5081 - val_sensitivity: 0.7692 - val_specificity: 0.3333\nEpoch 22/1000\n\nEpoch 22: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0260 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.2727 - val_loss: 1.3753 - val_sensitivity: 0.2308 - val_specificity: 0.5000\nEpoch 23/1000\n\nEpoch 23: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0243 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.3657 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 24/1000\n\nEpoch 24: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0132 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5600 - val_f1_score: 0.6207 - val_loss: 1.4795 - val_sensitivity: 0.6923 - val_specificity: 0.4167\nEpoch 25/1000\n\nEpoch 25: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0140 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 1.4594 - val_sensitivity: 0.6154 - val_specificity: 0.4167\nEpoch 26/1000\n\nEpoch 26: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0085 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4426 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 27/1000\n\nEpoch 27: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0075 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4515 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 28/1000\n\nEpoch 28: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0064 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 1.4736 - val_sensitivity: 0.6154 - val_specificity: 0.4167\nEpoch 29/1000\n\nEpoch 29: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0052 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4788 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 30/1000\n\nEpoch 30: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0044 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4854 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 31/1000\n\nEpoch 31: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0042 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4815 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 32/1000\n\nEpoch 32: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0034 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4710 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 33/1000\n\nEpoch 33: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0034 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4602 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 34/1000\n\nEpoch 34: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0030 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4480 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 35/1000\n\nEpoch 35: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0027 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5200 - val_f1_score: 0.5714 - val_loss: 1.4417 - val_sensitivity: 0.6154 - val_specificity: 0.4167\nEpoch 36/1000\n\nEpoch 36: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0028 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4319 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 37/1000\n\nEpoch 37: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4236 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 38/1000\n\nEpoch 38: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4154 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 39/1000\n\nEpoch 39: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0021 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4060 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 40/1000\n\nEpoch 40: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.4025 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 41/1000\n\nEpoch 41: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3990 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 42/1000\n\nEpoch 42: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3957 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 43/1000\n\nEpoch 43: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3950 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 44/1000\n\nEpoch 44: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3956 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 45/1000\n\nEpoch 45: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3949 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 46/1000\n\nEpoch 46: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3923 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 47/1000\n\nEpoch 47: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3905 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 48/1000\n\nEpoch 48: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3832 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 49/1000\n\nEpoch 49: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3806 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 50/1000\n\nEpoch 50: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3794 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 51/1000\n\nEpoch 51: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3798 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 52/1000\n\nEpoch 52: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3795 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 53/1000\n\nEpoch 53: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3785 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 54/1000\n\nEpoch 54: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3780 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 55/1000\n\nEpoch 55: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3786 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 56/1000\n\nEpoch 56: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3780 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 57/1000\n\nEpoch 57: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3754 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 58/1000\n\nEpoch 58: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3762 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 59/1000\n\nEpoch 59: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3779 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 60/1000\n\nEpoch 60: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.5502e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3814 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 61/1000\n\nEpoch 61: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.9849e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3838 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 62/1000\n\nEpoch 62: val_loss did not improve from 0.84329\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.8428e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3868 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 63/1000\n\nEpoch 63: val_loss did not improve from 0.84329\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5629e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3903 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 64/1000\n\nEpoch 64: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.4394e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3909 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 65/1000\n\nEpoch 65: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1338e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3877 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 66/1000\n\nEpoch 66: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5449e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3907 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 67/1000\n\nEpoch 67: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6317e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3846 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 68/1000\n\nEpoch 68: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.9474e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3795 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 69/1000\n\nEpoch 69: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.8759e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3803 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 70/1000\n\nEpoch 70: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.3826e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3854 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 71/1000\n\nEpoch 71: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4018e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3842 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 72/1000\n\nEpoch 72: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8787e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3788 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 73/1000\n\nEpoch 73: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5866e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3757 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 74/1000\n\nEpoch 74: val_loss did not improve from 0.84329\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6265e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3718 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 75/1000\n\nEpoch 75: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2851e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3725 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 76/1000\n\nEpoch 76: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6347e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3711 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 77/1000\n\nEpoch 77: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3368e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3695 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 78/1000\n\nEpoch 78: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8013e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3679 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 79/1000\n\nEpoch 79: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8679e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3676 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 80/1000\n\nEpoch 80: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5494e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3687 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 81/1000\n\nEpoch 81: val_loss did not improve from 0.84329\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.7591e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3711 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 82/1000\n\nEpoch 82: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4476e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3703 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 83/1000\n\nEpoch 83: val_loss did not improve from 0.84329\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3699e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3688 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 84/1000\n\nEpoch 84: val_loss did not improve from 0.84329\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3709e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3673 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 85/1000\n\nEpoch 85: val_loss did not improve from 0.84329\n4/4 - 0s - 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3030e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3674 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 86/1000\n\nEpoch 86: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0853e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3674 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 87/1000\n\nEpoch 87: val_loss did not improve from 0.84329\n4/4 - 0s - 48ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9549e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3699 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 88/1000\n\nEpoch 88: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8145e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3720 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 89/1000\n\nEpoch 89: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9878e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3728 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 90/1000\n\nEpoch 90: val_loss did not improve from 0.84329\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0275e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3727 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 91/1000\n\nEpoch 91: val_loss did not improve from 0.84329\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.6608e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3760 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 92/1000\n\nEpoch 92: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3978e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3785 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 93/1000\n\nEpoch 93: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5145e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3775 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 94/1000\n\nEpoch 94: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1998e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3743 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 95/1000\n\nEpoch 95: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0669e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3732 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 96/1000\n\nEpoch 96: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1842e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3721 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 97/1000\n\nEpoch 97: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1864e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3738 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 98/1000\n\nEpoch 98: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9102e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3771 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 99/1000\n\nEpoch 99: val_loss did not improve from 0.84329\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9296e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3783 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 100/1000\n\nEpoch 100: val_loss did not improve from 0.84329\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4261e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3804 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 101/1000\n\nEpoch 101: val_loss did not improve from 0.84329\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0820e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3852 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 102/1000\n\nEpoch 102: val_loss did not improve from 0.84329\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8370e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4800 - val_f1_score: 0.5185 - val_loss: 1.3824 - val_sensitivity: 0.5385 - val_specificity: 0.4167\nEpoch 102: early stopping\nRestoring model weights from the end of the best epoch: 2.\n  Eval (best model fold5): accuracy=0.5111, f1_score=0.6633, loss=0.8429, sensitivity=1.0000, specificity=0.0571\n\n=== Resumen Cross‐Validation ===\naccuracy    : 0.4800 ± 0.0253\nf1_score    : 0.5869 ± 0.0793\nloss        : 0.7549 ± 0.0530\nsensitivity : 0.7969 ± 0.2171\nspecificity : 0.1857 ± 0.1619\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# --- Parámetros ---\nN_SPLITS     = 5\nRANDOM_STATE = 42\nEPOCHS       = 1000\nFS           = 250.0\nMODEL_PATH   = \"/kaggle/input/best-models-sbjte/best_hp_model5.keras\"\n\n# Métricas a trackear\nmetrics = ['accuracy', 'specificity', 'sensitivity', 'f1_score']\n\n# Diccionarios para acumular resultados\ntrain_eval = {m: [] for m in metrics}\nval_eval   = {m: [] for m in metrics}\ntest_eval  = {m: [] for m in metrics}\n\n# Callbacks que usamos en cada fold\ndef get_callbacks(fold):\n    return [\n        EarlyStopping(\n            monitor=\"val_f1_score\",\n            mode=\"max\",\n            patience=100,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        CSVLogger(f\"continued_training_fold{fold}.log\", append=True),\n        ModelCheckpoint(\n            filepath=f\"best_model_fold{fold}.keras\",\n            monitor=\"val_accuracy\",\n            mode=\"max\",\n            save_best_only=True,\n            verbose=1\n        ),\n    ]\n\n# --- Carga de datos ---\ndb = Dataset_2a('/kaggle/input/dataset-2a')\nX_full, y_full = load_BCICIV2a(db, sbj=5, mode='training',   fs=FS)\nX_test, y_test = load_BCICIV2a(db, sbj=5, mode='evaluation', fs=FS)\n\nprint(f\"Training set:   {X_full.shape}, {y_full.shape}\")\nprint(f\"Evaluation set: {X_test.shape},  {y_test.shape}\")\n\n# Preparamos el Stratified K-Fold\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X_full, y_full), start=1):\n    print(f\"\\n=== Fold {fold}/{N_SPLITS} ===\")\n    X_train, y_train = X_full[train_idx], y_full[train_idx]\n    X_val,   y_val   = X_full[val_idx],   y_full[val_idx]\n\n    # 1) Cargar modelo con pesos y compilación original\n    model = load_model(MODEL_PATH, compile=True)\n\n    # 2) Continuar entrenamiento en este fold\n    model.fit(\n        x=X_train, y=y_train,\n        validation_data=(X_val, y_val),\n        epochs=EPOCHS,\n        callbacks=get_callbacks(fold),\n        verbose=2\n    )\n# /kaggle/input/cross-validation/best_model_fold1.keras\n    # 3) Cargar el mejor modelo guardado por ModelCheckpoint\n    best_model = load_model(f\"/kaggle/input/cross-validation/best_model_fold{fold}.keras\", compile=True)\n\n    # 4) Evaluar en train, validación y evaluación final\n    res_tr   = best_model.evaluate(X_train, y_train, return_dict=True, verbose=0)\n    res_va   = best_model.evaluate(X_val,   y_val,   return_dict=True, verbose=0)\n    res_test = best_model.evaluate(X_test,  y_test,  return_dict=True, verbose=0)\n\n    # 5) Almacenar cada métrica\n    for m in metrics:\n        train_eval[m].append( res_tr[m] )\n        val_eval[m].append(   res_va[m] )\n        test_eval[m].append(  res_test[m] )\n\n# --- Función para mostrar resumen ---\ndef summarize(eval_dict, title):\n    print(f\"\\n--- {title} ---\")\n    for m, vals in eval_dict.items():\n        mean = np.mean(vals)\n        std  = np.std(vals, ddof=1)\n        print(f\"{m:12s}: {mean:.4f} ± {std:.4f}\")\n\n# Imprimimos los promedios ± desviaciones estándar\nsummarize(train_eval, \"TRAIN   (best model por fold)\")\nsummarize(val_eval,   \"VALIDATION (best model por fold)\")\nsummarize(test_eval,  \"EVALUATION  (best model por fold)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T20:46:22.116670Z","iopub.execute_input":"2025-06-19T20:46:22.117395Z","iopub.status.idle":"2025-06-19T20:50:27.895281Z","shell.execute_reply.started":"2025-06-19T20:46:22.117368Z","shell.execute_reply":"2025-06-19T20:50:27.894392Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Training set:   (129, 22, 500), (129,)\nEvaluation set: (135, 22, 500),  (135,)\n\n=== Fold 1/5 ===\nEpoch 1/1000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\nW0000 00:00:1750365996.933563     248 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366002.417528     248 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366008.594575     247 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.50000, saving model to best_model_fold1.keras\n4/4 - 18s - 5s/step - accuracy: 0.5437 - f1_score: 0.5983 - loss: 0.6891 - sensitivity: 0.6604 - specificity: 0.4200 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.7040 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 2/1000\n\nEpoch 2: val_accuracy did not improve from 0.50000\n4/4 - 0s - 42ms/step - accuracy: 0.8350 - f1_score: 0.8522 - loss: 0.6284 - sensitivity: 0.9245 - specificity: 0.7400 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.1915 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 3/1000\n\nEpoch 3: val_accuracy did not improve from 0.50000\n4/4 - 0s - 43ms/step - accuracy: 0.5922 - f1_score: 0.7162 - loss: 0.5999 - sensitivity: 1.0000 - specificity: 0.1600 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.9170 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 4/1000\n\nEpoch 4: val_accuracy improved from 0.50000 to 0.57692, saving model to best_model_fold1.keras\n4/4 - 0s - 57ms/step - accuracy: 0.7961 - f1_score: 0.8000 - loss: 0.5503 - sensitivity: 0.7925 - specificity: 0.8000 - val_accuracy: 0.5769 - val_f1_score: 0.6857 - val_loss: 0.8054 - val_sensitivity: 0.9231 - val_specificity: 0.2308\nEpoch 5/1000\n\nEpoch 5: val_accuracy did not improve from 0.57692\n4/4 - 0s - 42ms/step - accuracy: 0.8058 - f1_score: 0.8387 - loss: 0.4999 - sensitivity: 0.9811 - specificity: 0.6200 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.0565 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 6/1000\n\nEpoch 6: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 0.8350 - f1_score: 0.8381 - loss: 0.4352 - sensitivity: 0.8302 - specificity: 0.8400 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 0.8838 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 7/1000\n\nEpoch 7: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 0.8835 - f1_score: 0.8750 - loss: 0.3752 - sensitivity: 0.7925 - specificity: 0.9800 - val_accuracy: 0.4615 - val_f1_score: 0.6111 - val_loss: 1.1887 - val_sensitivity: 0.8462 - val_specificity: 0.0769\nEpoch 8/1000\n\nEpoch 8: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 0.9029 - f1_score: 0.9138 - loss: 0.2934 - sensitivity: 1.0000 - specificity: 0.8000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.0696 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 9/1000\n\nEpoch 9: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 0.8932 - f1_score: 0.8889 - loss: 0.2729 - sensitivity: 0.8302 - specificity: 0.9600 - val_accuracy: 0.5000 - val_f1_score: 0.6286 - val_loss: 1.5940 - val_sensitivity: 0.8462 - val_specificity: 0.1538\nEpoch 10/1000\n\nEpoch 10: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 0.9612 - f1_score: 0.9630 - loss: 0.2057 - sensitivity: 0.9811 - specificity: 0.9400 - val_accuracy: 0.5000 - val_f1_score: 0.6061 - val_loss: 1.4455 - val_sensitivity: 0.7692 - val_specificity: 0.2308\nEpoch 11/1000\n\nEpoch 11: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.1516 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.4231 - val_f1_score: 0.4828 - val_loss: 1.3618 - val_sensitivity: 0.5385 - val_specificity: 0.3077\nEpoch 12/1000\n\nEpoch 12: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1238 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.5000 - val_loss: 1.6264 - val_sensitivity: 0.6154 - val_specificity: 0.1538\nEpoch 13/1000\n\nEpoch 13: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.0957 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.3846 - val_f1_score: 0.5000 - val_loss: 1.7235 - val_sensitivity: 0.6154 - val_specificity: 0.1538\nEpoch 14/1000\n\nEpoch 14: val_accuracy did not improve from 0.57692\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0629 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.4286 - val_loss: 1.7504 - val_sensitivity: 0.4615 - val_specificity: 0.3077\nEpoch 15/1000\n\nEpoch 15: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0458 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4828 - val_loss: 1.9016 - val_sensitivity: 0.5385 - val_specificity: 0.3077\nEpoch 16/1000\n\nEpoch 16: val_accuracy did not improve from 0.57692\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0336 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4828 - val_loss: 1.9841 - val_sensitivity: 0.5385 - val_specificity: 0.3077\nEpoch 17/1000\n\nEpoch 17: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0229 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4828 - val_loss: 1.9487 - val_sensitivity: 0.5385 - val_specificity: 0.3077\nEpoch 18/1000\n\nEpoch 18: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0190 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3462 - val_f1_score: 0.3704 - val_loss: 1.9687 - val_sensitivity: 0.3846 - val_specificity: 0.3077\nEpoch 19/1000\n\nEpoch 19: val_accuracy did not improve from 0.57692\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0121 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5806 - val_loss: 2.1686 - val_sensitivity: 0.6923 - val_specificity: 0.3077\nEpoch 20/1000\n\nEpoch 20: val_accuracy did not improve from 0.57692\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0101 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 2.0361 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 21/1000\n\nEpoch 21: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0079 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5000 - val_loss: 1.9503 - val_sensitivity: 0.5385 - val_specificity: 0.3846\nEpoch 22/1000\n\nEpoch 22: val_accuracy did not improve from 0.57692\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0054 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6250 - val_loss: 2.0575 - val_sensitivity: 0.7692 - val_specificity: 0.3077\nEpoch 23/1000\n\nEpoch 23: val_accuracy did not improve from 0.57692\n4/4 - 0s - 48ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0047 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.6000 - val_loss: 2.0198 - val_sensitivity: 0.6923 - val_specificity: 0.3846\nEpoch 24/1000\n\nEpoch 24: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0042 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5000 - val_loss: 1.9141 - val_sensitivity: 0.5385 - val_specificity: 0.3846\nEpoch 25/1000\n\nEpoch 25: val_accuracy did not improve from 0.57692\n4/4 - 0s - 72ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0040 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5517 - val_loss: 1.9371 - val_sensitivity: 0.6154 - val_specificity: 0.3846\nEpoch 26/1000\n\nEpoch 26: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0033 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5517 - val_loss: 1.9869 - val_sensitivity: 0.6154 - val_specificity: 0.3846\nEpoch 27/1000\n\nEpoch 27: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0025 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5517 - val_loss: 1.9744 - val_sensitivity: 0.6154 - val_specificity: 0.3846\nEpoch 28/1000\n\nEpoch 28: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9160 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 29/1000\n\nEpoch 29: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0021 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.8884 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 30/1000\n\nEpoch 30: val_accuracy did not improve from 0.57692\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9004 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 31/1000\n\nEpoch 31: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9460 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 32/1000\n\nEpoch 32: val_accuracy did not improve from 0.57692\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9654 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 33/1000\n\nEpoch 33: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9617 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 34/1000\n\nEpoch 34: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9566 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 35/1000\n\nEpoch 35: val_accuracy did not improve from 0.57692\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9677 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 36/1000\n\nEpoch 36: val_accuracy did not improve from 0.57692\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9761 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 37/1000\n\nEpoch 37: val_accuracy did not improve from 0.57692\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9805 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 38/1000\n\nEpoch 38: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9888 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 39/1000\n\nEpoch 39: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 2.0018 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 40/1000\n\nEpoch 40: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6132e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9865 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 41/1000\n\nEpoch 41: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.8523e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9513 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 42/1000\n\nEpoch 42: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.8615e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9405 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 43/1000\n\nEpoch 43: val_accuracy did not improve from 0.57692\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 1.9503 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 44/1000\n\nEpoch 44: val_accuracy did not improve from 0.57692\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.1957e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 2.0046 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 45/1000\n\nEpoch 45: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 2.0020 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 46/1000\n\nEpoch 46: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9713 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 47/1000\n\nEpoch 47: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.9366e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9585 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 48/1000\n\nEpoch 48: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1681e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9676 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 49/1000\n\nEpoch 49: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6067e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9780 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 50/1000\n\nEpoch 50: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.8694e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9872 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 51/1000\n\nEpoch 51: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.3171e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9939 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 52/1000\n\nEpoch 52: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6068e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0056 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 53/1000\n\nEpoch 53: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9889e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0163 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 54/1000\n\nEpoch 54: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5246e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.4444 - val_loss: 2.0170 - val_sensitivity: 0.4615 - val_specificity: 0.3846\nEpoch 55/1000\n\nEpoch 55: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4165e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9985 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 56/1000\n\nEpoch 56: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5218e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9885 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 57/1000\n\nEpoch 57: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8006e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9796 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 58/1000\n\nEpoch 58: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8319e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9814 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 59/1000\n\nEpoch 59: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1060e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9844 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 60/1000\n\nEpoch 60: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3413e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9892 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 61/1000\n\nEpoch 61: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3999e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9946 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 62/1000\n\nEpoch 62: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3426e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9988 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 63/1000\n\nEpoch 63: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8947e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0024 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 64/1000\n\nEpoch 64: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1468e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0076 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 65/1000\n\nEpoch 65: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8139e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0117 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 66/1000\n\nEpoch 66: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8089e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0107 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 67/1000\n\nEpoch 67: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4856e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0067 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 68/1000\n\nEpoch 68: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3815e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0067 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 69/1000\n\nEpoch 69: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5180e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0120 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 70/1000\n\nEpoch 70: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.0361e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0084 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 71/1000\n\nEpoch 71: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 2.0373 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 72/1000\n\nEpoch 72: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.5074e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9478 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 73/1000\n\nEpoch 73: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4167 - val_loss: 1.9483 - val_sensitivity: 0.3846 - val_specificity: 0.5385\nEpoch 74/1000\n\nEpoch 74: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5185 - val_loss: 1.9359 - val_sensitivity: 0.5385 - val_specificity: 0.4615\nEpoch 75/1000\n\nEpoch 75: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4125e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 1.9772 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 76/1000\n\nEpoch 76: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0133 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 77/1000\n\nEpoch 77: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9156e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0390 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 78/1000\n\nEpoch 78: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4028e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0578 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 79/1000\n\nEpoch 79: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6444e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0668 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 80/1000\n\nEpoch 80: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.0813e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0655 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 81/1000\n\nEpoch 81: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3049e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0659 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 82/1000\n\nEpoch 82: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2589e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0700 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 83/1000\n\nEpoch 83: val_accuracy did not improve from 0.57692\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2276e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0802 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 84/1000\n\nEpoch 84: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8243e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0834 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 85/1000\n\nEpoch 85: val_accuracy did not improve from 0.57692\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9839e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0803 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 86/1000\n\nEpoch 86: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8634e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0776 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 87/1000\n\nEpoch 87: val_accuracy did not improve from 0.57692\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7458e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0767 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 88/1000\n\nEpoch 88: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0807e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0765 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 89/1000\n\nEpoch 89: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1723e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0758 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 90/1000\n\nEpoch 90: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9139e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0760 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 91/1000\n\nEpoch 91: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2827e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0720 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 92/1000\n\nEpoch 92: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7838e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0696 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 93/1000\n\nEpoch 93: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8268e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0690 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 94/1000\n\nEpoch 94: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9426e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0685 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 95/1000\n\nEpoch 95: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7367e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0689 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 96/1000\n\nEpoch 96: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6876e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0730 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 97/1000\n\nEpoch 97: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5465e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0762 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 98/1000\n\nEpoch 98: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5174e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0799 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 99/1000\n\nEpoch 99: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4601e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0828 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 100/1000\n\nEpoch 100: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5980e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0859 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 101/1000\n\nEpoch 101: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4312e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0876 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 102/1000\n\nEpoch 102: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4539e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0927 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 103/1000\n\nEpoch 103: val_accuracy did not improve from 0.57692\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3571e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.0982 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 104/1000\n\nEpoch 104: val_accuracy did not improve from 0.57692\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3384e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.4615 - val_loss: 2.1036 - val_sensitivity: 0.4615 - val_specificity: 0.4615\nEpoch 104: early stopping\nRestoring model weights from the end of the best epoch: 4.\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1750366030.403874     246 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366032.455913     247 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366034.448354     247 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\n=== Fold 2/5 ===\nEpoch 1/1000\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1750366041.645018     246 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366047.186751     247 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366053.363848     246 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.53846, saving model to best_model_fold2.keras\n4/4 - 18s - 5s/step - accuracy: 0.5437 - f1_score: 0.6569 - loss: 0.6802 - sensitivity: 0.8491 - specificity: 0.2200 - val_accuracy: 0.5385 - val_f1_score: 0.1429 - val_loss: 0.7457 - val_sensitivity: 0.0769 - val_specificity: 1.0000\nEpoch 2/1000\n\nEpoch 2: val_accuracy improved from 0.53846 to 0.65385, saving model to best_model_fold2.keras\n4/4 - 0s - 57ms/step - accuracy: 0.5437 - f1_score: 0.2034 - loss: 0.6648 - sensitivity: 0.1132 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6667 - val_loss: 0.6493 - val_sensitivity: 0.6923 - val_specificity: 0.6154\nEpoch 3/1000\n\nEpoch 3: val_accuracy did not improve from 0.65385\n4/4 - 0s - 41ms/step - accuracy: 0.7087 - f1_score: 0.7692 - loss: 0.6191 - sensitivity: 0.9434 - specificity: 0.4600 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.9279 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 4/1000\n\nEpoch 4: val_accuracy did not improve from 0.65385\n4/4 - 0s - 40ms/step - accuracy: 0.7573 - f1_score: 0.8031 - loss: 0.5685 - sensitivity: 0.9623 - specificity: 0.5400 - val_accuracy: 0.5385 - val_f1_score: 0.6250 - val_loss: 0.6618 - val_sensitivity: 0.7692 - val_specificity: 0.3077\nEpoch 5/1000\n\nEpoch 5: val_accuracy did not improve from 0.65385\n4/4 - 0s - 42ms/step - accuracy: 0.8544 - f1_score: 0.8515 - loss: 0.5256 - sensitivity: 0.8113 - specificity: 0.9000 - val_accuracy: 0.6154 - val_f1_score: 0.7222 - val_loss: 0.9016 - val_sensitivity: 1.0000 - val_specificity: 0.2308\nEpoch 6/1000\n\nEpoch 6: val_accuracy did not improve from 0.65385\n4/4 - 0s - 39ms/step - accuracy: 0.8641 - f1_score: 0.8833 - loss: 0.4627 - sensitivity: 1.0000 - specificity: 0.7200 - val_accuracy: 0.5385 - val_f1_score: 0.6471 - val_loss: 1.0086 - val_sensitivity: 0.8462 - val_specificity: 0.2308\nEpoch 7/1000\n\nEpoch 7: val_accuracy did not improve from 0.65385\n4/4 - 0s - 39ms/step - accuracy: 0.9029 - f1_score: 0.9091 - loss: 0.4029 - sensitivity: 0.9434 - specificity: 0.8600 - val_accuracy: 0.5385 - val_f1_score: 0.5714 - val_loss: 0.8572 - val_sensitivity: 0.6154 - val_specificity: 0.4615\nEpoch 8/1000\n\nEpoch 8: val_accuracy did not improve from 0.65385\n4/4 - 0s - 39ms/step - accuracy: 0.8835 - f1_score: 0.8929 - loss: 0.3509 - sensitivity: 0.9434 - specificity: 0.8200 - val_accuracy: 0.5000 - val_f1_score: 0.5806 - val_loss: 1.1288 - val_sensitivity: 0.6923 - val_specificity: 0.3077\nEpoch 9/1000\n\nEpoch 9: val_accuracy did not improve from 0.65385\n4/4 - 0s - 39ms/step - accuracy: 0.9515 - f1_score: 0.9541 - loss: 0.2701 - sensitivity: 0.9811 - specificity: 0.9200 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 0.8767 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 10/1000\n\nEpoch 10: val_accuracy did not improve from 0.65385\n4/4 - 0s - 40ms/step - accuracy: 0.9515 - f1_score: 0.9524 - loss: 0.2374 - sensitivity: 0.9434 - specificity: 0.9600 - val_accuracy: 0.6154 - val_f1_score: 0.7059 - val_loss: 1.0628 - val_sensitivity: 0.9231 - val_specificity: 0.3077\nEpoch 11/1000\n\nEpoch 11: val_accuracy did not improve from 0.65385\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1483 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 0.9227 - val_sensitivity: 0.7692 - val_specificity: 0.5385\nEpoch 12/1000\n\nEpoch 12: val_accuracy did not improve from 0.65385\n4/4 - 0s - 37ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.1259 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 1.0416 - val_sensitivity: 0.7692 - val_specificity: 0.5385\nEpoch 13/1000\n\nEpoch 13: val_accuracy improved from 0.65385 to 0.69231, saving model to best_model_fold2.keras\n4/4 - 0s - 55ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0838 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 1.1928 - val_sensitivity: 0.8462 - val_specificity: 0.5385\nEpoch 14/1000\n\nEpoch 14: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0633 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 1.1054 - val_sensitivity: 0.7692 - val_specificity: 0.5385\nEpoch 15/1000\n\nEpoch 15: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0645 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6452 - val_loss: 1.6013 - val_sensitivity: 0.7692 - val_specificity: 0.3846\nEpoch 16/1000\n\nEpoch 16: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0781 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6667 - val_loss: 1.1081 - val_sensitivity: 0.6923 - val_specificity: 0.6154\nEpoch 17/1000\n\nEpoch 17: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0390 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 1.3960 - val_sensitivity: 0.7692 - val_specificity: 0.5385\nEpoch 18/1000\n\nEpoch 18: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 0.9709 - f1_score: 0.9725 - loss: 0.0698 - sensitivity: 1.0000 - specificity: 0.9400 - val_accuracy: 0.6538 - val_f1_score: 0.6667 - val_loss: 1.2380 - val_sensitivity: 0.6923 - val_specificity: 0.6154\nEpoch 19/1000\n\nEpoch 19: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 0.9320 - f1_score: 0.9293 - loss: 0.1453 - sensitivity: 0.8679 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.3839 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 20/1000\n\nEpoch 20: val_accuracy did not improve from 0.69231\n4/4 - 0s - 40ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.0854 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 1.8594 - val_sensitivity: 0.8462 - val_specificity: 0.3846\nEpoch 21/1000\n\nEpoch 21: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.0533 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.5385 - val_f1_score: 0.4000 - val_loss: 2.2473 - val_sensitivity: 0.3077 - val_specificity: 0.7692\nEpoch 22/1000\n\nEpoch 22: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 0.9320 - f1_score: 0.9293 - loss: 0.1235 - sensitivity: 0.8679 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.5385 - val_loss: 1.9324 - val_sensitivity: 0.5385 - val_specificity: 0.5385\nEpoch 23/1000\n\nEpoch 23: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 0.9612 - f1_score: 0.9636 - loss: 0.1042 - sensitivity: 1.0000 - specificity: 0.9200 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.9455 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 24/1000\n\nEpoch 24: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 0.9806 - f1_score: 0.9808 - loss: 0.0555 - sensitivity: 0.9623 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.4348 - val_loss: 2.2296 - val_sensitivity: 0.3846 - val_specificity: 0.6154\nEpoch 25/1000\n\nEpoch 25: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0527 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 2.1744 - val_sensitivity: 0.7692 - val_specificity: 0.5385\nEpoch 26/1000\n\nEpoch 26: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 0.9709 - f1_score: 0.9725 - loss: 0.0709 - sensitivity: 1.0000 - specificity: 0.9400 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 2.1921 - val_sensitivity: 0.7692 - val_specificity: 0.5385\nEpoch 27/1000\n\nEpoch 27: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0218 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5600 - val_loss: 1.8940 - val_sensitivity: 0.5385 - val_specificity: 0.6154\nEpoch 28/1000\n\nEpoch 28: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0446 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6667 - val_loss: 1.8936 - val_sensitivity: 0.6923 - val_specificity: 0.6154\nEpoch 29/1000\n\nEpoch 29: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0184 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 2.2546 - val_sensitivity: 0.7692 - val_specificity: 0.5385\nEpoch 30/1000\n\nEpoch 30: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0283 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 2.2547 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 31/1000\n\nEpoch 31: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0141 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 2.0552 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 32/1000\n\nEpoch 32: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0069 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 1.9539 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 33/1000\n\nEpoch 33: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0074 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 1.9294 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 34/1000\n\nEpoch 34: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0091 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 2.0160 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 35/1000\n\nEpoch 35: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0043 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 2.0429 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 36/1000\n\nEpoch 36: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0044 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6429 - val_loss: 2.0182 - val_sensitivity: 0.6923 - val_specificity: 0.5385\nEpoch 37/1000\n\nEpoch 37: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0036 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.9774 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 38/1000\n\nEpoch 38: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.9425 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 39/1000\n\nEpoch 39: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0024 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.9170 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 40/1000\n\nEpoch 40: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.9018 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 41/1000\n\nEpoch 41: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0024 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8921 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 42/1000\n\nEpoch 42: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.9016 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 43/1000\n\nEpoch 43: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8994 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 44/1000\n\nEpoch 44: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8895 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 45/1000\n\nEpoch 45: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8759 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 46/1000\n\nEpoch 46: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8625 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 47/1000\n\nEpoch 47: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8490 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 48/1000\n\nEpoch 48: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8400 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 49/1000\n\nEpoch 49: val_accuracy did not improve from 0.69231\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8321 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 50/1000\n\nEpoch 50: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.5926 - val_loss: 1.8242 - val_sensitivity: 0.6154 - val_specificity: 0.5385\nEpoch 51/1000\n\nEpoch 51: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8148 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 52/1000\n\nEpoch 52: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8120 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 53/1000\n\nEpoch 53: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8103 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 54/1000\n\nEpoch 54: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8059 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 55/1000\n\nEpoch 55: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.5533e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8030 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 56/1000\n\nEpoch 56: val_accuracy did not improve from 0.69231\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1061e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7984 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 57/1000\n\nEpoch 57: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.3895e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7930 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 58/1000\n\nEpoch 58: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.5089e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7889 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 59/1000\n\nEpoch 59: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.9347e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7883 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 60/1000\n\nEpoch 60: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.5975e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7877 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 61/1000\n\nEpoch 61: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.0353e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7872 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 62/1000\n\nEpoch 62: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4064e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7866 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 63/1000\n\nEpoch 63: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6243e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7858 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 64/1000\n\nEpoch 64: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9713e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7848 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 65/1000\n\nEpoch 65: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9416e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7826 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 66/1000\n\nEpoch 66: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.8976e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7828 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 67/1000\n\nEpoch 67: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.4251e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7836 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 68/1000\n\nEpoch 68: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2580e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7839 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 69/1000\n\nEpoch 69: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9997e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7842 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 70/1000\n\nEpoch 70: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2509e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7805 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 71/1000\n\nEpoch 71: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0623e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7805 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 72/1000\n\nEpoch 72: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.2092e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7813 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 73/1000\n\nEpoch 73: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4506e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7819 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 74/1000\n\nEpoch 74: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.7522e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7810 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 75/1000\n\nEpoch 75: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6848e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7781 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 76/1000\n\nEpoch 76: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6418e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7774 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 77/1000\n\nEpoch 77: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.4251e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7769 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 78/1000\n\nEpoch 78: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6154e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7777 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 79/1000\n\nEpoch 79: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6473e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7751 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 80/1000\n\nEpoch 80: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2908e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7734 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 81/1000\n\nEpoch 81: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9496e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7719 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 82/1000\n\nEpoch 82: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7640e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7707 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 83/1000\n\nEpoch 83: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5880e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7699 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 84/1000\n\nEpoch 84: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4418e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7703 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 85/1000\n\nEpoch 85: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.3328e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7706 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 86/1000\n\nEpoch 86: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1199e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7719 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 87/1000\n\nEpoch 87: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1081e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7717 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 88/1000\n\nEpoch 88: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1304e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7695 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 89/1000\n\nEpoch 89: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0784e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7703 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 90/1000\n\nEpoch 90: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2153e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7719 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 91/1000\n\nEpoch 91: val_accuracy did not improve from 0.69231\n4/4 - 0s - 34ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2635e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7740 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 92/1000\n\nEpoch 92: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4676e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7752 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 93/1000\n\nEpoch 93: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9528e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7765 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 94/1000\n\nEpoch 94: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.2763e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7762 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 95/1000\n\nEpoch 95: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7439e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7780 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 96/1000\n\nEpoch 96: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5350e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7792 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 97/1000\n\nEpoch 97: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.0150e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.7851 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 98/1000\n\nEpoch 98: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0444e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8017 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 99/1000\n\nEpoch 99: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5163e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8080 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 100/1000\n\nEpoch 100: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5468e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8095 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 101/1000\n\nEpoch 101: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9946e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8086 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 102/1000\n\nEpoch 102: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6254e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6154 - val_loss: 1.8048 - val_sensitivity: 0.6154 - val_specificity: 0.6154\nEpoch 103/1000\n\nEpoch 103: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4946e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8038 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 104/1000\n\nEpoch 104: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6279e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8046 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 105/1000\n\nEpoch 105: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9926e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8057 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 106/1000\n\nEpoch 106: val_accuracy did not improve from 0.69231\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2783e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8085 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 107/1000\n\nEpoch 107: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1321e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8113 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 108/1000\n\nEpoch 108: val_accuracy did not improve from 0.69231\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8552e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8116 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 109/1000\n\nEpoch 109: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9948e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8128 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 110/1000\n\nEpoch 110: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7667e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8139 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 111/1000\n\nEpoch 111: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0316e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8155 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 112/1000\n\nEpoch 112: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7997e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8156 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 113/1000\n\nEpoch 113: val_accuracy did not improve from 0.69231\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4967e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6400 - val_loss: 1.8163 - val_sensitivity: 0.6154 - val_specificity: 0.6923\nEpoch 113: early stopping\nRestoring model weights from the end of the best epoch: 13.\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1750366075.823125     247 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366077.906707     246 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366079.933792     246 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\n=== Fold 3/5 ===\nEpoch 1/1000\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1750366087.275881     245 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366092.662393     245 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366098.508836     245 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_accuracy improved from -inf to 0.50000, saving model to best_model_fold3.keras\n4/4 - 18s - 4s/step - accuracy: 0.5340 - f1_score: 0.6308 - loss: 0.6875 - sensitivity: 0.7736 - specificity: 0.2800 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 0.8737 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 2/1000\n\nEpoch 2: val_accuracy did not improve from 0.50000\n4/4 - 0s - 42ms/step - accuracy: 0.6117 - f1_score: 0.7260 - loss: 0.6544 - sensitivity: 1.0000 - specificity: 0.2000 - val_accuracy: 0.5000 - val_f1_score: 0.6667 - val_loss: 1.3621 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 3/1000\n\nEpoch 3: val_accuracy did not improve from 0.50000\n4/4 - 0s - 40ms/step - accuracy: 0.6796 - f1_score: 0.7591 - loss: 0.6094 - sensitivity: 0.9811 - specificity: 0.3600 - val_accuracy: 0.4231 - val_f1_score: 0.5714 - val_loss: 0.8616 - val_sensitivity: 0.7692 - val_specificity: 0.0769\nEpoch 4/1000\n\nEpoch 4: val_accuracy did not improve from 0.50000\n4/4 - 0s - 41ms/step - accuracy: 0.8447 - f1_score: 0.8367 - loss: 0.5607 - sensitivity: 0.7736 - specificity: 0.9200 - val_accuracy: 0.4231 - val_f1_score: 0.5946 - val_loss: 1.1088 - val_sensitivity: 0.8462 - val_specificity: 0.0000e+00\nEpoch 5/1000\n\nEpoch 5: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 0.8155 - f1_score: 0.8430 - loss: 0.5077 - sensitivity: 0.9623 - specificity: 0.6600 - val_accuracy: 0.4615 - val_f1_score: 0.6111 - val_loss: 1.0519 - val_sensitivity: 0.8462 - val_specificity: 0.0769\nEpoch 6/1000\n\nEpoch 6: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 0.9029 - f1_score: 0.9000 - loss: 0.4379 - sensitivity: 0.8491 - specificity: 0.9600 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.0710 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 7/1000\n\nEpoch 7: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 0.8932 - f1_score: 0.8972 - loss: 0.3692 - sensitivity: 0.9057 - specificity: 0.8800 - val_accuracy: 0.4615 - val_f1_score: 0.6111 - val_loss: 1.3897 - val_sensitivity: 0.8462 - val_specificity: 0.0769\nEpoch 8/1000\n\nEpoch 8: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 0.8932 - f1_score: 0.8911 - loss: 0.3364 - sensitivity: 0.8491 - specificity: 0.9400 - val_accuracy: 0.4615 - val_f1_score: 0.5882 - val_loss: 1.3596 - val_sensitivity: 0.7692 - val_specificity: 0.1538\nEpoch 9/1000\n\nEpoch 9: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 0.9320 - f1_score: 0.9358 - loss: 0.2610 - sensitivity: 0.9623 - specificity: 0.9000 - val_accuracy: 0.3846 - val_f1_score: 0.4667 - val_loss: 1.3103 - val_sensitivity: 0.5385 - val_specificity: 0.2308\nEpoch 10/1000\n\nEpoch 10: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 0.8738 - f1_score: 0.8632 - loss: 0.2922 - sensitivity: 0.7736 - specificity: 0.9800 - val_accuracy: 0.4615 - val_f1_score: 0.6316 - val_loss: 2.7136 - val_sensitivity: 0.9231 - val_specificity: 0.0000e+00\nEpoch 11/1000\n\nEpoch 11: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 0.8350 - f1_score: 0.8618 - loss: 0.3577 - sensitivity: 1.0000 - specificity: 0.6600 - val_accuracy: 0.3846 - val_f1_score: 0.4667 - val_loss: 1.2011 - val_sensitivity: 0.5385 - val_specificity: 0.2308\nEpoch 12/1000\n\nEpoch 12: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 0.8447 - f1_score: 0.8222 - loss: 0.3217 - sensitivity: 0.6981 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5714 - val_loss: 1.7197 - val_sensitivity: 0.7692 - val_specificity: 0.0769\nEpoch 13/1000\n\nEpoch 13: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 0.9612 - f1_score: 0.9636 - loss: 0.1744 - sensitivity: 1.0000 - specificity: 0.9200 - val_accuracy: 0.4615 - val_f1_score: 0.6316 - val_loss: 3.8437 - val_sensitivity: 0.9231 - val_specificity: 0.0000e+00\nEpoch 14/1000\n\nEpoch 14: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 0.9223 - f1_score: 0.9298 - loss: 0.2211 - sensitivity: 1.0000 - specificity: 0.8400 - val_accuracy: 0.4231 - val_f1_score: 0.5714 - val_loss: 1.4989 - val_sensitivity: 0.7692 - val_specificity: 0.0769\nEpoch 15/1000\n\nEpoch 15: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 0.9612 - f1_score: 0.9608 - loss: 0.1681 - sensitivity: 0.9245 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5714 - val_loss: 1.4131 - val_sensitivity: 0.7692 - val_specificity: 0.0769\nEpoch 16/1000\n\nEpoch 16: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 0.9806 - f1_score: 0.9811 - loss: 0.1097 - sensitivity: 0.9811 - specificity: 0.9800 - val_accuracy: 0.4615 - val_f1_score: 0.6316 - val_loss: 2.4697 - val_sensitivity: 0.9231 - val_specificity: 0.0000e+00\nEpoch 17/1000\n\nEpoch 17: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 0.9903 - f1_score: 0.9907 - loss: 0.0983 - sensitivity: 1.0000 - specificity: 0.9800 - val_accuracy: 0.5000 - val_f1_score: 0.6486 - val_loss: 1.8775 - val_sensitivity: 0.9231 - val_specificity: 0.0769\nEpoch 18/1000\n\nEpoch 18: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0776 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.6111 - val_loss: 1.6266 - val_sensitivity: 0.8462 - val_specificity: 0.0769\nEpoch 19/1000\n\nEpoch 19: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0527 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.6486 - val_loss: 2.3913 - val_sensitivity: 0.9231 - val_specificity: 0.0769\nEpoch 20/1000\n\nEpoch 20: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0434 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.6486 - val_loss: 2.0577 - val_sensitivity: 0.9231 - val_specificity: 0.0769\nEpoch 21/1000\n\nEpoch 21: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0303 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7563 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 22/1000\n\nEpoch 22: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0239 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.5294 - val_loss: 1.9506 - val_sensitivity: 0.6923 - val_specificity: 0.0769\nEpoch 23/1000\n\nEpoch 23: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0192 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.5294 - val_loss: 2.0269 - val_sensitivity: 0.6923 - val_specificity: 0.0769\nEpoch 24/1000\n\nEpoch 24: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0145 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7836 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 25/1000\n\nEpoch 25: val_accuracy did not improve from 0.50000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0136 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7370 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 26/1000\n\nEpoch 26: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0104 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.9219 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 27/1000\n\nEpoch 27: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0091 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.9803 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 28/1000\n\nEpoch 28: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0085 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.8634 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 29/1000\n\nEpoch 29: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0073 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7083 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 30/1000\n\nEpoch 30: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0065 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7468 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 31/1000\n\nEpoch 31: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0054 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7294 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 32/1000\n\nEpoch 32: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0051 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7214 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 33/1000\n\nEpoch 33: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0044 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.6747 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 34/1000\n\nEpoch 34: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0044 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7183 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 35/1000\n\nEpoch 35: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0036 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7943 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 36/1000\n\nEpoch 36: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0037 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.8129 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 37/1000\n\nEpoch 37: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0032 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7694 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 38/1000\n\nEpoch 38: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0029 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7120 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 39/1000\n\nEpoch 39: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0027 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.6773 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 40/1000\n\nEpoch 40: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7045 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 41/1000\n\nEpoch 41: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7305 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 42/1000\n\nEpoch 42: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7214 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 43/1000\n\nEpoch 43: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7336 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 44/1000\n\nEpoch 44: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7524 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 45/1000\n\nEpoch 45: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7487 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 46/1000\n\nEpoch 46: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7426 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 47/1000\n\nEpoch 47: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7252 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 48/1000\n\nEpoch 48: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.5000 - val_loss: 1.6598 - val_sensitivity: 0.6154 - val_specificity: 0.1538\nEpoch 49/1000\n\nEpoch 49: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.5000 - val_loss: 1.6613 - val_sensitivity: 0.6154 - val_specificity: 0.1538\nEpoch 50/1000\n\nEpoch 50: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7021 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 51/1000\n\nEpoch 51: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.7005 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 52/1000\n\nEpoch 52: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5455 - val_loss: 1.6796 - val_sensitivity: 0.6923 - val_specificity: 0.1538\nEpoch 53/1000\n\nEpoch 53: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.5000 - val_loss: 1.6667 - val_sensitivity: 0.6154 - val_specificity: 0.1538\nEpoch 54/1000\n\nEpoch 54: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3846 - val_f1_score: 0.5000 - val_loss: 1.6463 - val_sensitivity: 0.6154 - val_specificity: 0.1538\nEpoch 55/1000\n\nEpoch 55: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0015 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6497 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 56/1000\n\nEpoch 56: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6392 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 57/1000\n\nEpoch 57: val_accuracy did not improve from 0.50000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6291 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 58/1000\n\nEpoch 58: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6188 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 59/1000\n\nEpoch 59: val_accuracy did not improve from 0.50000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6307 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 60/1000\n\nEpoch 60: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6553 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 61/1000\n\nEpoch 61: val_accuracy did not improve from 0.50000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6790 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 62/1000\n\nEpoch 62: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7111 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 63/1000\n\nEpoch 63: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7214 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 64/1000\n\nEpoch 64: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.7308e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6826 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 65/1000\n\nEpoch 65: val_accuracy did not improve from 0.50000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.4418e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6408 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 66/1000\n\nEpoch 66: val_accuracy did not improve from 0.50000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.6290 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 67/1000\n\nEpoch 67: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6524 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 68/1000\n\nEpoch 68: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.7072e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.6412 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 69/1000\n\nEpoch 69: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.6188e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.6523 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 70/1000\n\nEpoch 70: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.1359e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.6829 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 71/1000\n\nEpoch 71: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3034e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7114 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 72/1000\n\nEpoch 72: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3135e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7376 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 73/1000\n\nEpoch 73: val_accuracy did not improve from 0.50000\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6637e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7455 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 74/1000\n\nEpoch 74: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.8534e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7389 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 75/1000\n\nEpoch 75: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.5191e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7241 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 76/1000\n\nEpoch 76: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.5003e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7317 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 77/1000\n\nEpoch 77: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5101e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7542 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 78/1000\n\nEpoch 78: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5108e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7430 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 79/1000\n\nEpoch 79: val_accuracy did not improve from 0.50000\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.1893e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7045 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 80/1000\n\nEpoch 80: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.7300e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5806 - val_loss: 1.6589 - val_sensitivity: 0.6923 - val_specificity: 0.3077\nEpoch 81/1000\n\nEpoch 81: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1411e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5806 - val_loss: 1.6772 - val_sensitivity: 0.6923 - val_specificity: 0.3077\nEpoch 82/1000\n\nEpoch 82: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0695e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7192 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 83/1000\n\nEpoch 83: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5107e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7451 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 84/1000\n\nEpoch 84: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8463e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7635 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 85/1000\n\nEpoch 85: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1077e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7409 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 86/1000\n\nEpoch 86: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5599e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5625 - val_loss: 1.7195 - val_sensitivity: 0.6923 - val_specificity: 0.2308\nEpoch 87/1000\n\nEpoch 87: val_accuracy did not improve from 0.50000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8168e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5000 - val_f1_score: 0.5806 - val_loss: 1.7003 - val_sensitivity: 0.6923 - val_specificity: 0.3077\nEpoch 88/1000\n\nEpoch 88: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9747e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.6916 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 89/1000\n\nEpoch 89: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8693e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.7082 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 90/1000\n\nEpoch 90: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5439e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.7207 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 91/1000\n\nEpoch 91: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7680e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.7442 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 92/1000\n\nEpoch 92: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5937e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.7529 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 93/1000\n\nEpoch 93: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3487e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.7508 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 94/1000\n\nEpoch 94: val_accuracy did not improve from 0.50000\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1252e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.7442 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 95/1000\n\nEpoch 95: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4472e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.7569 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 96/1000\n\nEpoch 96: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8141e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.7752 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 97/1000\n\nEpoch 97: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3928e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4231 - val_f1_score: 0.5161 - val_loss: 1.7868 - val_sensitivity: 0.6154 - val_specificity: 0.2308\nEpoch 98/1000\n\nEpoch 98: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1043e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.6718 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 99/1000\n\nEpoch 99: val_accuracy did not improve from 0.50000\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4126e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.6131 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 100/1000\n\nEpoch 100: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.4205e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.5883 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 101/1000\n\nEpoch 101: val_accuracy did not improve from 0.50000\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8520e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4615 - val_f1_score: 0.5333 - val_loss: 1.6195 - val_sensitivity: 0.6154 - val_specificity: 0.3077\nEpoch 101: early stopping\nRestoring model weights from the end of the best epoch: 1.\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1750366119.705244     245 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\nW0000 00:00:1750366121.775166     245 assert_op.cc:38] Ignoring Assert operator functional_1/remove_diag_flatten_1/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\n=== Fold 4/5 ===\nEpoch 1/1000\n\nEpoch 1: val_accuracy improved from -inf to 0.53846, saving model to best_model_fold4.keras\n4/4 - 18s - 5s/step - accuracy: 0.6311 - f1_score: 0.6935 - loss: 0.7051 - sensitivity: 0.8269 - specificity: 0.4314 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.7654 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 2/1000\n\nEpoch 2: val_accuracy improved from 0.53846 to 0.65385, saving model to best_model_fold4.keras\n4/4 - 0s - 57ms/step - accuracy: 0.7670 - f1_score: 0.7551 - loss: 0.6359 - sensitivity: 0.7115 - specificity: 0.8235 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 0.6747 - val_sensitivity: 0.7143 - val_specificity: 0.5833\nEpoch 3/1000\n\nEpoch 3: val_accuracy did not improve from 0.65385\n4/4 - 0s - 42ms/step - accuracy: 0.8252 - f1_score: 0.8364 - loss: 0.6075 - sensitivity: 0.8846 - specificity: 0.7647 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.7818 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 4/1000\n\nEpoch 4: val_accuracy did not improve from 0.65385\n4/4 - 0s - 42ms/step - accuracy: 0.9029 - f1_score: 0.8980 - loss: 0.5538 - sensitivity: 0.8462 - specificity: 0.9608 - val_accuracy: 0.5000 - val_f1_score: 0.5806 - val_loss: 0.7268 - val_sensitivity: 0.6429 - val_specificity: 0.3333\nEpoch 5/1000\n\nEpoch 5: val_accuracy did not improve from 0.65385\n4/4 - 0s - 41ms/step - accuracy: 0.8738 - f1_score: 0.8571 - loss: 0.5001 - sensitivity: 0.7500 - specificity: 1.0000 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 1.2900 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 6/1000\n\nEpoch 6: val_accuracy did not improve from 0.65385\n4/4 - 0s - 40ms/step - accuracy: 0.8350 - f1_score: 0.8571 - loss: 0.4524 - sensitivity: 0.9808 - specificity: 0.6863 - val_accuracy: 0.5769 - val_f1_score: 0.6857 - val_loss: 0.7520 - val_sensitivity: 0.8571 - val_specificity: 0.2500\nEpoch 7/1000\n\nEpoch 7: val_accuracy did not improve from 0.65385\n4/4 - 0s - 39ms/step - accuracy: 0.9029 - f1_score: 0.9000 - loss: 0.3659 - sensitivity: 0.8654 - specificity: 0.9412 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 0.7893 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 8/1000\n\nEpoch 8: val_accuracy did not improve from 0.65385\n4/4 - 0s - 38ms/step - accuracy: 0.9515 - f1_score: 0.9515 - loss: 0.2970 - sensitivity: 0.9423 - specificity: 0.9608 - val_accuracy: 0.5385 - val_f1_score: 0.7000 - val_loss: 1.1599 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 9/1000\n\nEpoch 9: val_accuracy did not improve from 0.65385\n4/4 - 0s - 38ms/step - accuracy: 0.9126 - f1_score: 0.9204 - loss: 0.2987 - sensitivity: 1.0000 - specificity: 0.8235 - val_accuracy: 0.6538 - val_f1_score: 0.6667 - val_loss: 0.7048 - val_sensitivity: 0.6429 - val_specificity: 0.6667\nEpoch 10/1000\n\nEpoch 10: val_accuracy did not improve from 0.65385\n4/4 - 0s - 40ms/step - accuracy: 0.9417 - f1_score: 0.9400 - loss: 0.2316 - sensitivity: 0.9038 - specificity: 0.9804 - val_accuracy: 0.5769 - val_f1_score: 0.7179 - val_loss: 1.1834 - val_sensitivity: 1.0000 - val_specificity: 0.0833\nEpoch 11/1000\n\nEpoch 11: val_accuracy improved from 0.65385 to 0.73077, saving model to best_model_fold4.keras\n4/4 - 0s - 55ms/step - accuracy: 0.9612 - f1_score: 0.9630 - loss: 0.1730 - sensitivity: 1.0000 - specificity: 0.9216 - val_accuracy: 0.7308 - val_f1_score: 0.7586 - val_loss: 0.7053 - val_sensitivity: 0.7857 - val_specificity: 0.6667\nEpoch 12/1000\n\nEpoch 12: val_accuracy did not improve from 0.73077\n4/4 - 0s - 40ms/step - accuracy: 0.9612 - f1_score: 0.9600 - loss: 0.1688 - sensitivity: 0.9231 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7647 - val_loss: 0.8292 - val_sensitivity: 0.9286 - val_specificity: 0.4167\nEpoch 13/1000\n\nEpoch 13: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 0.9903 - f1_score: 0.9905 - loss: 0.1450 - sensitivity: 1.0000 - specificity: 0.9804 - val_accuracy: 0.6538 - val_f1_score: 0.7429 - val_loss: 1.0214 - val_sensitivity: 0.9286 - val_specificity: 0.3333\nEpoch 14/1000\n\nEpoch 14: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 0.9709 - f1_score: 0.9703 - loss: 0.1203 - sensitivity: 0.9423 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7143 - val_loss: 0.6687 - val_sensitivity: 0.7143 - val_specificity: 0.6667\nEpoch 15/1000\n\nEpoch 15: val_accuracy did not improve from 0.73077\n4/4 - 0s - 40ms/step - accuracy: 0.9903 - f1_score: 0.9903 - loss: 0.0887 - sensitivity: 0.9808 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.7027 - val_loss: 1.4490 - val_sensitivity: 0.9286 - val_specificity: 0.1667\nEpoch 16/1000\n\nEpoch 16: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0982 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.6897 - val_loss: 0.9560 - val_sensitivity: 0.7143 - val_specificity: 0.5833\nEpoch 17/1000\n\nEpoch 17: val_accuracy did not improve from 0.73077\n4/4 - 0s - 37ms/step - accuracy: 0.9903 - f1_score: 0.9903 - loss: 0.0726 - sensitivity: 0.9808 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.6667 - val_loss: 1.1797 - val_sensitivity: 0.7857 - val_specificity: 0.3333\nEpoch 18/1000\n\nEpoch 18: val_accuracy did not improve from 0.73077\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0461 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.5769 - val_f1_score: 0.7027 - val_loss: 1.3973 - val_sensitivity: 0.9286 - val_specificity: 0.1667\nEpoch 19/1000\n\nEpoch 19: val_accuracy did not improve from 0.73077\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0343 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 1.0712 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 20/1000\n\nEpoch 20: val_accuracy did not improve from 0.73077\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0316 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.6875 - val_loss: 1.1352 - val_sensitivity: 0.7857 - val_specificity: 0.4167\nEpoch 21/1000\n\nEpoch 21: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0195 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6154 - val_f1_score: 0.7222 - val_loss: 1.3669 - val_sensitivity: 0.9286 - val_specificity: 0.2500\nEpoch 22/1000\n\nEpoch 22: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0225 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6538 - val_f1_score: 0.7273 - val_loss: 0.9882 - val_sensitivity: 0.8571 - val_specificity: 0.4167\nEpoch 23/1000\n\nEpoch 23: val_accuracy did not improve from 0.73077\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0142 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.8954 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 24/1000\n\nEpoch 24: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0131 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7647 - val_loss: 0.9606 - val_sensitivity: 0.9286 - val_specificity: 0.4167\nEpoch 25/1000\n\nEpoch 25: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0082 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7647 - val_loss: 1.0602 - val_sensitivity: 0.9286 - val_specificity: 0.4167\nEpoch 26/1000\n\nEpoch 26: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0088 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7647 - val_loss: 1.0634 - val_sensitivity: 0.9286 - val_specificity: 0.4167\nEpoch 27/1000\n\nEpoch 27: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0061 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9649 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 28/1000\n\nEpoch 28: val_accuracy did not improve from 0.73077\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0056 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9384 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 29/1000\n\nEpoch 29: val_accuracy improved from 0.73077 to 0.76923, saving model to best_model_fold4.keras\n4/4 - 0s - 54ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0050 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.9217 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 30/1000\n\nEpoch 30: val_accuracy did not improve from 0.76923\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0045 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9590 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 31/1000\n\nEpoch 31: val_accuracy did not improve from 0.76923\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0036 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9700 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 32/1000\n\nEpoch 32: val_accuracy did not improve from 0.76923\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0032 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9514 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 33/1000\n\nEpoch 33: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0033 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9315 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 34/1000\n\nEpoch 34: val_accuracy did not improve from 0.76923\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0030 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9237 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 35/1000\n\nEpoch 35: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0029 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9241 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 36/1000\n\nEpoch 36: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0026 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9239 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 37/1000\n\nEpoch 37: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0024 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9075 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 38/1000\n\nEpoch 38: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0021 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9011 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 39/1000\n\nEpoch 39: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0024 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.8839 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 40/1000\n\nEpoch 40: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0031 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8620 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 41/1000\n\nEpoch 41: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9637 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 42/1000\n\nEpoch 42: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0037 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7500 - val_loss: 0.9489 - val_sensitivity: 0.8571 - val_specificity: 0.5000\nEpoch 43/1000\n\nEpoch 43: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0027 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8746 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 44/1000\n\nEpoch 44: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8561 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 45/1000\n\nEpoch 45: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0018 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.8592 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 46/1000\n\nEpoch 46: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0020 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8731 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 47/1000\n\nEpoch 47: val_accuracy did not improve from 0.76923\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8792 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 48/1000\n\nEpoch 48: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8852 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 49/1000\n\nEpoch 49: val_accuracy did not improve from 0.76923\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8938 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 50/1000\n\nEpoch 50: val_accuracy did not improve from 0.76923\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8978 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 51/1000\n\nEpoch 51: val_accuracy did not improve from 0.76923\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8977 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 52/1000\n\nEpoch 52: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8928 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 53/1000\n\nEpoch 53: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8873 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 54/1000\n\nEpoch 54: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6620e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8893 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 55/1000\n\nEpoch 55: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.9758e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.8883 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 56/1000\n\nEpoch 56: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.4675e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8868 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 57/1000\n\nEpoch 57: val_accuracy did not improve from 0.76923\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.8347e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8831 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 58/1000\n\nEpoch 58: val_accuracy did not improve from 0.76923\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.0121e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8833 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 59/1000\n\nEpoch 59: val_accuracy did not improve from 0.76923\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.3093e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8835 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 60/1000\n\nEpoch 60: val_accuracy improved from 0.76923 to 0.80769, saving model to best_model_fold4.keras\n4/4 - 0s - 57ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.9550e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8884 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 61/1000\n\nEpoch 61: val_accuracy did not improve from 0.80769\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.0812e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8922 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 62/1000\n\nEpoch 62: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.3775e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8938 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 63/1000\n\nEpoch 63: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.2607e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8959 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 64/1000\n\nEpoch 64: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.1094e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8975 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 65/1000\n\nEpoch 65: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.0676e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8974 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 66/1000\n\nEpoch 66: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9295e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8949 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 67/1000\n\nEpoch 67: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.7593e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8924 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 68/1000\n\nEpoch 68: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3541e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8916 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 69/1000\n\nEpoch 69: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9030e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8930 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 70/1000\n\nEpoch 70: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9256e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8922 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 71/1000\n\nEpoch 71: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3673e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8893 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 72/1000\n\nEpoch 72: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.7611e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7586 - val_loss: 0.8826 - val_sensitivity: 0.7857 - val_specificity: 0.6667\nEpoch 73/1000\n\nEpoch 73: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1301e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8795 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 74/1000\n\nEpoch 74: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.5594e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8777 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 75/1000\n\nEpoch 75: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6413e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8771 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 76/1000\n\nEpoch 76: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9636e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8788 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 77/1000\n\nEpoch 77: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0157e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8864 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 78/1000\n\nEpoch 78: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.9807e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8928 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 79/1000\n\nEpoch 79: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.6527e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8969 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 80/1000\n\nEpoch 80: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1248e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8989 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 81/1000\n\nEpoch 81: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8269e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.8934 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 82/1000\n\nEpoch 82: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.6198e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8860 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 83/1000\n\nEpoch 83: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8580e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8844 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 84/1000\n\nEpoch 84: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7781e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8895 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 85/1000\n\nEpoch 85: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.5124e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.8918 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 86/1000\n\nEpoch 86: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2975e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8944 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 87/1000\n\nEpoch 87: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0564e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8953 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 88/1000\n\nEpoch 88: val_accuracy did not improve from 0.80769\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3198e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8949 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 89/1000\n\nEpoch 89: val_accuracy did not improve from 0.80769\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8407e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8968 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 90/1000\n\nEpoch 90: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.0282e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8963 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 91/1000\n\nEpoch 91: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8556e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8987 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 92/1000\n\nEpoch 92: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6331e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8979 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 93/1000\n\nEpoch 93: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5188e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8963 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 94/1000\n\nEpoch 94: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.8292e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8963 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 95/1000\n\nEpoch 95: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3781e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8959 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 96/1000\n\nEpoch 96: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7422e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8970 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 97/1000\n\nEpoch 97: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9883e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9009 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 98/1000\n\nEpoch 98: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4150e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8995 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 99/1000\n\nEpoch 99: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5146e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9004 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 100/1000\n\nEpoch 100: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3464e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.8994 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 101/1000\n\nEpoch 101: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5323e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9020 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 102/1000\n\nEpoch 102: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.5174e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9101 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 103/1000\n\nEpoch 103: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0676e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.9144 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 104/1000\n\nEpoch 104: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8093e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.9156 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 105/1000\n\nEpoch 105: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9525e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.9153 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 106/1000\n\nEpoch 106: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8239e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9139 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 107/1000\n\nEpoch 107: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7852e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9136 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 108/1000\n\nEpoch 108: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3974e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9132 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 109/1000\n\nEpoch 109: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8370e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9141 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 110/1000\n\nEpoch 110: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0043e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9163 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 111/1000\n\nEpoch 111: val_accuracy did not improve from 0.80769\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2635e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9178 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 112/1000\n\nEpoch 112: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9106e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9198 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 113/1000\n\nEpoch 113: val_accuracy did not improve from 0.80769\n4/4 - 0s - 35ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1161e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.9256 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 114/1000\n\nEpoch 114: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2618e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9314 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 115/1000\n\nEpoch 115: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.7797e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9322 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 116/1000\n\nEpoch 116: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.4297e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9297 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 117/1000\n\nEpoch 117: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5551e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9266 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 118/1000\n\nEpoch 118: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.6615e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9242 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 119/1000\n\nEpoch 119: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.5548e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9221 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 120/1000\n\nEpoch 120: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3285e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9215 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 121/1000\n\nEpoch 121: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8910e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9220 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 122/1000\n\nEpoch 122: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3207e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9230 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 123/1000\n\nEpoch 123: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3918e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9235 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 124/1000\n\nEpoch 124: val_accuracy did not improve from 0.80769\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3844e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9263 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 125/1000\n\nEpoch 125: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2270e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9282 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 126/1000\n\nEpoch 126: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3125e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9306 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 127/1000\n\nEpoch 127: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1376e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9371 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 128/1000\n\nEpoch 128: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9934e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8077 - val_f1_score: 0.8276 - val_loss: 0.9423 - val_sensitivity: 0.8571 - val_specificity: 0.7500\nEpoch 129/1000\n\nEpoch 129: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.3826e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.8000 - val_loss: 0.9444 - val_sensitivity: 0.8571 - val_specificity: 0.6667\nEpoch 130/1000\n\nEpoch 130: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1409e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9408 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 131/1000\n\nEpoch 131: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0950e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9399 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 132/1000\n\nEpoch 132: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1076e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7692 - val_f1_score: 0.7857 - val_loss: 0.9413 - val_sensitivity: 0.7857 - val_specificity: 0.7500\nEpoch 133/1000\n\nEpoch 133: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.1745e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7586 - val_loss: 0.9488 - val_sensitivity: 0.7857 - val_specificity: 0.6667\nEpoch 134/1000\n\nEpoch 134: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.0410e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7586 - val_loss: 0.9550 - val_sensitivity: 0.7857 - val_specificity: 0.6667\nEpoch 135/1000\n\nEpoch 135: val_accuracy did not improve from 0.80769\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8935e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9609 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 136/1000\n\nEpoch 136: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8798e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9621 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 137/1000\n\nEpoch 137: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9100e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9606 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 138/1000\n\nEpoch 138: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9307e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9586 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 139/1000\n\nEpoch 139: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7419e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9570 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 140/1000\n\nEpoch 140: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8106e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7586 - val_loss: 0.9550 - val_sensitivity: 0.7857 - val_specificity: 0.6667\nEpoch 141/1000\n\nEpoch 141: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.9704e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9586 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 142/1000\n\nEpoch 142: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7339e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9602 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 143/1000\n\nEpoch 143: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8078e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9625 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 144/1000\n\nEpoch 144: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7449e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9640 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 145/1000\n\nEpoch 145: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6484e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9638 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 146/1000\n\nEpoch 146: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5630e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7586 - val_loss: 0.9632 - val_sensitivity: 0.7857 - val_specificity: 0.6667\nEpoch 147/1000\n\nEpoch 147: val_accuracy did not improve from 0.80769\n4/4 - 0s - 38ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.8989e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7586 - val_loss: 0.9640 - val_sensitivity: 0.7857 - val_specificity: 0.6667\nEpoch 148/1000\n\nEpoch 148: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7437e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9657 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 149/1000\n\nEpoch 149: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5222e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9673 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 150/1000\n\nEpoch 150: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6284e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9665 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 151/1000\n\nEpoch 151: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7166e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9647 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 152/1000\n\nEpoch 152: val_accuracy did not improve from 0.80769\n4/4 - 0s - 36ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5998e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9635 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 153/1000\n\nEpoch 153: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.5179e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9622 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 154/1000\n\nEpoch 154: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6905e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9651 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 155/1000\n\nEpoch 155: val_accuracy did not improve from 0.80769\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6525e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9711 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 156/1000\n\nEpoch 156: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.7291e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9767 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 157/1000\n\nEpoch 157: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.4238e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9833 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 158/1000\n\nEpoch 158: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.2892e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.7308 - val_f1_score: 0.7742 - val_loss: 0.9821 - val_sensitivity: 0.8571 - val_specificity: 0.5833\nEpoch 159/1000\n\nEpoch 159: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.6132e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9724 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 160/1000\n\nEpoch 160: val_accuracy did not improve from 0.80769\n4/4 - 0s - 37ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 1.3832e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.6923 - val_f1_score: 0.7333 - val_loss: 0.9679 - val_sensitivity: 0.7857 - val_specificity: 0.5833\nEpoch 160: early stopping\nRestoring model weights from the end of the best epoch: 60.\n\n=== Fold 5/5 ===\nEpoch 1/1000\n\nEpoch 1: val_accuracy improved from -inf to 0.44000, saving model to best_model_fold5.keras\n4/4 - 19s - 5s/step - accuracy: 0.5577 - f1_score: 0.6567 - loss: 0.6927 - sensitivity: 0.8302 - specificity: 0.2745 - val_accuracy: 0.4400 - val_f1_score: 0.5882 - val_loss: 0.7841 - val_sensitivity: 0.7692 - val_specificity: 0.0833\nEpoch 2/1000\n\nEpoch 2: val_accuracy improved from 0.44000 to 0.52000, saving model to best_model_fold5.keras\n4/4 - 0s - 60ms/step - accuracy: 0.7115 - f1_score: 0.7656 - loss: 0.6552 - sensitivity: 0.9245 - specificity: 0.4902 - val_accuracy: 0.5200 - val_f1_score: 0.6842 - val_loss: 1.0245 - val_sensitivity: 1.0000 - val_specificity: 0.0000e+00\nEpoch 3/1000\n\nEpoch 3: val_accuracy did not improve from 0.52000\n4/4 - 0s - 44ms/step - accuracy: 0.6346 - f1_score: 0.7324 - loss: 0.6194 - sensitivity: 0.9811 - specificity: 0.2745 - val_accuracy: 0.4800 - val_f1_score: 0.6286 - val_loss: 0.8244 - val_sensitivity: 0.8462 - val_specificity: 0.0833\nEpoch 4/1000\n\nEpoch 4: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 0.9135 - f1_score: 0.9159 - loss: 0.5820 - sensitivity: 0.9245 - specificity: 0.9020 - val_accuracy: 0.4800 - val_f1_score: 0.6486 - val_loss: 0.9315 - val_sensitivity: 0.9231 - val_specificity: 0.0000e+00\nEpoch 5/1000\n\nEpoch 5: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 0.7692 - f1_score: 0.8154 - loss: 0.5344 - sensitivity: 1.0000 - specificity: 0.5294 - val_accuracy: 0.4000 - val_f1_score: 0.5714 - val_loss: 1.0587 - val_sensitivity: 0.7692 - val_specificity: 0.0000e+00\nEpoch 6/1000\n\nEpoch 6: val_accuracy did not improve from 0.52000\n4/4 - 0s - 44ms/step - accuracy: 0.9327 - f1_score: 0.9358 - loss: 0.4503 - sensitivity: 0.9623 - specificity: 0.9020 - val_accuracy: 0.4000 - val_f1_score: 0.5161 - val_loss: 1.0656 - val_sensitivity: 0.6154 - val_specificity: 0.1667\nEpoch 7/1000\n\nEpoch 7: val_accuracy did not improve from 0.52000\n4/4 - 0s - 44ms/step - accuracy: 0.9038 - f1_score: 0.9123 - loss: 0.3797 - sensitivity: 0.9811 - specificity: 0.8235 - val_accuracy: 0.3600 - val_f1_score: 0.4286 - val_loss: 1.0158 - val_sensitivity: 0.4615 - val_specificity: 0.2500\nEpoch 8/1000\n\nEpoch 8: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 0.9615 - f1_score: 0.9608 - loss: 0.2821 - sensitivity: 0.9245 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4828 - val_loss: 1.1832 - val_sensitivity: 0.5385 - val_specificity: 0.2500\nEpoch 9/1000\n\nEpoch 9: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 0.9904 - f1_score: 0.9905 - loss: 0.2065 - sensitivity: 0.9811 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.3333 - val_loss: 1.3445 - val_sensitivity: 0.3077 - val_specificity: 0.4167\nEpoch 10/1000\n\nEpoch 10: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 0.9327 - f1_score: 0.9307 - loss: 0.2080 - sensitivity: 0.8868 - specificity: 0.9804 - val_accuracy: 0.4800 - val_f1_score: 0.6486 - val_loss: 1.9464 - val_sensitivity: 0.9231 - val_specificity: 0.0000e+00\nEpoch 11/1000\n\nEpoch 11: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 0.9231 - f1_score: 0.9298 - loss: 0.2033 - sensitivity: 1.0000 - specificity: 0.8431 - val_accuracy: 0.4400 - val_f1_score: 0.2222 - val_loss: 1.8481 - val_sensitivity: 0.1538 - val_specificity: 0.7500\nEpoch 12/1000\n\nEpoch 12: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 0.9327 - f1_score: 0.9307 - loss: 0.2322 - sensitivity: 0.8868 - specificity: 0.9804 - val_accuracy: 0.5200 - val_f1_score: 0.6667 - val_loss: 2.2050 - val_sensitivity: 0.9231 - val_specificity: 0.0833\nEpoch 13/1000\n\nEpoch 13: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 0.9712 - f1_score: 0.9720 - loss: 0.1397 - sensitivity: 0.9811 - specificity: 0.9608 - val_accuracy: 0.3600 - val_f1_score: 0.3846 - val_loss: 1.4631 - val_sensitivity: 0.3846 - val_specificity: 0.3333\nEpoch 14/1000\n\nEpoch 14: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 0.9904 - f1_score: 0.9905 - loss: 0.0692 - sensitivity: 0.9811 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.5625 - val_loss: 1.6765 - val_sensitivity: 0.6923 - val_specificity: 0.1667\nEpoch 15/1000\n\nEpoch 15: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 0.9904 - f1_score: 0.9907 - loss: 0.0869 - sensitivity: 1.0000 - specificity: 0.9804 - val_accuracy: 0.3600 - val_f1_score: 0.3846 - val_loss: 1.4431 - val_sensitivity: 0.3846 - val_specificity: 0.3333\nEpoch 16/1000\n\nEpoch 16: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0488 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.3846 - val_loss: 1.5312 - val_sensitivity: 0.3846 - val_specificity: 0.3333\nEpoch 17/1000\n\nEpoch 17: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0342 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.5333 - val_loss: 1.7366 - val_sensitivity: 0.6154 - val_specificity: 0.2500\nEpoch 18/1000\n\nEpoch 18: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0331 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4444 - val_loss: 1.6490 - val_sensitivity: 0.4615 - val_specificity: 0.3333\nEpoch 19/1000\n\nEpoch 19: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0199 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.6961 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 20/1000\n\nEpoch 20: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0148 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.7393 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 21/1000\n\nEpoch 21: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0136 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.7852 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 22/1000\n\nEpoch 22: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0105 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8893 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 23/1000\n\nEpoch 23: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0181 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4444 - val_loss: 1.9452 - val_sensitivity: 0.4615 - val_specificity: 0.3333\nEpoch 24/1000\n\nEpoch 24: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0145 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.4286 - val_loss: 2.0808 - val_sensitivity: 0.4615 - val_specificity: 0.2500\nEpoch 25/1000\n\nEpoch 25: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0107 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4444 - val_loss: 2.0802 - val_sensitivity: 0.4615 - val_specificity: 0.3333\nEpoch 26/1000\n\nEpoch 26: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0074 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.3846 - val_loss: 2.1420 - val_sensitivity: 0.3846 - val_specificity: 0.3333\nEpoch 27/1000\n\nEpoch 27: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0065 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.3846 - val_loss: 2.1637 - val_sensitivity: 0.3846 - val_specificity: 0.3333\nEpoch 28/1000\n\nEpoch 28: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0046 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.3846 - val_loss: 2.1550 - val_sensitivity: 0.3846 - val_specificity: 0.3333\nEpoch 29/1000\n\nEpoch 29: val_accuracy did not improve from 0.52000\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0042 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4444 - val_loss: 2.1145 - val_sensitivity: 0.4615 - val_specificity: 0.3333\nEpoch 30/1000\n\nEpoch 30: val_accuracy did not improve from 0.52000\n4/4 - 0s - 48ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0034 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.3600 - val_f1_score: 0.3846 - val_loss: 2.0676 - val_sensitivity: 0.3846 - val_specificity: 0.3333\nEpoch 31/1000\n\nEpoch 31: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0030 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 2.0230 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 32/1000\n\nEpoch 32: val_accuracy did not improve from 0.52000\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0027 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.9874 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 33/1000\n\nEpoch 33: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0023 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.9590 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 34/1000\n\nEpoch 34: val_accuracy did not improve from 0.52000\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.9369 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 35/1000\n\nEpoch 35: val_accuracy did not improve from 0.52000\n4/4 - 0s - 47ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0022 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.9234 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 36/1000\n\nEpoch 36: val_accuracy did not improve from 0.52000\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.9227 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 37/1000\n\nEpoch 37: val_accuracy did not improve from 0.52000\n4/4 - 0s - 45ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.9156 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 38/1000\n\nEpoch 38: val_accuracy did not improve from 0.52000\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.9174 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 39/1000\n\nEpoch 39: val_accuracy did not improve from 0.52000\n4/4 - 0s - 46ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0017 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.9115 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 40/1000\n\nEpoch 40: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0016 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.9044 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 41/1000\n\nEpoch 41: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8956 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 42/1000\n\nEpoch 42: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0014 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8857 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 43/1000\n\nEpoch 43: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8755 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 44/1000\n\nEpoch 44: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8634 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 45/1000\n\nEpoch 45: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8529 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 46/1000\n\nEpoch 46: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0013 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8507 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 47/1000\n\nEpoch 47: val_accuracy did not improve from 0.52000\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0012 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8461 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 48/1000\n\nEpoch 48: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8426 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 49/1000\n\nEpoch 49: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0011 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8387 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 50/1000\n\nEpoch 50: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8342 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 51/1000\n\nEpoch 51: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0010 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8322 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 52/1000\n\nEpoch 52: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.2369e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8290 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 53/1000\n\nEpoch 53: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.6594e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8268 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 54/1000\n\nEpoch 54: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 9.0123e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8322 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 55/1000\n\nEpoch 55: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.6222e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8342 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 56/1000\n\nEpoch 56: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.1203e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8388 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 57/1000\n\nEpoch 57: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.4590e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8411 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 58/1000\n\nEpoch 58: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 8.0670e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8396 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 59/1000\n\nEpoch 59: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6210e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8379 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 60/1000\n\nEpoch 60: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.6626e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8368 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 61/1000\n\nEpoch 61: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.2760e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.8355 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 62/1000\n\nEpoch 62: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.4929e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8349 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 63/1000\n\nEpoch 63: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.6327e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8376 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 64/1000\n\nEpoch 64: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 7.3153e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8402 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 65/1000\n\nEpoch 65: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.1525e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8424 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 66/1000\n\nEpoch 66: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.5321e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8416 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 67/1000\n\nEpoch 67: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.3969e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8405 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 68/1000\n\nEpoch 68: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.9530e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8429 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 69/1000\n\nEpoch 69: val_accuracy did not improve from 0.52000\n4/4 - 0s - 43ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 6.0056e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8521 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 70/1000\n\nEpoch 70: val_accuracy did not improve from 0.52000\n4/4 - 0s - 42ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8739e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8606 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 71/1000\n\nEpoch 71: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.9457e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8632 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 72/1000\n\nEpoch 72: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.8730e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8605 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 73/1000\n\nEpoch 73: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.7612e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8512 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 74/1000\n\nEpoch 74: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1866e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8468 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 75/1000\n\nEpoch 75: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1729e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8460 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 76/1000\n\nEpoch 76: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 5.1039e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8488 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 77/1000\n\nEpoch 77: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7768e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8530 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 78/1000\n\nEpoch 78: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.8395e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8564 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 79/1000\n\nEpoch 79: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.6768e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8585 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 80/1000\n\nEpoch 80: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.4228e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8610 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 81/1000\n\nEpoch 81: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.7143e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8634 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 82/1000\n\nEpoch 82: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.3416e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8695 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 83/1000\n\nEpoch 83: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1798e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8712 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 84/1000\n\nEpoch 84: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.2364e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8686 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 85/1000\n\nEpoch 85: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 4.1965e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8628 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 86/1000\n\nEpoch 86: val_accuracy did not improve from 0.52000\n4/4 - 0s - 44ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9793e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8574 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 87/1000\n\nEpoch 87: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9256e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8545 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 88/1000\n\nEpoch 88: val_accuracy did not improve from 0.52000\n4/4 - 0s - 41ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.7796e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.8533 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 89/1000\n\nEpoch 89: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6953e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4400 - val_f1_score: 0.4615 - val_loss: 1.8563 - val_sensitivity: 0.4615 - val_specificity: 0.4167\nEpoch 90/1000\n\nEpoch 90: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.6968e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8600 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 91/1000\n\nEpoch 91: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.9279e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8637 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 92/1000\n\nEpoch 92: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4533e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8722 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 93/1000\n\nEpoch 93: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.4177e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8816 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 94/1000\n\nEpoch 94: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2045e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8857 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 95/1000\n\nEpoch 95: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3669e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8855 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 96/1000\n\nEpoch 96: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.2459e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8840 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 97/1000\n\nEpoch 97: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.3081e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8862 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 98/1000\n\nEpoch 98: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.1712e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8834 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 99/1000\n\nEpoch 99: val_accuracy did not improve from 0.52000\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 3.0532e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8830 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 100/1000\n\nEpoch 100: val_accuracy did not improve from 0.52000\n4/4 - 0s - 39ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9994e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8819 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 101/1000\n\nEpoch 101: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.8923e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8814 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 102/1000\n\nEpoch 102: val_accuracy did not improve from 0.52000\n4/4 - 0s - 40ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 2.9276e-04 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.4000 - val_f1_score: 0.4000 - val_loss: 1.8831 - val_sensitivity: 0.3846 - val_specificity: 0.4167\nEpoch 102: early stopping\nRestoring model weights from the end of the best epoch: 2.\n\n--- TRAIN   (best model por fold) ---\naccuracy    : 0.8107 ± 0.2151\nspecificity : 0.6926 ± 0.4088\nsensitivity : 0.9243 ± 0.1286\nf1_score    : 0.8477 ± 0.1586\n\n--- VALIDATION (best model por fold) ---\naccuracy    : 0.6578 ± 0.0903\nspecificity : 0.4872 ± 0.2815\nsensitivity : 0.8187 ± 0.1386\nf1_score    : 0.7104 ± 0.0547\n\n--- EVALUATION  (best model por fold) ---\naccuracy    : 0.5274 ± 0.0364\nspecificity : 0.2971 ± 0.1556\nsensitivity : 0.7754 ± 0.1552\nf1_score    : 0.6081 ± 0.0556\n","output_type":"stream"}],"execution_count":11}]}