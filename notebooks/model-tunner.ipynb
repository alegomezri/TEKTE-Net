{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5137200,"sourceType":"datasetVersion","datasetId":2984453}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Tuning Takens + Transfer Entropy (Keras-Tuner)**\nThis notebook performs hyperparameter search for the TakensConv1D block (dx, dy, tau, mu), which is used to build Takens embeddings and compute Transfer Entropy (TE) between EEG channels","metadata":{}},{"cell_type":"markdown","source":"# Setup (dependencies and data)","metadata":{}},{"cell_type":"code","source":"!pip show tensorflow tensorflow-probability\n!pip install tensorflow-probability==0.24.0\n!pip install --upgrade keras-tuner\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n!pip install mne #The MNE Package is installed\nFILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n!unzip MI_EEG_ClassMeth.zip -y #Package with useful functions for motor imagery classification based in EEG.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n!dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T14:42:13.088906Z","iopub.execute_input":"2025-06-19T14:42:13.089348Z","iopub.status.idle":"2025-06-19T14:43:05.999569Z","shell.execute_reply.started":"2025-06-19T14:42:13.089328Z","shell.execute_reply":"2025-06-19T14:43:05.998703Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Name: tensorflow\nVersion: 2.18.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\nRequired-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n---\nName: tensorflow-probability\nVersion: 0.25.0\nSummary: Probabilistic modeling and statistical inference in TensorFlow\nHome-page: http://github.com/tensorflow/probability\nAuthor: Google LLC\nAuthor-email: no-reply@google.com\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: absl-py, cloudpickle, decorator, dm-tree, gast, numpy, six\nRequired-by: dopamine_rl\nCollecting tensorflow-probability==0.24.0\n  Downloading tensorflow_probability-0.24.0-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.4.0)\nRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.17.0)\nRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.26.4)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (4.4.2)\nRequirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (3.1.1)\nRequirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (0.6.0)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (0.1.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2.4.1)\nRequirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.24.0) (25.3.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.24.0) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nDownloading tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow-probability\n  Attempting uninstall: tensorflow-probability\n    Found existing installation: tensorflow-probability 0.25.0\n    Uninstalling tensorflow-probability-0.25.0:\n      Successfully uninstalled tensorflow-probability-0.25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-probability-0.24.0\nRequirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\nRequirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\nRequirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras->keras-tuner) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras->keras-tuner) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras->keras-tuner) (2024.2.0)\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.databases\n  Cloning https://github.com/UN-GCPDS/python-gcpds.databases to /tmp/pip-req-build-201loldc\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.databases /tmp/pip-req-build-201loldc\n  Resolved https://github.com/UN-GCPDS/python-gcpds.databases to commit d174df9958b6638156dcfe03996a6307e631a6a2\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.15.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (3.7.2)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.9.0)\nRequirement already satisfied: tables in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (3.10.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (4.67.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (2.2.3)\nRequirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (2.32.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2.4.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (0.4)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (1.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gcpds-databases==0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gcpds-databases==0.2) (2025.2)\nRequirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (2.10.2)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (9.0.0)\nRequirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (3.2.1)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (4.13.2)\nRequirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.9.2)\nRequirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.1.0)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (4.3.8)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->gcpds-databases==0.2) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->gcpds-databases==0.2) (2.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne->gcpds-databases==0.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-databases==0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-databases==0.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->gcpds-databases==0.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->gcpds-databases==0.2) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2025.4.26)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->gcpds-databases==0.2) (2024.2.0)\nBuilding wheels for collected packages: gcpds-databases\n  Building wheel for gcpds-databases (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gcpds-databases: filename=gcpds_databases-0.2-py3-none-any.whl size=32972809 sha256=b17cdb0d48f37eac4fcbf7506505e0048aca70f8d39f0f898e76b57211c31322\n  Stored in directory: /tmp/pip-ephem-wheel-cache-8lffq595/wheels/ae/48/8d/edf617d5fe8f03b17aa26306a04abdfcc605b218d8e6deac83\nSuccessfully built gcpds-databases\nInstalling collected packages: gcpds-databases\nSuccessfully installed gcpds-databases-0.2\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n  Cloning https://github.com/UN-GCPDS/python-gcpds.visualizations.git to /tmp/pip-req-build-34zhkl9j\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.visualizations.git /tmp/pip-req-build-34zhkl9j\n  Resolved https://github.com/UN-GCPDS/python-gcpds.visualizations.git to commit 162dbeac141a7472d3b0bd7f005932241b4663a5\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting python-circos (from gcpds-visualizations==0.6)\n  Downloading python_circos-0.3.0-py3-none-any.whl.metadata (766 bytes)\nRequirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (1.26.4)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (1.9.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2.4.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (0.4)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (4.67.1)\nCollecting biopython>=1.78 (from python-circos->gcpds-visualizations==0.6)\n  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (2.32.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne->gcpds-visualizations==0.6) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-visualizations==0.6) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->gcpds-visualizations==0.6) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (2025.4.26)\nDownloading python_circos-0.3.0-py3-none-any.whl (27 kB)\nDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: gcpds-visualizations\n  Building wheel for gcpds-visualizations (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gcpds-visualizations: filename=gcpds_visualizations-0.6-py3-none-any.whl size=12440 sha256=ddfb98faed5e50f3878b73b43dbb55d97628c539f51ee993d8697a524590783c\n  Stored in directory: /tmp/pip-ephem-wheel-cache-g5gy44y5/wheels/12/e9/11/f7246de13d1d668c154d68fb1260be82dbfbc166301807d756\nSuccessfully built gcpds-visualizations\nInstalling collected packages: biopython, python-circos, gcpds-visualizations\nSuccessfully installed biopython-1.85 gcpds-visualizations-0.6 python-circos-0.3.0\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\nRequirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.7.2)\nRequirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (25.0)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->mne) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.23->mne) (2024.2.0)\n--2025-06-19 14:42:53--  https://docs.google.com/uc?export=download&confirm=&id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\nResolving docs.google.com (docs.google.com)... 142.251.189.100, 142.251.189.138, 142.251.189.113, ...\nConnecting to docs.google.com (docs.google.com)|142.251.189.100|:443... connected.\nHTTP request sent, awaiting response... 303 See Other\nLocation: https://drive.usercontent.google.com/download?id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7&export=download [following]\n--2025-06-19 14:42:53--  https://drive.usercontent.google.com/download?id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7&export=download\nResolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.152.132, 2607:f8b0:4001:c56::84\nConnecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.152.132|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 86900 (85K) [application/octet-stream]\nSaving to: ‘MI_EEG_ClassMeth.zip’\n\nMI_EEG_ClassMeth.zi 100%[===================>]  84.86K  --.-KB/s    in 0.009s  \n\n2025-06-19 14:42:55 (8.77 MB/s) - ‘MI_EEG_ClassMeth.zip’ saved [86900/86900]\n\nArchive:  MI_EEG_ClassMeth.zip\ncaution: filename not matched:  -y\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n  Cloning https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to /tmp/pip-req-build-bz2hljv7\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git /tmp/pip-req-build-bz2hljv7\n  Resolved https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to commit 0c791f236d503dac4829adb78cdba759c5843417\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting braindecode==0.7 (from EEG_Tensorflow_models==0.2)\n  Downloading Braindecode-0.7-py3-none-any.whl.metadata (6.8 kB)\nCollecting moabb (from EEG_Tensorflow_models==0.2)\n  Downloading moabb-1.2.0-py3-none-any.whl.metadata (14 kB)\nCollecting tensorflow-addons (from EEG_Tensorflow_models==0.2)\n  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: tensorflow>=2.8 in /usr/local/lib/python3.11/dist-packages (from EEG_Tensorflow_models==0.2) (2.18.0)\nCollecting tf-keras-vis (from EEG_Tensorflow_models==0.2)\n  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.15.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.7.2)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.13.0)\nCollecting skorch (from braindecode==0.7->EEG_Tensorflow_models==0.2)\n  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.8.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.37.1)\nRequirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (6.0.2)\nRequirement already satisfied: coverage<8.0.0,>=7.0.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (7.8.0)\nCollecting edfio<0.5.0,>=0.4.2 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading edfio-0.4.9-py3-none-any.whl.metadata (3.9 kB)\nCollecting edflib-python<2.0.0,>=1.0.6 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\nCollecting memory-profiler<0.62.0,>=0.61.0 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\nCollecting mne-bids>=0.14 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading mne_bids-0.16.0-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (1.8.2)\nCollecting pyriemann<0.8,>=0.7 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading pyriemann-0.7-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: scikit-learn<1.6 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (1.2.2)\nRequirement already satisfied: seaborn<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (0.12.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (4.67.1)\nCollecting urllib3<2.0.0,>=1.26.15 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->EEG_Tensorflow_models==0.2)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (11.1.0)\nRequirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (1.2.18)\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (2.37.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.14.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.9.0.post0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory-profiler<0.62.0,>=0.61.0->moabb->EEG_Tensorflow_models==0.2) (7.0.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.2)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch<2.0.0,>=1.6.0->moabb->EEG_Tensorflow_models==0.2) (4.3.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pyriemann<0.8,>=0.7->moabb->EEG_Tensorflow_models==0.2) (1.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2025.4.26)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6->moabb->EEG_Tensorflow_models==0.2) (3.6.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.1.3)\nRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.9.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.1.2)\nDownloading Braindecode-0.7-py3-none-any.whl (184 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading moabb-1.2.0-py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading edfio-0.4.9-py3-none-any.whl (27 kB)\nDownloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\nDownloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\nDownloading mne_bids-0.16.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyriemann-0.7-py2.py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading skorch-1.1.0-py3-none-any.whl (228 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: EEG_Tensorflow_models\n  Building wheel for EEG_Tensorflow_models (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for EEG_Tensorflow_models: filename=EEG_Tensorflow_models-0.2-py3-none-any.whl size=29287 sha256=4570398d23236793b2df5e5bf1025d990c7aa68c88c2242b59eec7403b09d53d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-gbnkrh3z/wheels/ec/2b/bd/488f6c2631523174d34618ee5e61f72194b1389c81838cfd71\nSuccessfully built EEG_Tensorflow_models\nInstalling collected packages: urllib3, typeguard, memory-profiler, tensorflow-addons, skorch, pyriemann, mne-bids, edflib-python, edfio, tf-keras-vis, moabb, braindecode, EEG_Tensorflow_models\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.4.0\n    Uninstalling urllib3-2.4.0:\n      Successfully uninstalled urllib3-2.4.0\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.4.2\n    Uninstalling typeguard-4.4.2:\n      Successfully uninstalled typeguard-4.4.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ninflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed EEG_Tensorflow_models-0.2 braindecode-0.7 edfio-0.4.9 edflib-python-1.0.8 memory-profiler-0.61.0 mne-bids-0.16.0 moabb-1.2.0 pyriemann-0.7 skorch-1.1.0 tensorflow-addons-0.23.0 tf-keras-vis-0.8.7 typeguard-2.13.3 urllib3-1.26.20\nMI_EEG_ClassMeth.zip\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Imports and utilities","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport itertools\nimport random\nimport pickle\nimport mne\nimport h5py\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport matplotlib.pyplot as plt\nimport keras_tuner as kt\n\n\nfrom gcpds.databases.BCI_Competition_IV import Dataset_2a\nfrom typing import Sequence, Tuple\nfrom scipy.signal import iirnotch, filtfilt, butter, freqz\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\nimport networkx as nx\nfrom tqdm import tqdm\nfrom mne.preprocessing import compute_current_source_density\nfrom mne.channels import make_standard_montage, read_custom_montage\nfrom scipy.signal import butter, filtfilt, resample, iirnotch\nfrom gcpds.visualizations.series import plot_eeg\nfrom scipy.stats import norm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score\nfrom tqdm import tqdm\n\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom gcpds.databases import GIGA_MI_ME\nfrom sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom tensorflow.keras.utils import register_keras_serializable\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import LeavePGroupsOut, StratifiedGroupKFold\nfrom tensorflow.keras.models import Model\nfrom scipy.spatial.distance import cdist\nfrom sklearn.model_selection import GroupKFold\nfrom tensorflow.keras.models import load_model\n\nfrom keras_tuner import Objective\nfrom keras_tuner import HyperModel\nfrom keras.layers import Layer, Activation\nfrom keras_tuner import BayesianOptimization\nfrom keras_tuner.engine.hyperparameters import HyperParameters\nfrom tensorflow.keras.metrics import BinaryAccuracy, Recall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:15:54.420152Z","iopub.execute_input":"2025-06-19T16:15:54.420435Z","iopub.status.idle":"2025-06-19T16:15:54.428217Z","shell.execute_reply.started":"2025-06-19T16:15:54.420416Z","shell.execute_reply":"2025-06-19T16:15:54.427628Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def load_BCICIV2a(db, sbj: int, mode: str, fs: float) -> tuple:\n    \"\"\"\n    Load EEG data for a specific subject with preprocessing, including filtering and surface Laplacian.\n    The signal is cropped to the 2–4 second interval, and only the left-hand (0) and right-hand (1) classes are included\n    \n    Args:\n        db (Dataset_2a): Dataset object.\n        sbj (int): Subject identifier (1–9).\n        mode (str): 'training' or 'testing'.\n        fs (float): Sampling frequency.\n\n    Returns:\n        tuple: Preprocessed EEG data with surface Laplacian and time-cropped segment (X), and corresponding labels (y).\n    \"\"\"\n    # Load the subject's data\n    db.load_subject(sbj, mode=mode)\n    X, y = db.get_data()# Data and labels\n    X = X[:, :-3, :]# Select only the EEG channels (22 channels)\n    X = X * 1e6# Convert to microvolts\n\n    # Apply a notch filter (50 Hz)\n    notch_freq = 50.0\n    q_factor = 30.0\n    b_notch, a_notch = iirnotch(w0=notch_freq, Q=q_factor, fs=fs)\n    X = filtfilt(b_notch, a_notch, X, axis=2)\n\n    # Apply a band-pass filter (0.5–100 Hz)\n    lowcut = 0.5\n    highcut = 100.0\n    b_band, a_band = butter(N=4, Wn=[lowcut, highcut], btype='bandpass', fs=fs)\n    X = filtfilt(b_band, a_band, X, axis=2)\n\n    # Crop the data between 2 and 4 seconds\n    start_sample = int(2 * fs)# Start at 2 seconds\n    end_sample = int(4 * fs)# End at 4 seconds\n    X = X[:, :, start_sample:end_sample]\n\n    # Keep only the classes of interest (1: left hand, 2: right hand)\n    clases = [0, 1]\n    mask = np.isin(y, clases)\n    X = X[mask]\n    y = y[mask]\n\n    # List of the 22 EEG channel names (excluding EOG)\n    eeg_channel_names = [\n        'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4',\n        'C6', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'P1', 'Pz', 'P2', 'POz'\n    ]\n\n    # Create channel information for the EEG channels\n    info = mne.create_info(\n        ch_names=eeg_channel_names,\n        sfreq=fs,  \n        ch_types=[\"eeg\"] * len(eeg_channel_names) \n    )\n\n    # Load a standard montage based on the 10–20 system\n    montage = mne.channels.make_standard_montage('standard_1020')\n    info.set_montage(montage)\n\n    # Apply surface Laplacian computation \n    laplacian_X = []\n    for trial in X:\n        # Create a RawArray object for each trial\n        raw = mne.io.RawArray(trial, info)\n        # Compute the surface Laplacian\n        raw = mne.preprocessing.compute_current_source_density(raw)\n        # Get the data with the Laplacian applied\n        laplacian_X.append(raw.get_data())\n\n    X = np.stack(laplacian_X)\n\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:15:58.180144Z","iopub.execute_input":"2025-06-19T16:15:58.180877Z","iopub.status.idle":"2025-06-19T16:15:58.188760Z","shell.execute_reply.started":"2025-06-19T16:15:58.180854Z","shell.execute_reply":"2025-06-19T16:15:58.188005Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Custom layers and metrics","metadata":{}},{"cell_type":"code","source":"@register_keras_serializable(package=\"CustomLayers\")\nclass TakensConv1D(tf.keras.layers.Layer):\n    def __init__(self, dx=5, dy=5, tau=1, mu=4, **kwargs):\n        super().__init__(**kwargs)\n        self.dx = int(dx)\n        self.dy = int(dy)\n        self.tau = int(tau)\n        self.mu = int(mu)\n        self.num_filters = self.dx + self.dy + 1\n\n    def build(self, input_shape):\n        kernel_size = self.mu + (self.dx - 1) * self.tau + 1\n        kernel_shape = (kernel_size, 1, self.num_filters)\n        kernel = tf.zeros(kernel_shape, dtype=tf.float32)\n\n        offsets_x = self.mu + tf.range(self.dx) * self.tau\n        offsets_y = tf.range(1, self.dy + 1) * self.tau\n        offset_y_t = tf.constant([0], dtype=tf.int32)\n\n        filas_x = tf.range(self.dx)\n        filas_y = self.dx + tf.range(self.dy)\n        fila_y_t = tf.constant([self.dx + self.dy])\n\n        cols_x = filas_x\n        cols_y = filas_y\n        col_y_t = fila_y_t\n\n        idx_x = tf.stack([filas_x, offsets_x, cols_x], axis=1)\n        idx_y = tf.stack([filas_y, offsets_y, cols_y], axis=1)\n        idx_yt = tf.stack([fila_y_t, offset_y_t, col_y_t], axis=1)\n\n        indices_total = tf.concat([idx_x, idx_y, idx_yt], axis=0)\n        updates = tf.ones([tf.shape(indices_total)[0]], dtype=tf.float32)\n\n        sort_order = tf.argsort(indices_total[:, 0])\n        indices_sorted = tf.gather(indices_total, sort_order)\n\n        row_for_scatter = tf.cast(indices_sorted[:, 1], tf.int32)\n        col_for_scatter = tf.cast(indices_sorted[:, 2], tf.int32)\n\n        final_indices = tf.stack([row_for_scatter,\n                                  tf.zeros_like(row_for_scatter),\n                                  col_for_scatter], axis=1)\n\n        kernel = tf.scatter_nd(final_indices, updates, kernel_shape)\n        self.kernel = kernel.numpy()[::-1]\n\n        self.conv1d = tf.keras.layers.Conv1D(\n            filters=self.num_filters,\n            kernel_size=kernel_size,\n            strides=self.tau,\n            padding=\"valid\",\n            use_bias=False\n        )\n        self.conv1d.build((None, input_shape[2], 1))\n        self.conv1d.set_weights([self.kernel])\n        self.conv1d.trainable=False\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        channels = tf.shape(inputs)[1]\n        time_steps = tf.shape(inputs)[2]\n\n        reshaped = tf.reshape(inputs, (-1, time_steps, 1))\n        conv_output = self.conv1d(reshaped)\n        new_time = tf.shape(conv_output)[1]\n\n        output = tf.reshape(conv_output, \n                            (batch_size, channels, new_time, self.num_filters))\n\n        x_sub_t_minus_mu = output[..., :self.dx]\n        y_sub_t_minus_1 = output[..., self.dx:self.dx + self.dy]\n        y_sub_t = output[..., -1:]\n\n        return x_sub_t_minus_mu, y_sub_t_minus_1, y_sub_t\n       \n\n@register_keras_serializable(package=\"CustomLayers\")\nclass KernelLayer(tf.keras.layers.Layer):\n    def __init__(self, \n                 amplitude=1.0,\n                 trainable_amplitude=False, \n                 length_scale=1.0,\n                 trainable_length_scale=False,\n                 alpha=1.0,  # Only used for Rational Quadratic\n                 trainable_alpha=False,\n                 kernel_type=\"gaussian\",  # \"gaussian\" or \"rational_quadratic\"\n                 **kwargs):\n        super(KernelLayer, self).__init__(**kwargs)\n\n        self.init_amplitude = amplitude\n        self.trainable_amplitude = trainable_amplitude\n        self.init_length_scale = length_scale\n        self.trainable_length_scale = trainable_length_scale\n        self.init_alpha = alpha\n        self.trainable_alpha = trainable_alpha\n        self.kernel_type = kernel_type.lower()\n\n    def build(self, input_shape):\n        self.amplitude = self.add_weight(\n            name=\"amplitude\",\n            shape=(),\n            initializer=tf.constant_initializer(self.init_amplitude),\n            trainable=self.trainable_amplitude,\n            dtype=self.dtype\n        )\n\n        self.length_scale = self.add_weight(\n            name=\"length_scale\",\n            shape=(),\n            initializer=tf.constant_initializer(self.init_length_scale),\n            trainable=self.trainable_length_scale,\n            dtype=self.dtype\n        )\n\n        if self.kernel_type == \"rational_quadratic\":\n            self.alpha = self.add_weight(\n                name=\"alpha\",\n                shape=(),\n                initializer=tf.constant_initializer(self.init_alpha),\n                trainable=self.trainable_alpha,\n                dtype=self.dtype\n            )\n\n        super(KernelLayer, self).build(input_shape)\n\n    def call(self, X):\n        if self.kernel_type == \"gaussian\":\n            kernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n                amplitude=self.amplitude,\n                length_scale=self.length_scale\n            )\n        elif self.kernel_type == \"rational_quadratic\":\n            kernel = tfp.math.psd_kernels.RationalQuadratic(\n                amplitude=self.amplitude,\n                length_scale=self.length_scale,\n                scale_mixture_rate=self.alpha\n            )\n        else:\n            raise ValueError(f\"Unsupported kernel_type: {self.kernel_type}\")\n        \n        return kernel.matrix(X, X)\n       \n@register_keras_serializable(package=\"CustomLayers\")\nclass TransferEntropyLayer(tf.keras.layers.Layer):\n    def __init__(self, alpha=2, **kwargs):\n\n        super().__init__(**kwargs)\n        self.alpha = int(alpha)\n\n    def compute_entropy(self, K_hadamard):\n        \n        trace_hadamard = tf.reduce_sum(tf.linalg.diag_part(K_hadamard), axis=-1) \n        trace_hadamard = tf.expand_dims(tf.expand_dims(trace_hadamard, axis=-1), axis=-1)\n        K_normalized = K_hadamard / trace_hadamard\n\n        K_power = tf.linalg.matmul( K_normalized , K_normalized, grad_a=True, grad_b=True ) \n        trace_power = tf.reduce_sum(tf.linalg.diag_part(K_power), axis=-1)  \n        H_alpha = (1 / (1 - self.alpha)) * tf.math.log(trace_power)\n        return H_alpha\n\n    def call(self, K_x, K_y_minus_1, K_y):\n        \n        K_x_exp = tf.expand_dims(K_x, axis=2)\n        \n        K_y_minus_1_exp = tf.expand_dims(K_y_minus_1, axis=1)\n        K_y_exp = tf.expand_dims(K_y, axis=1)\n\n        \n        H_1 = self.compute_entropy(K_y_minus_1_exp * K_x_exp)\n        H_2 = self.compute_entropy(K_y_exp * K_y_minus_1_exp * K_x_exp)\n        H_3 = self.compute_entropy(K_y_exp * K_y_minus_1_exp)\n        H_4 = self.compute_entropy(K_y_minus_1_exp)\n\n        TE = H_1 - H_2 + H_3 - H_4\n        \n        return TE\n        \n@register_keras_serializable(package=\"CustomLayers\")      \nclass RemoveDiagonalFlatten(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n    \n        super().__init__(**kwargs)\n\n    def call(self, inputs):\n        \n        shape_dyn = tf.shape(inputs)  \n        batch_size = shape_dyn[0]\n        c = tf.shape(inputs)[1]\n\n        \n        tf.debugging.assert_equal(\n            tf.shape(inputs)[1], tf.shape(inputs)[2],\n            message=\"RemoveDiagonalFlatten: la matriz de entrada no es cuadrada.\"\n        )  \n        diag_mask = tf.eye(c, dtype=inputs.dtype)  \n        inputs_no_diag = inputs * (1 - diag_mask) \n        flattened = tf.reshape(inputs_no_diag, [batch_size, -1])  \n        non_diag = tf.boolean_mask(flattened, tf.reshape(1 - diag_mask, [-1]), axis=1)\n        num_features = c * (c - 1)  \n        result = tf.reshape(non_diag, [batch_size, num_features])  \n\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:16:24.215035Z","iopub.execute_input":"2025-06-19T16:16:24.215328Z","iopub.status.idle":"2025-06-19T16:16:24.237302Z","shell.execute_reply.started":"2025-06-19T16:16:24.215311Z","shell.execute_reply":"2025-06-19T16:16:24.236730Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# Additional custom metrics (Sensitivity/Specificity, etc.)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.metrics import Metric\n@register_keras_serializable(package=\"CustomMetrics\")\nclass Sensitivity(Metric):\n    def __init__(self, name='sensitivity', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = tf.keras.metrics.TruePositives()\n        self.fn = tf.keras.metrics.FalseNegatives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tp.update_state(y_true, y_pred, sample_weight)\n        self.fn.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        return self.tp.result() / (self.tp.result() + self.fn.result() + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.reset_states()\n        self.fn.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config\n\n\n@register_keras_serializable(package=\"CustomMetrics\")\nclass Accuracy(Metric):\n    def __init__(self, name='accuracy', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = tf.keras.metrics.TruePositives()\n        self.tn = tf.keras.metrics.TrueNegatives()\n        self.fp = tf.keras.metrics.FalsePositives()\n        self.fn = tf.keras.metrics.FalseNegatives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tp.update_state(y_true, y_pred, sample_weight)\n        self.tn.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n        self.fn.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        num = self.tp.result() + self.tn.result()\n        den = num + self.fp.result() + self.fn.result() + tf.keras.backend.epsilon()\n        return num / den\n\n    def reset_states(self):\n        self.tp.reset_states()\n        self.tn.reset_states()\n        self.fp.reset_states()\n        self.fn.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config\n\n\n@register_keras_serializable(package=\"CustomMetrics\")\nclass F1Score(Metric):\n    def __init__(self, name='f1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = tf.keras.metrics.TruePositives()\n        self.fp = tf.keras.metrics.FalsePositives()\n        self.fn = tf.keras.metrics.FalseNegatives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tp.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n        self.fn.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        precision = self.tp.result() / (self.tp.result() + self.fp.result() + tf.keras.backend.epsilon())\n        recall = self.tp.result() / (self.tp.result() + self.fn.result() + tf.keras.backend.epsilon())\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tp.reset_states()\n        self.fp.reset_states()\n        self.fn.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config\n\n\n@register_keras_serializable(package=\"CustomMetrics\")\nclass Specificity(Metric):\n    def __init__(self, name='specificity', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tn = tf.keras.metrics.TrueNegatives()\n        self.fp = tf.keras.metrics.FalsePositives()\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tn.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n\n    def result(self):\n        return self.tn.result() / (self.tn.result() + self.fp.result() + tf.keras.backend.epsilon())\n\n    def reset_states(self):\n        self.tn.reset_states()\n        self.fp.reset_states()\n\n    def get_config(self):\n        base_config = super().get_config()\n        return base_config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:17:04.244046Z","iopub.execute_input":"2025-06-19T16:17:04.244328Z","iopub.status.idle":"2025-06-19T16:17:04.259022Z","shell.execute_reply.started":"2025-06-19T16:17:04.244308Z","shell.execute_reply":"2025-06-19T16:17:04.258415Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Create a dataset instance\ndb = Dataset_2a(\"/kaggle/input/dataset-2a\")\nfs = 250.0\n\n# Load the subject's data in 'training' mode\nX, y = load_BCICIV2a(db, sbj=5, mode=\"training\", fs=fs)\nprint(\"X shape:\", X.shape)\nprint(\"y shape:\", y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:16:07.321570Z","iopub.execute_input":"2025-06-19T16:16:07.322228Z","iopub.status.idle":"2025-06-19T16:16:12.052704Z","shell.execute_reply.started":"2025-06-19T16:16:07.322199Z","shell.execute_reply":"2025-06-19T16:16:12.052045Z"}},"outputs":[{"name":"stdout","text":"tamaño de X: (129, 22, 500)\ntamaño de y: (129,)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"train_data, val_data, train_labels, val_labels = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=72,\n    stratify=y\n)\n\ndef create_tunable_model(dx, dy, tau, mu,\n                         kernel_type, learning_rate,\n                         kernel_size):\n    input_eeg = tf.keras.Input(shape=(22, 500), name=\"input_eeg\")\n\n    # Block 1 with tunable kernel_size\n    x = tf.keras.layers.DepthwiseConv1D(\n        kernel_size=kernel_size,\n        strides=1,\n        padding=\"valid\",\n        activation=\"relu\",\n        depth_multiplier=1,\n        data_format=\"channels_first\",\n        name=\"block1_depthwise_conv1d\"\n    )(input_eeg)\n\n    x = tf.keras.layers.AveragePooling1D(\n        pool_size=4,\n        strides=4,\n        padding=\"valid\",\n        data_format=\"channels_first\",\n        name=\"block1_avg_pooling\"\n    )(x)\n\n    x = tf.keras.layers.BatchNormalization(\n        axis=1,\n        name=\"block1_batch_norm\"\n    )(x)\n\n    # Block 2: TakensConv1D\n    takens = TakensConv1D(dx=dx, dy=dy, tau=tau, mu=mu,\n                          name=\"takens_conv1d\")(x)\n    x_sub, y_minus_1, y_t = takens\n\n    # Dense projections\n    x_sub     = tf.keras.layers.Dense(dx, activation=None,\n                                      use_bias=False,\n                                      name=\"dense_proj_x\")(x_sub)\n    y_minus_1 = tf.keras.layers.Dense(dy, activation=None,\n                                      use_bias=False,\n                                      name=\"dense_proj_y_1\")(y_minus_1)\n    y_t       = tf.keras.layers.Dense(1, activation=None,\n                                      use_bias=False,\n                                      name=\"dense_proj_y\")(y_t)\n\n    # Fixed kernel layers\n    def fixed_kernel(name):\n        layer = KernelLayer(\n            amplitude=1.0, trainable_amplitude=False,\n            length_scale=1.0, trainable_length_scale=False,\n            alpha=1.0, trainable_alpha=False,\n            kernel_type=kernel_type,\n            name=name\n        )\n        layer.trainable = False\n        return layer\n\n    Kx  = fixed_kernel(\"kernel_x\")(x_sub)\n    Ky1 = fixed_kernel(\"kernel_y_minus_1\")(y_minus_1)\n    Ky  = fixed_kernel(\"kernel_y\")(y_t)\n\n    # Transfer Entropy + flattening\n    TE   = TransferEntropyLayer(alpha=2,\n                                name=\"transfer_entropy\")(Kx, Ky1, Ky)\n    flat = RemoveDiagonalFlatten(name=\"remove_diag_flatten\")(TE)\n\n    # Output head\n    h   = tf.keras.layers.Dense(10, activation=\"relu\",\n                                name=\"dense_1\")(flat)\n    out = tf.keras.layers.Dense(1, activation=\"sigmoid\",\n                                name=\"output\")(h)\n\n    model = tf.keras.Model(inputs=input_eeg, outputs=out)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=\"binary_crossentropy\",\n        metrics=[\n            BinaryAccuracy(name=\"accuracy\"),\n            F1Score(name=\"f1_score\"),\n            Recall(name=\"sensitivity\"),\n            Specificity(name=\"specificity\")\n        ]\n    )\n    return model\n\ndef build_model(hp):\n    # Hyperparameters to search\n    dx          = hp.Int(\"dx\",  min_value=1,  max_value=10, step=1)\n    dy          = hp.Int(\"dy\",  min_value=1,  max_value=10, step=1)\n    tau         = hp.Int(\"tau\", min_value=1,  max_value=5,  step=1)\n    mu          = hp.Int(\"mu\",  min_value=0,  max_value=10, step=1)\n    lr          = hp.Choice(\"learning_rate\", [1e-2, 1e-3, 1e-4])\n    kernel_type = \"rational_quadratic\"\n\n    # New: searchable range for kernel_size\n    kernel_size = hp.Int(\n        \"kernel_size\",\n        min_value=3,      # very small windows (3 samples)\n        max_value=125,    # up to ~125 samples (~0.25 s at 500 Hz)\n        step=2            # odd values only\n    )\n\n    # Validate that the Takens embedding window fits after Conv+Pool\n    conv_len = 500 - kernel_size + 1\n    pool_len = (conv_len - 4) // 4 + 1\n    window   = mu + (dx - 1) * tau + 1\n    if window > pool_len:\n        # Invalid trial: return a trivial model to penalize it\n        m = tf.keras.Sequential([\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(1, activation=\"sigmoid\")\n        ])\n        m.compile(\"adam\", \"binary_crossentropy\", [\"accuracy\"])\n        return m\n\n    # Build and return the actual model\n    return create_tunable_model(\n        dx, dy, tau, mu,\n        kernel_type, lr,\n        kernel_size\n    )\n\n# Tuner configuration\ntuner = kt.BayesianOptimization(\n    hypermodel=build_model,\n    objective=kt.Objective(\"val_f1_score\", direction=\"max\"),\n    max_trials=50,\n    executions_per_trial=2,\n    directory=\"tuner_dir5\",\n    project_name=\"takens_te_tuning_5\"\n)\n\nstop_early = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    patience=1\n)\n\n# Start the search\ntuner.search(\n    x=train_data,\n    y=train_labels,\n    validation_data=(val_data, val_labels),\n    epochs=200,\n    callbacks=[stop_early]\n)\n\n# Extract the best result\nbest_hp    = tuner.get_best_hyperparameters(num_trials=1)[0]\nbest_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\nbest_score = best_trial.score  # val_f1_score\n\n# Save to a DataFrame and CSV\nimport pandas as pd\n\nbest_dict = {\n    \"dx\":            best_hp.get(\"dx\"),\n    \"dy\":            best_hp.get(\"dy\"),\n    \"tau\":           best_hp.get(\"tau\"),\n    \"mu\":            best_hp.get(\"mu\"),\n    \"kernel_size\":   best_hp.get(\"kernel_size\"),\n    \"learning_rate\": best_hp.get(\"learning_rate\"),\n    \"val_f1_score\":  best_score\n}\n\ndf_best = pd.DataFrame([best_dict])\nprint(df_best)\ndf_best.to_csv(\"best_hyperparameters_with_score5.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:21:15.862019Z","iopub.execute_input":"2025-06-19T16:21:15.862740Z"}},"outputs":[{"name":"stdout","text":"Trial 32 Complete [00h 01m 01s]\nval_f1_score: 0.6376811265945435\n\nBest val_f1_score So Far: 0.7126436233520508\nTotal elapsed time: 00h 33m 23s\n\nSearch: Running Trial #33\n\nValue             |Best Value So Far |Hyperparameter\n1                 |1                 |dx\n7                 |8                 |dy\n5                 |5                 |tau\n3                 |3                 |mu\n0.01              |0.01              |learning_rate\n103               |65                |kernel_size\n\nEpoch 1/200\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.4640 - f1_score: 0.5111 - loss: 0.6928 - sensitivity: 0.5463 - specificity: 0.3788 - val_accuracy: 0.5000 - val_f1_score: 0.1333 - val_loss: 0.7096 - val_sensitivity: 0.0769 - val_specificity: 0.9231\nEpoch 2/200\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7662 - f1_score: 0.7511 - loss: 0.6653 - sensitivity: 0.6598 - specificity: 0.8961 - val_accuracy: 0.5769 - val_f1_score: 0.5217 - val_loss: 0.6670 - val_sensitivity: 0.4615 - val_specificity: 0.6923\nEpoch 3/200\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8997 - f1_score: 0.9017 - loss: 0.6068 - sensitivity: 0.9465 - specificity: 0.8584 - val_accuracy: 0.6154 - val_f1_score: 0.6667 - val_loss: 0.6675 - val_sensitivity: 0.7692 - val_specificity: 0.4615\nEpoch 1/200\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 1) Retrieve the best HyperParameters and Trial\nbest_hp    = tuner.get_best_hyperparameters(num_trials=1)[0]\nbest_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n\n# 2) Extract the validation score (F1)\nbest_score = best_trial.score  # corresponds to val_f1_score\n\n# 3) Build a DataFrame with all values\nimport pandas as pd\n\nbest_dict = {\n    \"dx\":            best_hp.get(\"dx\"),\n    \"dy\":            best_hp.get(\"dy\"),\n    \"tau\":           best_hp.get(\"tau\"),\n    \"mu\":            best_hp.get(\"mu\"),\n    \"learning_rate\": best_hp.get(\"learning_rate\"),\n    \"val_f1_score\":  best_score\n}\n\ndf_best = pd.DataFrame([best_dict])\nprint(df_best)\n\n# 4) Save to CSV\ndf_best.to_csv(\"best_hyperparameters_with_score5.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1) Iterate over all trials stored in the tuner\nrecords = []\nfor trial in tuner.oracle.trials.values():\n    # Each trial has a HyperParameters object where .values is a dict of {hp_name: value}\n    hp_dict = trial.hyperparameters.values.copy()\n    # Add this trial's score (val_f1_score)\n    hp_dict[\"val_f1_score\"] = trial.score\n    # Optional: identify the trial\n    hp_dict[\"trial_id\"] = trial.trial_id\n    records.append(hp_dict)\n\n# 2) Create the DataFrame\ndf_all = pd.DataFrame(records)\n\n# 3) Sort by the metric in descending order to show the best trials first\ndf_all = df_all.sort_values(\"val_f1_score\", ascending=False).reset_index(drop=True)\n\n# 4) Display and save\nprint(df_all)\ndf_all.to_csv(\"all_trials_hyperparameters5.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T15:46:04.381939Z","iopub.execute_input":"2025-06-19T15:46:04.382558Z","iopub.status.idle":"2025-06-19T15:46:04.420539Z","shell.execute_reply.started":"2025-06-19T15:46:04.382536Z","shell.execute_reply":"2025-06-19T15:46:04.419888Z"}},"outputs":[{"name":"stdout","text":"    dx  dy  tau  mu  learning_rate  val_f1_score trial_id\n0    5   1    4   3         0.0001      0.905983       49\n1    5   1    4   3         0.0001      0.902778       43\n2    5   1    4   2         0.0001      0.893793       37\n3    5   1    4   3         0.0001      0.873016       47\n4    5   2    4   3         0.0001      0.851429       28\n5    5   1    4   3         0.0001      0.841111       44\n6    9   2    2   8         0.0001      0.831351       12\n7    1   9    3   6         0.0001      0.830629       19\n8   10   9    4   5         0.0010      0.828722       01\n9    1   9    3   4         0.0001      0.822511       26\n10   1   9    3   5         0.0001      0.815686       04\n11   5   2    4   4         0.0001      0.812890       08\n12   1   9    3   5         0.0001      0.811111       31\n13   5   1    4   3         0.0001      0.795796       39\n14  10   9    4   5         0.0010      0.786134       33\n15   5   1    3   9         0.0100      0.782407       10\n16   5   1    4   1         0.0001      0.779923       38\n17  10   9    4   5         0.0010      0.771429       24\n18   5   1    4   3         0.0001      0.768018       46\n19   1  10    3   7         0.0001      0.766667       16\n20   1  10    3   5         0.0001      0.766667       25\n21  10   9    4   5         0.0010      0.752688       32\n22  10   8    5   5         0.0001      0.751351       00\n23   1  10    5   1         0.0001      0.747619       05\n24   1   8    4   6         0.0001      0.735222       20\n25  10   9    5   6         0.0010      0.730662       35\n26   1   9    3   5         0.0001      0.727941       34\n27   9   2    2   8         0.0001      0.724747       18\n28   5   2    4   3         0.0001      0.718018       29\n29   5   2    4   4         0.0001      0.712462       30\n30   5   1    4   2         0.0001      0.712462       40\n31   8   2    3   7         0.0001      0.704292       15\n32   3   3    4   4         0.0010      0.702703       03\n33  10   5    4   1         0.0010      0.702703       13\n34   5   1    4   3         0.0001      0.702703       45\n35  10  10    4   5         0.0001      0.702703       36\n36   6   3    2   1         0.0100      0.702703       09\n37   4  10    3   0         0.0100      0.702703       11\n38   2   6    3   6         0.0100      0.702703       07\n39   9   9    2   6         0.0010      0.702703       06\n40   2   9    3   6         0.0001      0.702703       22\n41   7   4    5   9         0.0100      0.684685       14\n42   5   1    4   3         0.0001      0.684685       48\n43   1   9    3   6         0.0001      0.673932       23\n44   5   1    5   2         0.0001      0.666667       41\n45   1   8    2   6         0.0001      0.631944       21\n46   1   9    3   4         0.0001      0.610611       27\n47  10   2    1   9         0.0001      0.538851       17\n48  10   7    2   1         0.0010      0.419935       02\n49   5   1    3   2         0.0001      0.366667       42\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# 1) Get the already-trained model with the best hyperparameters\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# 2) Save it to /kaggle/working\nbest_model.save(\"best_hp_model5.keras\")\n\n\n# Create a dataset instance\ndb = Dataset_2a(\"/kaggle/input/dataset-2a\")\nfs = 250.0\n\n# Load the subject's data in 'evaluation' mode\nX, y = load_BCICIV2a(db, sbj=5, mode=\"evaluation\", fs=fs)\nprint(\"X shape:\", X.shape)\nprint(\"y shape:\", y.shape)\n\nresults = best_model.evaluate(X, y, return_dict=True)\n\nprint(\"Evaluation results:\")\nprint(f\"  Accuracy:     {results['accuracy']:.4f}\")\nprint(f\"  F1 Score:     {results['f1_score']:.4f}\")\nprint(f\"  Loss:         {results['loss']:.4f}\")\nprint(f\"  Sensitivity:  {results['sensitivity']:.4f}\")\nprint(f\"  Specificity:  {results['specificity']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:06:05.991499Z","iopub.execute_input":"2025-06-19T16:06:05.991772Z","iopub.status.idle":"2025-06-19T16:06:22.537001Z","shell.execute_reply.started":"2025-06-19T16:06:05.991753Z","shell.execute_reply":"2025-06-19T16:06:22.536419Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 24 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"tamaño de X: (130, 22, 500)\ntamaño de X: (130,)\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 420ms/step - accuracy: 0.7763 - f1_score: 0.7799 - loss: 0.5086 - sensitivity: 0.8985 - specificity: 0.6774\nResultados evaluación:\n  Accuracy:     0.7846\n  F1 Score:     0.8056\n  Loss:         0.5000\n  Sensitivity:  0.8923\n  Specificity:  0.6769\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Training with Quadratic","metadata":{}},{"cell_type":"code","source":"model = load_model(\"/kaggle/working/best_hp_model5.keras\", compile=True)\n\n# Callbacks\nearly_stopping = EarlyStopping(\n    monitor=\"val_loss\",\n    mode=\"min\",\n    patience=100,\n    restore_best_weights=True,\n    verbose=1\n)\ncsv_logger = CSVLogger(\"continued_training.log\", append=True)\n\n# 3) Load the BCI Competition IV-2a data\ndb = Dataset_2a(\"/kaggle/input/dataset-2a\")\nfs = 250.0\n\n#    – Training split\nX_full, y_full = load_BCICIV2a(db, sbj=5, mode=\"training\", fs=fs)\n#    – Evaluation split (final test)\nX_test, y_test = load_BCICIV2a(db, sbj=5, mode=\"evaluation\", fs=fs)\n\n# 4) Split the training set into train/val (80/20)\ntrain_data, val_data, train_labels, val_labels = train_test_split(\n    X_full, y_full,\n    test_size=0.2,\n    random_state=42,\n    stratify=y_full\n)\n\nprint(f\"Train: {train_data.shape}, {train_labels.shape}\")\nprint(f\"Val:   {val_data.shape}, {val_labels.shape}\")\nprint(f\"Test:  {X_test.shape}, {y_test.shape}\")\n\n# 5) Continue training\nhistory = model.fit(\n    x=train_data,\n    y=train_labels,\n    validation_data=(val_data, val_labels),\n    epochs=1000,\n    callbacks=[early_stopping, csv_logger]\n)\n\n# 6) Evaluate on the evaluation set\nresults = model.evaluate(X_test, y_test, return_dict=True)\nprint(\"Test results:\")\nfor name, value in results.items():\n    print(f\"  {name}: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:09:23.758479Z","iopub.execute_input":"2025-06-19T16:09:23.759051Z","iopub.status.idle":"2025-06-19T16:10:55.464636Z","shell.execute_reply.started":"2025-06-19T16:09:23.759032Z","shell.execute_reply":"2025-06-19T16:10:55.464076Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 24 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"Train: (92, 22, 500), (92,)\nVal:   (24, 22, 500), (24,)\nTest:  (130, 22, 500), (130,)\nEpoch 1/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.9090 - f1_score: 0.9208 - loss: 0.4373 - sensitivity: 0.9724 - specificity: 0.8333 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4484 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 2/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8777 - f1_score: 0.8985 - loss: 0.4493 - sensitivity: 0.9604 - specificity: 0.7700 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4477 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 3/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8808 - f1_score: 0.8963 - loss: 0.4499 - sensitivity: 0.9510 - specificity: 0.7983 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4472 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 4/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9042 - f1_score: 0.9154 - loss: 0.4432 - sensitivity: 0.9800 - specificity: 0.8198 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4468 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 5/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8956 - f1_score: 0.9136 - loss: 0.4350 - sensitivity: 0.9423 - specificity: 0.8277 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4462 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 6/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8651 - f1_score: 0.8721 - loss: 0.4624 - sensitivity: 0.9530 - specificity: 0.7830 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4459 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 7/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8995 - f1_score: 0.9067 - loss: 0.4486 - sensitivity: 0.9558 - specificity: 0.8413 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4454 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 8/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8871 - f1_score: 0.9032 - loss: 0.4360 - sensitivity: 0.9587 - specificity: 0.7996 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4447 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 9/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9034 - f1_score: 0.9147 - loss: 0.4475 - sensitivity: 0.9676 - specificity: 0.8290 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4440 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 10/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9237 - f1_score: 0.9336 - loss: 0.4182 - sensitivity: 0.9661 - specificity: 0.8707 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4432 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 11/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9136 - f1_score: 0.9198 - loss: 0.4317 - sensitivity: 0.9644 - specificity: 0.8601 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4426 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 12/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9424 - f1_score: 0.9493 - loss: 0.4210 - sensitivity: 0.9537 - specificity: 0.9309 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4417 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 13/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8956 - f1_score: 0.9028 - loss: 0.4339 - sensitivity: 0.9482 - specificity: 0.8413 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4411 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 14/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9361 - f1_score: 0.9424 - loss: 0.4200 - sensitivity: 0.9665 - specificity: 0.9026 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4403 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 15/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9244 - f1_score: 0.9255 - loss: 0.4331 - sensitivity: 0.9719 - specificity: 0.8826 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4397 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 16/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9548 - f1_score: 0.9575 - loss: 0.4183 - sensitivity: 0.9371 - specificity: 0.9762 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4390 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 17/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9400 - f1_score: 0.9469 - loss: 0.4210 - sensitivity: 0.9597 - specificity: 0.9159 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4381 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 18/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8916 - f1_score: 0.8990 - loss: 0.4429 - sensitivity: 0.9900 - specificity: 0.8012 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4374 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 19/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9205 - f1_score: 0.9289 - loss: 0.4218 - sensitivity: 0.9390 - specificity: 0.8998 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4364 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 20/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9533 - f1_score: 0.9572 - loss: 0.4118 - sensitivity: 0.9726 - specificity: 0.9310 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4356 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 21/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9385 - f1_score: 0.9475 - loss: 0.4073 - sensitivity: 0.9615 - specificity: 0.9081 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4346 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 22/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9331 - f1_score: 0.9438 - loss: 0.4137 - sensitivity: 0.9569 - specificity: 0.9068 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4336 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 23/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9205 - f1_score: 0.9230 - loss: 0.4170 - sensitivity: 0.9639 - specificity: 0.8804 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4331 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 24/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9361 - f1_score: 0.9416 - loss: 0.4087 - sensitivity: 0.9726 - specificity: 0.8961 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4324 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 25/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9603 - f1_score: 0.9647 - loss: 0.4000 - sensitivity: 0.9599 - specificity: 0.9599 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.4315 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 26/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9322 - f1_score: 0.9341 - loss: 0.4087 - sensitivity: 0.9639 - specificity: 0.9019 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4308 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 27/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9611 - f1_score: 0.9650 - loss: 0.3987 - sensitivity: 0.9665 - specificity: 0.9550 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4299 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 28/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9509 - f1_score: 0.9556 - loss: 0.3921 - sensitivity: 0.9403 - specificity: 0.9679 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4290 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 29/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9509 - f1_score: 0.9544 - loss: 0.4007 - sensitivity: 0.9510 - specificity: 0.9509 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4281 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 30/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9518 - f1_score: 0.9583 - loss: 0.3894 - sensitivity: 0.9832 - specificity: 0.9104 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4272 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 31/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9759 - f1_score: 0.9777 - loss: 0.3959 - sensitivity: 0.9729 - specificity: 0.9795 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4264 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 32/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9276 - f1_score: 0.9337 - loss: 0.3986 - sensitivity: 0.9356 - specificity: 0.9167 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4255 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 33/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9533 - f1_score: 0.9571 - loss: 0.3883 - sensitivity: 0.9661 - specificity: 0.9397 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4247 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 34/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - f1_score: 0.9865 - loss: 0.3869 - sensitivity: 0.9900 - specificity: 0.9795 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4241 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 35/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9509 - f1_score: 0.9558 - loss: 0.3820 - sensitivity: 0.9526 - specificity: 0.9491 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4233 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 36/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9322 - f1_score: 0.9394 - loss: 0.3907 - sensitivity: 0.9587 - specificity: 0.8998 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4225 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 37/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9564 - f1_score: 0.9605 - loss: 0.3866 - sensitivity: 0.9521 - specificity: 0.9605 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4218 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 38/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9400 - f1_score: 0.9457 - loss: 0.3869 - sensitivity: 0.9724 - specificity: 0.9023 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4211 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 39/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9759 - f1_score: 0.9777 - loss: 0.3791 - sensitivity: 0.9661 - specificity: 0.9881 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.4204 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 40/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9587 - f1_score: 0.9620 - loss: 0.3756 - sensitivity: 0.9724 - specificity: 0.9422 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4196 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 41/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9704 - f1_score: 0.9722 - loss: 0.3770 - sensitivity: 0.9800 - specificity: 0.9610 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4189 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 42/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9744 - f1_score: 0.9766 - loss: 0.3673 - sensitivity: 0.9732 - specificity: 0.9762 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4180 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 43/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9720 - f1_score: 0.9741 - loss: 0.3659 - sensitivity: 0.9590 - specificity: 0.9881 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4171 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 44/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9642 - f1_score: 0.9676 - loss: 0.3711 - sensitivity: 0.9532 - specificity: 0.9795 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4161 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 45/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9603 - f1_score: 0.9664 - loss: 0.3611 - sensitivity: 0.9445 - specificity: 0.9881 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4151 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 46/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9338 - f1_score: 0.9374 - loss: 0.3823 - sensitivity: 0.9492 - specificity: 0.9169 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4142 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 47/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9548 - f1_score: 0.9572 - loss: 0.3773 - sensitivity: 0.9800 - specificity: 0.9301 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4135 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 48/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9587 - f1_score: 0.9623 - loss: 0.3671 - sensitivity: 0.9590 - specificity: 0.9589 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4126 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 49/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9681 - f1_score: 0.9699 - loss: 0.3604 - sensitivity: 0.9510 - specificity: 0.9881 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4116 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 50/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9813 - f1_score: 0.9824 - loss: 0.3594 - sensitivity: 0.9824 - specificity: 0.9800 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4106 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 51/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9720 - f1_score: 0.9729 - loss: 0.3727 - sensitivity: 0.9800 - specificity: 0.9656 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4097 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 52/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9798 - f1_score: 0.9812 - loss: 0.3641 - sensitivity: 0.9729 - specificity: 0.9881 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4087 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 53/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9681 - f1_score: 0.9715 - loss: 0.3573 - sensitivity: 0.9606 - specificity: 0.9792 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4075 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 54/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9735 - f1_score: 0.9762 - loss: 0.3644 - sensitivity: 0.9701 - specificity: 0.9798 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4065 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 55/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9564 - f1_score: 0.9620 - loss: 0.3580 - sensitivity: 0.9422 - specificity: 0.9781 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4054 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 56/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9548 - f1_score: 0.9570 - loss: 0.3568 - sensitivity: 0.9363 - specificity: 0.9762 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4043 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 57/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.3587 - sensitivity: 0.9829 - specificity: 0.9795 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4034 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 58/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9837 - f1_score: 0.9848 - loss: 0.3385 - sensitivity: 0.9800 - specificity: 0.9881 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4025 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 59/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9470 - f1_score: 0.9497 - loss: 0.3611 - sensitivity: 0.9497 - specificity: 0.9439 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4016 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 60/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9509 - f1_score: 0.9476 - loss: 0.3730 - sensitivity: 0.9722 - specificity: 0.9368 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.4006 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 61/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9681 - f1_score: 0.9706 - loss: 0.3428 - sensitivity: 0.9590 - specificity: 0.9795 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3997 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 62/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9603 - f1_score: 0.9628 - loss: 0.3463 - sensitivity: 0.9579 - specificity: 0.9631 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3987 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 63/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9626 - f1_score: 0.9648 - loss: 0.3408 - sensitivity: 0.9648 - specificity: 0.9601 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3977 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 64/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9798 - f1_score: 0.9818 - loss: 0.3368 - sensitivity: 0.9834 - specificity: 0.9762 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3967 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 65/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9681 - f1_score: 0.9687 - loss: 0.3408 - sensitivity: 0.9558 - specificity: 0.9800 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3958 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 66/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.3331 - sensitivity: 0.9665 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3949 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 67/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9548 - f1_score: 0.9546 - loss: 0.3498 - sensitivity: 0.9546 - specificity: 0.9542 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3940 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 68/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9774 - f1_score: 0.9779 - loss: 0.3514 - sensitivity: 0.9900 - specificity: 0.9656 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3931 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 69/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9642 - f1_score: 0.9643 - loss: 0.3460 - sensitivity: 0.9644 - specificity: 0.9664 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3922 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 70/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9657 - f1_score: 0.9666 - loss: 0.3359 - sensitivity: 0.9359 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3912 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 71/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9681 - f1_score: 0.9690 - loss: 0.3346 - sensitivity: 0.9722 - specificity: 0.9656 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3903 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 72/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9642 - f1_score: 0.9676 - loss: 0.3281 - sensitivity: 0.9532 - specificity: 0.9795 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3892 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 73/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9657 - f1_score: 0.9688 - loss: 0.3239 - sensitivity: 0.9398 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3882 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 74/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9564 - f1_score: 0.9566 - loss: 0.3290 - sensitivity: 0.9482 - specificity: 0.9653 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3873 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 75/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9813 - f1_score: 0.9824 - loss: 0.3226 - sensitivity: 0.9824 - specificity: 0.9800 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3864 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 76/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9720 - f1_score: 0.9744 - loss: 0.3245 - sensitivity: 0.9595 - specificity: 0.9881 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3854 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 77/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9681 - f1_score: 0.9701 - loss: 0.3202 - sensitivity: 0.9585 - specificity: 0.9800 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3846 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 78/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9735 - f1_score: 0.9742 - loss: 0.3275 - sensitivity: 0.9497 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3836 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 79/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9485 - f1_score: 0.9478 - loss: 0.3331 - sensitivity: 0.9320 - specificity: 0.9651 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3827 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 80/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9813 - f1_score: 0.9826 - loss: 0.3257 - sensitivity: 0.9826 - specificity: 0.9798 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3818 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 81/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.3122 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3811 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 82/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9665 - f1_score: 0.9703 - loss: 0.3120 - sensitivity: 0.9734 - specificity: 0.9570 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3803 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 83/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9759 - f1_score: 0.9777 - loss: 0.3045 - sensitivity: 0.9729 - specificity: 0.9795 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3795 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 84/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9759 - f1_score: 0.9779 - loss: 0.3135 - sensitivity: 0.9665 - specificity: 0.9881 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3787 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 85/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9681 - f1_score: 0.9697 - loss: 0.3074 - sensitivity: 0.9577 - specificity: 0.9800 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3779 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 86/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9774 - f1_score: 0.9781 - loss: 0.3110 - sensitivity: 0.9572 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3772 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 87/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9470 - f1_score: 0.9514 - loss: 0.3191 - sensitivity: 0.9514 - specificity: 0.9417 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3764 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 88/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9735 - f1_score: 0.9761 - loss: 0.3090 - sensitivity: 0.9533 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3756 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 89/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9759 - f1_score: 0.9777 - loss: 0.3026 - sensitivity: 0.9729 - specificity: 0.9795 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3748 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 90/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.2951 - sensitivity: 0.9665 - specificity: 1.0000 - val_accuracy: 0.9583 - val_f1_score: 0.9600 - val_loss: 0.3741 - val_sensitivity: 0.9231 - val_specificity: 1.0000\nEpoch 91/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9564 - f1_score: 0.9577 - loss: 0.3154 - sensitivity: 0.9492 - specificity: 0.9644 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3733 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 92/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.2864 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3725 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 93/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9657 - f1_score: 0.9666 - loss: 0.3036 - sensitivity: 0.9359 - specificity: 1.0000 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3717 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 94/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9774 - f1_score: 0.9786 - loss: 0.2943 - sensitivity: 0.9582 - specificity: 1.0000 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3710 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 95/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9759 - f1_score: 0.9770 - loss: 0.2950 - sensitivity: 0.9722 - specificity: 0.9803 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3703 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 96/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9642 - f1_score: 0.9657 - loss: 0.3081 - sensitivity: 0.9672 - specificity: 0.9610 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3696 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 97/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9735 - f1_score: 0.9762 - loss: 0.2959 - sensitivity: 0.9536 - specificity: 1.0000 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3689 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 98/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.2771 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3681 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 99/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9470 - f1_score: 0.9526 - loss: 0.2928 - sensitivity: 0.9407 - specificity: 0.9589 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3674 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 100/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9603 - f1_score: 0.9651 - loss: 0.2888 - sensitivity: 0.9422 - specificity: 0.9881 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3668 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 101/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9681 - f1_score: 0.9715 - loss: 0.2792 - sensitivity: 0.9606 - specificity: 0.9792 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3662 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 102/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9720 - f1_score: 0.9729 - loss: 0.2883 - sensitivity: 0.9644 - specificity: 0.9803 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3654 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 103/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9509 - f1_score: 0.9528 - loss: 0.3122 - sensitivity: 0.9722 - specificity: 0.9312 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3647 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 104/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9587 - f1_score: 0.9621 - loss: 0.2872 - sensitivity: 0.9597 - specificity: 0.9606 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3641 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 105/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9564 - f1_score: 0.9593 - loss: 0.2790 - sensitivity: 0.9510 - specificity: 0.9628 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3633 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 106/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9720 - f1_score: 0.9724 - loss: 0.2776 - sensitivity: 0.9800 - specificity: 0.9664 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3626 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 107/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9657 - f1_score: 0.9683 - loss: 0.2807 - sensitivity: 0.9390 - specificity: 1.0000 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3620 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 108/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9813 - f1_score: 0.9826 - loss: 0.2748 - sensitivity: 0.9826 - specificity: 0.9798 - val_accuracy: 0.9167 - val_f1_score: 0.9231 - val_loss: 0.3615 - val_sensitivity: 0.9231 - val_specificity: 0.9091\nEpoch 109/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9798 - f1_score: 0.9815 - loss: 0.2686 - sensitivity: 0.9734 - specificity: 0.9881 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3609 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 110/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9681 - f1_score: 0.9715 - loss: 0.2780 - sensitivity: 0.9540 - specificity: 0.9881 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3604 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 111/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9642 - f1_score: 0.9674 - loss: 0.2704 - sensitivity: 0.9526 - specificity: 0.9788 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3598 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 112/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9603 - f1_score: 0.9611 - loss: 0.2870 - sensitivity: 0.9900 - specificity: 0.9323 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3591 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 113/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.2766 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3584 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 114/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9564 - f1_score: 0.9596 - loss: 0.2738 - sensitivity: 0.9514 - specificity: 0.9625 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3577 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 115/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - f1_score: 0.9865 - loss: 0.2658 - sensitivity: 0.9900 - specificity: 0.9795 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3570 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 116/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9774 - f1_score: 0.9739 - loss: 0.3171 - sensitivity: 0.9900 - specificity: 0.9696 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3561 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 117/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9735 - f1_score: 0.9744 - loss: 0.2657 - sensitivity: 0.9824 - specificity: 0.9653 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3555 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 118/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9774 - f1_score: 0.9772 - loss: 0.2682 - sensitivity: 0.9555 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3550 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 119/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9657 - f1_score: 0.9688 - loss: 0.2740 - sensitivity: 0.9398 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3546 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 120/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9657 - f1_score: 0.9670 - loss: 0.2720 - sensitivity: 0.9367 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3541 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 121/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9828 - f1_score: 0.9849 - loss: 0.2621 - sensitivity: 0.9704 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3538 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 122/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9735 - f1_score: 0.9742 - loss: 0.2670 - sensitivity: 0.9498 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3531 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 123/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9837 - f1_score: 0.9848 - loss: 0.2517 - sensitivity: 0.9800 - specificity: 0.9881 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3526 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 124/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.2513 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3519 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 125/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9564 - f1_score: 0.9599 - loss: 0.2636 - sensitivity: 0.9518 - specificity: 0.9622 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3514 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 126/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9735 - f1_score: 0.9739 - loss: 0.2560 - sensitivity: 0.9492 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3507 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 127/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9720 - f1_score: 0.9737 - loss: 0.2570 - sensitivity: 0.9653 - specificity: 0.9798 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3501 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 128/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9681 - f1_score: 0.9700 - loss: 0.2626 - sensitivity: 0.9588 - specificity: 0.9805 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3495 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 129/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9642 - f1_score: 0.9629 - loss: 0.2637 - sensitivity: 0.9644 - specificity: 0.9678 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3488 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 130/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9564 - f1_score: 0.9593 - loss: 0.2543 - sensitivity: 0.9510 - specificity: 0.9628 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3483 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 131/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9813 - f1_score: 0.9824 - loss: 0.2503 - sensitivity: 0.9657 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3478 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 132/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9657 - f1_score: 0.9672 - loss: 0.2462 - sensitivity: 0.9371 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3472 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 133/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9642 - f1_score: 0.9652 - loss: 0.2515 - sensitivity: 0.9492 - specificity: 0.9800 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3466 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 134/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9774 - f1_score: 0.9779 - loss: 0.2440 - sensitivity: 0.9568 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3460 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 135/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9774 - f1_score: 0.9790 - loss: 0.2397 - sensitivity: 0.9590 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3456 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 136/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9774 - f1_score: 0.9766 - loss: 0.2540 - sensitivity: 0.9543 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3449 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 137/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9681 - f1_score: 0.9717 - loss: 0.2330 - sensitivity: 0.9543 - specificity: 0.9881 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3443 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 138/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9657 - f1_score: 0.9688 - loss: 0.2456 - sensitivity: 0.9398 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3437 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 139/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9735 - f1_score: 0.9744 - loss: 0.2336 - sensitivity: 0.9501 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3430 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 140/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9852 - f1_score: 0.9864 - loss: 0.2348 - sensitivity: 0.9732 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3425 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 141/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9813 - f1_score: 0.9822 - loss: 0.2306 - sensitivity: 0.9653 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3419 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 142/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.2255 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3414 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 143/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9774 - f1_score: 0.9782 - loss: 0.2390 - sensitivity: 0.9574 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3407 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 144/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9907 - f1_score: 0.9912 - loss: 0.2416 - sensitivity: 0.9826 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3399 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 145/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9907 - f1_score: 0.9910 - loss: 0.2446 - sensitivity: 0.9822 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3392 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 146/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9642 - f1_score: 0.9701 - loss: 0.2470 - sensitivity: 0.9730 - specificity: 0.9570 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3386 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 147/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9852 - f1_score: 0.9862 - loss: 0.2263 - sensitivity: 0.9729 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3379 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 148/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9774 - f1_score: 0.9787 - loss: 0.2239 - sensitivity: 0.9583 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3372 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 149/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9548 - f1_score: 0.9547 - loss: 0.2327 - sensitivity: 0.9633 - specificity: 0.9476 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3363 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 150/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9704 - f1_score: 0.9737 - loss: 0.2225 - sensitivity: 0.9678 - specificity: 0.9762 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3357 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 151/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9774 - f1_score: 0.9780 - loss: 0.2246 - sensitivity: 0.9570 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3347 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 152/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9603 - f1_score: 0.9663 - loss: 0.2399 - sensitivity: 0.9444 - specificity: 0.9881 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3340 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 153/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9657 - f1_score: 0.9699 - loss: 0.2231 - sensitivity: 0.9419 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3333 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 154/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9603 - f1_score: 0.9592 - loss: 0.2289 - sensitivity: 0.9543 - specificity: 0.9664 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3323 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 155/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9852 - f1_score: 0.9858 - loss: 0.2169 - sensitivity: 0.9722 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3317 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 156/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9735 - f1_score: 0.9755 - loss: 0.2119 - sensitivity: 0.9522 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3312 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 157/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9813 - f1_score: 0.9824 - loss: 0.2148 - sensitivity: 0.9657 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3306 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 158/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9642 - f1_score: 0.9665 - loss: 0.2135 - sensitivity: 0.9653 - specificity: 0.9631 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3300 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 159/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.2217 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3293 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 160/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - f1_score: 0.9860 - loss: 0.2209 - sensitivity: 0.9900 - specificity: 0.9805 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3286 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 161/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9813 - f1_score: 0.9830 - loss: 0.2114 - sensitivity: 0.9668 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3280 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 162/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9735 - f1_score: 0.9734 - loss: 0.2156 - sensitivity: 0.9482 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3274 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 163/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9735 - f1_score: 0.9768 - loss: 0.2188 - sensitivity: 0.9546 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3267 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 164/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9735 - f1_score: 0.9742 - loss: 0.2097 - sensitivity: 0.9497 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3260 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 165/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9681 - f1_score: 0.9656 - loss: 0.2278 - sensitivity: 0.9717 - specificity: 0.9688 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3254 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 166/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - f1_score: 0.9862 - loss: 0.1930 - sensitivity: 0.9729 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3248 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 167/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1924 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3243 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 168/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.1979 - sensitivity: 0.9665 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3237 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 169/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9657 - f1_score: 0.9639 - loss: 0.2107 - sensitivity: 0.9310 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3230 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 170/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - f1_score: 0.9862 - loss: 0.1918 - sensitivity: 0.9729 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3224 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 171/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9564 - f1_score: 0.9593 - loss: 0.2022 - sensitivity: 0.9510 - specificity: 0.9628 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3218 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 172/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9735 - f1_score: 0.9746 - loss: 0.2129 - sensitivity: 0.9505 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3211 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 173/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9735 - f1_score: 0.9762 - loss: 0.1984 - sensitivity: 0.9536 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3205 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 174/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9774 - f1_score: 0.9776 - loss: 0.2082 - sensitivity: 0.9563 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3199 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 175/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9774 - f1_score: 0.9774 - loss: 0.2037 - sensitivity: 0.9560 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3195 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 176/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9774 - f1_score: 0.9795 - loss: 0.1933 - sensitivity: 0.9599 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3190 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 177/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1863 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3187 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 178/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9852 - f1_score: 0.9861 - loss: 0.2040 - sensitivity: 0.9726 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3182 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 179/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9774 - f1_score: 0.9784 - loss: 0.1934 - sensitivity: 0.9577 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3177 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 180/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1973 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3173 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 181/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9859 - loss: 0.2052 - sensitivity: 0.9722 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3170 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 182/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9852 - f1_score: 0.9863 - loss: 0.1775 - sensitivity: 0.9731 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3165 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 183/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9774 - f1_score: 0.9783 - loss: 0.1902 - sensitivity: 0.9576 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3159 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 184/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9798 - f1_score: 0.9808 - loss: 0.1891 - sensitivity: 0.9800 - specificity: 0.9807 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3153 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 185/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9852 - f1_score: 0.9864 - loss: 0.1824 - sensitivity: 0.9732 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3148 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 186/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1817 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3143 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 187/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9828 - f1_score: 0.9843 - loss: 0.1901 - sensitivity: 0.9692 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3140 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 188/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9657 - f1_score: 0.9713 - loss: 0.1862 - sensitivity: 0.9445 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3136 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 189/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1792 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3130 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 190/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9907 - f1_score: 0.9917 - loss: 0.1779 - sensitivity: 0.9836 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3126 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 191/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9798 - f1_score: 0.9814 - loss: 0.1834 - sensitivity: 0.9800 - specificity: 0.9792 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3122 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 192/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9657 - f1_score: 0.9704 - loss: 0.1902 - sensitivity: 0.9427 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3117 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 193/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9774 - f1_score: 0.9785 - loss: 0.1805 - sensitivity: 0.9579 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3112 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 194/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9657 - f1_score: 0.9686 - loss: 0.1801 - sensitivity: 0.9394 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3109 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 195/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9907 - f1_score: 0.9911 - loss: 0.1799 - sensitivity: 0.9824 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3105 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 196/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9852 - f1_score: 0.9861 - loss: 0.1869 - sensitivity: 0.9726 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3103 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 197/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9735 - f1_score: 0.9766 - loss: 0.1753 - sensitivity: 0.9543 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3100 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 198/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1745 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3097 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 199/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9852 - f1_score: 0.9854 - loss: 0.1882 - sensitivity: 0.9714 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3094 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 200/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9735 - f1_score: 0.9768 - loss: 0.1708 - sensitivity: 0.9546 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3093 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 201/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9657 - f1_score: 0.9713 - loss: 0.1787 - sensitivity: 0.9445 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3092 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 202/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1780 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3087 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 203/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9907 - f1_score: 0.9917 - loss: 0.1700 - sensitivity: 0.9836 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3083 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 204/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - f1_score: 0.9863 - loss: 0.1684 - sensitivity: 0.9731 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3079 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 205/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - f1_score: 0.9866 - loss: 0.1554 - sensitivity: 0.9832 - specificity: 0.9881 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3075 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 206/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1603 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3072 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 207/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9907 - f1_score: 0.9913 - loss: 0.1671 - sensitivity: 0.9829 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3066 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 208/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - f1_score: 0.9857 - loss: 0.1623 - sensitivity: 0.9719 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3061 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 209/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9907 - f1_score: 0.9910 - loss: 0.1714 - sensitivity: 0.9822 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3058 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 210/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9830 - loss: 0.1902 - sensitivity: 0.9667 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3055 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 211/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9813 - f1_score: 0.9827 - loss: 0.1644 - sensitivity: 0.9661 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3053 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 212/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - f1_score: 0.9859 - loss: 0.1542 - sensitivity: 0.9724 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3050 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 213/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1722 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3048 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 214/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - f1_score: 0.9950 - loss: 0.1526 - sensitivity: 1.0000 - specificity: 0.9881 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3047 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 215/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - f1_score: 0.9861 - loss: 0.1504 - sensitivity: 0.9726 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3044 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 216/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1652 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3041 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 217/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9852 - f1_score: 0.9858 - loss: 0.1649 - sensitivity: 0.9722 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3038 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 218/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9813 - f1_score: 0.9832 - loss: 0.1549 - sensitivity: 0.9672 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3036 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 219/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1601 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3033 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 220/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.1584 - sensitivity: 0.9665 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3032 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 221/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1562 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3030 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 222/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9841 - loss: 0.1560 - sensitivity: 0.9689 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3030 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 223/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1455 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3030 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 224/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1492 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3027 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 225/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9850 - loss: 0.1459 - sensitivity: 0.9706 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3024 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 226/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9839 - loss: 0.1656 - sensitivity: 0.9685 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3023 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 227/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9828 - f1_score: 0.9852 - loss: 0.1585 - sensitivity: 0.9710 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3021 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 228/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.1502 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3020 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 229/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9828 - f1_score: 0.9839 - loss: 0.1555 - sensitivity: 0.9685 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3018 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 230/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.1470 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3015 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 231/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9907 - f1_score: 0.9911 - loss: 0.1620 - sensitivity: 0.9824 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3012 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 232/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1529 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3011 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 233/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9828 - f1_score: 0.9847 - loss: 0.1614 - sensitivity: 0.9699 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3008 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 234/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9852 - f1_score: 0.9863 - loss: 0.1485 - sensitivity: 0.9731 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3007 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 235/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1353 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3006 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 236/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9657 - f1_score: 0.9656 - loss: 0.1521 - sensitivity: 0.9340 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3002 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 237/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.1473 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3000 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 238/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1359 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2997 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 239/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1385 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2995 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 240/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9907 - f1_score: 0.9916 - loss: 0.1459 - sensitivity: 0.9834 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2993 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 241/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9657 - f1_score: 0.9697 - loss: 0.1494 - sensitivity: 0.9415 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2990 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 242/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9849 - loss: 0.1422 - sensitivity: 0.9704 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2987 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 243/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.1351 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2984 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 244/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9828 - f1_score: 0.9838 - loss: 0.1464 - sensitivity: 0.9682 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2981 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 245/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9828 - f1_score: 0.9833 - loss: 0.1478 - sensitivity: 0.9672 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2977 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 246/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9657 - f1_score: 0.9679 - loss: 0.1472 - sensitivity: 0.9383 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2975 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 247/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9548 - f1_score: 0.9611 - loss: 0.1514 - sensitivity: 0.9437 - specificity: 0.9762 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2974 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 248/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - f1_score: 0.9862 - loss: 0.1360 - sensitivity: 0.9729 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2972 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 249/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9813 - f1_score: 0.9827 - loss: 0.1381 - sensitivity: 0.9661 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2971 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 250/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9828 - f1_score: 0.9839 - loss: 0.1437 - sensitivity: 0.9683 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2969 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 251/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9907 - f1_score: 0.9915 - loss: 0.1281 - sensitivity: 0.9832 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2970 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 252/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9828 - f1_score: 0.9853 - loss: 0.1420 - sensitivity: 0.9712 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2969 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 253/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9657 - f1_score: 0.9686 - loss: 0.1466 - sensitivity: 0.9394 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2968 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 254/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - f1_score: 0.9861 - loss: 0.1261 - sensitivity: 0.9726 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2967 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 255/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9657 - f1_score: 0.9658 - loss: 0.1425 - sensitivity: 0.9345 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2966 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 256/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.1262 - sensitivity: 0.9665 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2968 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 257/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9735 - f1_score: 0.9774 - loss: 0.1428 - sensitivity: 0.9558 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2969 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 258/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1431 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2968 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 259/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9828 - f1_score: 0.9848 - loss: 0.1420 - sensitivity: 0.9701 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2969 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 260/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1433 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2966 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 261/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9828 - f1_score: 0.9853 - loss: 0.1381 - sensitivity: 0.9712 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2966 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 262/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9828 - f1_score: 0.9847 - loss: 0.1315 - sensitivity: 0.9699 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2964 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 263/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1442 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2961 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 264/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9828 - f1_score: 0.9821 - loss: 0.1705 - sensitivity: 1.0000 - specificity: 0.9669 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2959 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 265/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9657 - f1_score: 0.9677 - loss: 0.1339 - sensitivity: 0.9379 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2958 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 266/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9907 - f1_score: 0.9912 - loss: 0.1326 - sensitivity: 0.9826 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2958 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 267/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1171 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2959 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 268/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1355 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2958 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 269/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9735 - f1_score: 0.9751 - loss: 0.1297 - sensitivity: 0.9514 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2959 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 270/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1274 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2960 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 271/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9774 - f1_score: 0.9772 - loss: 0.1238 - sensitivity: 0.9555 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2960 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 272/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.1271 - sensitivity: 0.9665 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2961 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 273/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1208 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2960 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 274/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9907 - f1_score: 0.9913 - loss: 0.1163 - sensitivity: 0.9829 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2960 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 275/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9735 - f1_score: 0.9773 - loss: 0.1346 - sensitivity: 0.9556 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2961 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 276/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1319 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2957 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 277/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1257 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2956 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 278/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1212 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2956 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 279/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9828 - f1_score: 0.9854 - loss: 0.1384 - sensitivity: 0.9713 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2955 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 280/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1195 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2954 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 281/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9852 - loss: 0.1213 - sensitivity: 0.9709 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2952 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 282/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1208 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2952 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 283/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9813 - f1_score: 0.9824 - loss: 0.1228 - sensitivity: 0.9657 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2951 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 284/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1199 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2951 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 285/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - f1_score: 0.9858 - loss: 0.1215 - sensitivity: 0.9722 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2950 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 286/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9828 - f1_score: 0.9849 - loss: 0.1197 - sensitivity: 0.9703 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2951 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 287/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1195 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2950 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 288/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9852 - f1_score: 0.9861 - loss: 0.1185 - sensitivity: 0.9726 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2948 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 289/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1079 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2948 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 290/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1370 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2947 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 291/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1245 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2948 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 292/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9657 - f1_score: 0.9707 - loss: 0.1302 - sensitivity: 0.9434 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2951 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 293/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9828 - f1_score: 0.9846 - loss: 0.1148 - sensitivity: 0.9697 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2951 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 294/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1060 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2953 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 295/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9907 - f1_score: 0.9911 - loss: 0.1318 - sensitivity: 0.9824 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2950 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 296/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1075 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2949 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 297/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9907 - f1_score: 0.9915 - loss: 0.1116 - sensitivity: 0.9832 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2948 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 298/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1154 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2944 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 299/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1154 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2943 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 300/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1200 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2942 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 301/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9907 - f1_score: 0.9915 - loss: 0.1056 - sensitivity: 0.9832 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2943 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 302/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1077 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2941 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 303/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9828 - f1_score: 0.9851 - loss: 0.1070 - sensitivity: 0.9707 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2941 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 304/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1032 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2941 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 305/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9907 - f1_score: 0.9913 - loss: 0.1101 - sensitivity: 0.9829 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2941 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 306/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9828 - f1_score: 0.9848 - loss: 0.1159 - sensitivity: 0.9701 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2942 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 307/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1109 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2940 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 308/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9735 - f1_score: 0.9759 - loss: 0.1030 - sensitivity: 0.9530 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2939 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 309/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1215 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2938 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 310/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9907 - f1_score: 0.9912 - loss: 0.0985 - sensitivity: 0.9826 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2938 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 311/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1126 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2939 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 312/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9907 - f1_score: 0.9918 - loss: 0.1154 - sensitivity: 0.9837 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2942 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 313/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1019 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2942 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 314/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9828 - f1_score: 0.9833 - loss: 0.1082 - sensitivity: 0.9672 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2942 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 315/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1220 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2941 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 316/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9774 - f1_score: 0.9792 - loss: 0.1108 - sensitivity: 0.9593 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2941 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 317/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9828 - f1_score: 0.9846 - loss: 0.1081 - sensitivity: 0.9697 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2940 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 318/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1051 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2941 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 319/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0988 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2943 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 320/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0886 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2945 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 321/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1000 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2945 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 322/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9907 - f1_score: 0.9913 - loss: 0.0943 - sensitivity: 0.9829 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2945 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 323/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1075 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2943 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 324/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9813 - f1_score: 0.9829 - loss: 0.0994 - sensitivity: 0.9665 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2944 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 325/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.1058 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2943 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 326/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9828 - f1_score: 0.9853 - loss: 0.0978 - sensitivity: 0.9711 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2944 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 327/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9828 - f1_score: 0.9849 - loss: 0.1042 - sensitivity: 0.9703 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2945 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 328/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0917 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2945 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 329/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.0964 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2945 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 330/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1029 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2947 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 331/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1073 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2947 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 332/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0955 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2948 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 333/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9907 - f1_score: 0.9912 - loss: 0.0962 - sensitivity: 0.9826 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2950 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 334/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0932 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2952 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 335/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1042 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2955 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 336/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0922 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2958 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 337/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1025 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2960 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 338/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.1014 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2961 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 339/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9828 - f1_score: 0.9854 - loss: 0.1018 - sensitivity: 0.9713 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2963 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 340/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9907 - f1_score: 0.9914 - loss: 0.1013 - sensitivity: 0.9831 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2963 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 341/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0965 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2966 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 342/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9907 - f1_score: 0.9911 - loss: 0.1136 - sensitivity: 0.9824 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2964 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 343/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1031 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2964 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 344/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0966 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2965 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 345/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0913 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2967 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 346/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.0949 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2968 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 347/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1118 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2968 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 348/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0980 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2972 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 349/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0883 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2974 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 350/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1036 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2976 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 351/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.0953 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2977 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 352/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.0990 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2978 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 353/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0982 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2980 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 354/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0968 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2982 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 355/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0929 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2984 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 356/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1035 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2985 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 357/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1216 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2984 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 358/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9946 - f1_score: 0.9949 - loss: 0.0980 - sensitivity: 0.9900 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2982 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 359/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.1007 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2980 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 360/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0893 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2981 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 361/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0972 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2982 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 362/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9891 - f1_score: 0.9898 - loss: 0.0844 - sensitivity: 0.9800 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2981 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 363/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0875 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2982 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 364/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0809 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2981 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 365/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0789 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2983 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 366/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0814 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2981 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 367/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0834 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2978 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 368/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0840 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2978 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 369/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0830 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2978 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 370/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0846 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2980 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 371/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0824 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2980 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 372/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0841 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2980 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 373/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0792 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2983 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 374/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0835 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2982 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 375/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0713 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2983 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 376/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0823 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2983 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 377/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0825 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2984 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 378/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0825 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2985 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 379/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0915 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2991 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 380/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0906 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2992 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 381/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0791 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2994 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 382/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0749 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2997 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 383/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0890 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2997 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 384/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0877 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2997 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 385/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0817 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2997 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 386/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0829 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.2997 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 387/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0851 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3002 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 388/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0825 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3003 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 389/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0760 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3005 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 390/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0757 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3005 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 391/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0850 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3005 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 392/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0798 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3007 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 393/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0732 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3009 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 394/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0791 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3008 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 395/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0747 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3010 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 396/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0640 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3013 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 397/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0851 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3016 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 398/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0840 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3019 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 399/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0691 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3021 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 400/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0669 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3021 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 401/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0685 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3021 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 402/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0796 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3021 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 403/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9907 - f1_score: 0.9913 - loss: 0.0810 - sensitivity: 0.9829 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3023 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 404/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0766 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3024 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 405/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0703 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3026 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 406/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0709 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3028 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 407/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0809 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3027 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 408/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0679 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3026 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 409/1000\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - f1_score: 1.0000 - loss: 0.0671 - sensitivity: 1.0000 - specificity: 1.0000 - val_accuracy: 0.8750 - val_f1_score: 0.8889 - val_loss: 0.3025 - val_sensitivity: 0.9231 - val_specificity: 0.8182\nEpoch 409: early stopping\nRestoring model weights from the end of the best epoch: 309.\n\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 419ms/step - accuracy: 0.9168 - f1_score: 0.9115 - loss: 0.2741 - sensitivity: 0.9080 - specificity: 0.9193\nResultados en test:\n  accuracy: 0.8846\n  f1_score: 0.8855\n  loss: 0.2931\n  sensitivity: 0.8923\n  specificity: 0.8769\n","output_type":"stream"}],"execution_count":18}]}