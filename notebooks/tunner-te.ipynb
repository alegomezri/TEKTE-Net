{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5137200,"sourceType":"datasetVersion","datasetId":2984453}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip show tensorflow tensorflow-probability\n!pip install tensorflow-probability==0.24.0\n!pip install --upgrade keras-tuner\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.databases #Package for database reading.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n!pip install mne #The MNE Package is installed\nFILEID = \"1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\"\n!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O MI_EEG_ClassMeth.zip && rm -rf /tmp/cookies.txt\n!unzip MI_EEG_ClassMeth.zip -y #Package with useful functions for motor imagery classification based in EEG.\n!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n!dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:03:15.652382Z","iopub.execute_input":"2025-06-16T00:03:15.652676Z","iopub.status.idle":"2025-06-16T00:04:12.721508Z","shell.execute_reply.started":"2025-06-16T00:03:15.652656Z","shell.execute_reply":"2025-06-16T00:04:12.720360Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Name: tensorflow\nVersion: 2.18.0\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\nRequired-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n---\nName: tensorflow-probability\nVersion: 0.25.0\nSummary: Probabilistic modeling and statistical inference in TensorFlow\nHome-page: http://github.com/tensorflow/probability\nAuthor: Google LLC\nAuthor-email: no-reply@google.com\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: absl-py, cloudpickle, decorator, dm-tree, gast, numpy, six\nRequired-by: dopamine_rl\nCollecting tensorflow-probability==0.24.0\n  Downloading tensorflow_probability-0.24.0-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.4.0)\nRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.17.0)\nRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (1.26.4)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (4.4.2)\nRequirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (3.1.1)\nRequirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (0.6.0)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.24.0) (0.1.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.13.3->tensorflow-probability==0.24.0) (2.4.1)\nRequirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.24.0) (25.3.0)\nRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability==0.24.0) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.13.3->tensorflow-probability==0.24.0) (2024.2.0)\nDownloading tensorflow_probability-0.24.0-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorflow-probability\n  Attempting uninstall: tensorflow-probability\n    Found existing installation: tensorflow-probability 0.25.0\n    Uninstalling tensorflow-probability-0.25.0:\n      Successfully uninstalled tensorflow-probability-0.25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorflow-probability-0.24.0\nRequirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\nRequirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\nRequirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.4.26)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras->keras-tuner) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras->keras-tuner) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras->keras-tuner) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras->keras-tuner) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras->keras-tuner) (2024.2.0)\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.databases\n  Cloning https://github.com/UN-GCPDS/python-gcpds.databases to /tmp/pip-req-build-wmrp58fj\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.databases /tmp/pip-req-build-wmrp58fj\n  Resolved https://github.com/UN-GCPDS/python-gcpds.databases to commit d174df9958b6638156dcfe03996a6307e631a6a2\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.15.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (3.7.2)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (1.9.0)\nRequirement already satisfied: tables in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (3.10.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (4.67.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (2.2.3)\nRequirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from gcpds-databases==0.2) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown->gcpds-databases==0.2) (2.32.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->gcpds-databases==0.2) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-databases==0.2) (2.4.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (0.4)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-databases==0.2) (1.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gcpds-databases==0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gcpds-databases==0.2) (2025.2)\nRequirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (2.10.2)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (9.0.0)\nRequirement already satisfied: blosc2>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (3.2.1)\nRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from tables->gcpds-databases==0.2) (4.13.2)\nRequirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.9.2)\nRequirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (1.1.0)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=2.3.0->tables->gcpds-databases==0.2) (4.3.8)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->gcpds-databases==0.2) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->gcpds-databases==0.2) (2.6)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne->gcpds-databases==0.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-databases==0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-databases==0.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->gcpds-databases==0.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->gcpds-databases==0.2) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (2025.4.26)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->gcpds-databases==0.2) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->gcpds-databases==0.2) (2024.2.0)\nBuilding wheels for collected packages: gcpds-databases\n  Building wheel for gcpds-databases (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gcpds-databases: filename=gcpds_databases-0.2-py3-none-any.whl size=32972809 sha256=ac525d89b10fca4b6e51e76aa7319d4bdc7083861515139b6c389b4ed854d8c5\n  Stored in directory: /tmp/pip-ephem-wheel-cache-uqhdhi_r/wheels/ae/48/8d/edf617d5fe8f03b17aa26306a04abdfcc605b218d8e6deac83\nSuccessfully built gcpds-databases\nInstalling collected packages: gcpds-databases\nSuccessfully installed gcpds-databases-0.2\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.visualizations.git\n  Cloning https://github.com/UN-GCPDS/python-gcpds.visualizations.git to /tmp/pip-req-build-b83tux7f\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.visualizations.git /tmp/pip-req-build-b83tux7f\n  Resolved https://github.com/UN-GCPDS/python-gcpds.visualizations.git to commit 162dbeac141a7472d3b0bd7f005932241b4663a5\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting python-circos (from gcpds-visualizations==0.6)\n  Downloading python_circos-0.3.0-py3-none-any.whl.metadata (766 bytes)\nRequirement already satisfied: matplotlib>=3.5.3 in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (1.26.4)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from gcpds-visualizations==0.6) (1.9.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.3->gcpds-visualizations==0.6) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->gcpds-visualizations==0.6) (2.4.1)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (0.4)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne->gcpds-visualizations==0.6) (4.67.1)\nCollecting biopython>=1.78 (from python-circos->gcpds-visualizations==0.6)\n  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne->gcpds-visualizations==0.6) (2.32.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.3->gcpds-visualizations==0.6) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne->gcpds-visualizations==0.6) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->gcpds-visualizations==0.6) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->gcpds-visualizations==0.6) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->gcpds-visualizations==0.6) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->gcpds-visualizations==0.6) (2025.4.26)\nDownloading python_circos-0.3.0-py3-none-any.whl (27 kB)\nDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: gcpds-visualizations\n  Building wheel for gcpds-visualizations (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gcpds-visualizations: filename=gcpds_visualizations-0.6-py3-none-any.whl size=12440 sha256=afe45e5513f5f72a88697dbc6aa56eba50911563c97d359117ebca026154d2d4\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ra2rbuiu/wheels/12/e9/11/f7246de13d1d668c154d68fb1260be82dbfbc166301807d756\nSuccessfully built gcpds-visualizations\nInstalling collected packages: biopython, python-circos, gcpds-visualizations\nSuccessfully installed biopython-1.85 gcpds-visualizations-0.6 python-circos-0.3.0\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\nRequirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.7.2)\nRequirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (25.0)\nRequirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\nRequirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.15.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.23->mne) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.8)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.23->mne) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->mne) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.23->mne) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.23->mne) (2024.2.0)\n--2025-06-16 00:03:59--  https://docs.google.com/uc?export=download&confirm=&id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7\nResolving docs.google.com (docs.google.com)... 74.125.69.100, 74.125.69.113, 74.125.69.101, ...\nConnecting to docs.google.com (docs.google.com)|74.125.69.100|:443... connected.\nHTTP request sent, awaiting response... 303 See Other\nLocation: https://drive.usercontent.google.com/download?id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7&export=download [following]\n--2025-06-16 00:03:59--  https://drive.usercontent.google.com/download?id=1lo0MjWLvsyne2CgTA6VZ2HGY9SKxiwZ7&export=download\nResolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.125.132, 2607:f8b0:4001:c2f::84\nConnecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.125.132|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 86900 (85K) [application/octet-stream]\nSaving to: ‘MI_EEG_ClassMeth.zip’\n\nMI_EEG_ClassMeth.zi 100%[===================>]  84.86K  --.-KB/s    in 0.002s  \n\n2025-06-16 00:04:01 (50.9 MB/s) - ‘MI_EEG_ClassMeth.zip’ saved [86900/86900]\n\nArchive:  MI_EEG_ClassMeth.zip\ncaution: filename not matched:  -y\nCollecting git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n  Cloning https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to /tmp/pip-req-build-yf2qib8s\n  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git /tmp/pip-req-build-yf2qib8s\n  Resolved https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to commit 0c791f236d503dac4829adb78cdba759c5843417\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting braindecode==0.7 (from EEG_Tensorflow_models==0.2)\n  Downloading Braindecode-0.7-py3-none-any.whl.metadata (6.8 kB)\nCollecting moabb (from EEG_Tensorflow_models==0.2)\n  Downloading moabb-1.2.0-py3-none-any.whl.metadata (14 kB)\nCollecting tensorflow-addons (from EEG_Tensorflow_models==0.2)\n  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: tensorflow>=2.8 in /usr/local/lib/python3.11/dist-packages (from EEG_Tensorflow_models==0.2) (2.18.0)\nCollecting tf-keras-vis (from EEG_Tensorflow_models==0.2)\n  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (2.2.3)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (1.15.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.7.2)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from braindecode==0.7->EEG_Tensorflow_models==0.2) (3.13.0)\nCollecting skorch (from braindecode==0.7->EEG_Tensorflow_models==0.2)\n  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.8.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.37.1)\nRequirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (6.0.2)\nRequirement already satisfied: coverage<8.0.0,>=7.0.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (7.8.0)\nCollecting edfio<0.5.0,>=0.4.2 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading edfio-0.4.9-py3-none-any.whl.metadata (3.9 kB)\nCollecting edflib-python<2.0.0,>=1.0.6 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\nCollecting memory-profiler<0.62.0,>=0.61.0 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\nCollecting mne-bids>=0.14 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading mne_bids-0.16.0-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (1.8.2)\nCollecting pyriemann<0.8,>=0.7 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading pyriemann-0.7-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: scikit-learn<1.6 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (1.2.2)\nRequirement already satisfied: seaborn<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (0.12.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from moabb->EEG_Tensorflow_models==0.2) (4.67.1)\nCollecting urllib3<2.0.0,>=1.26.15 (from moabb->EEG_Tensorflow_models==0.2)\n  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->EEG_Tensorflow_models==0.2)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (11.1.0)\nRequirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (1.2.18)\nRequirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from tf-keras-vis->EEG_Tensorflow_models==0.2) (2.37.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.14.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.9.0.post0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from memory-profiler<0.62.0,>=0.61.0->moabb->EEG_Tensorflow_models==0.2) (7.0.0)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (4.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (3.1.6)\nRequirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->braindecode==0.7->EEG_Tensorflow_models==0.2) (2025.2)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch<2.0.0,>=1.6.0->moabb->EEG_Tensorflow_models==0.2) (4.3.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pyriemann<0.8,>=0.7->moabb->EEG_Tensorflow_models==0.2) (1.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2025.4.26)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6->moabb->EEG_Tensorflow_models==0.2) (3.6.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.1.3)\nRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch->braindecode==0.7->EEG_Tensorflow_models==0.2) (0.9.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->braindecode==0.7->EEG_Tensorflow_models==0.2) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.8->EEG_Tensorflow_models==0.2) (0.1.2)\nDownloading Braindecode-0.7-py3-none-any.whl (184 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading moabb-1.2.0-py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading edfio-0.4.9-py3-none-any.whl (27 kB)\nDownloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\nDownloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\nDownloading mne_bids-0.16.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyriemann-0.7-py2.py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading skorch-1.1.0-py3-none-any.whl (228 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: EEG_Tensorflow_models\n  Building wheel for EEG_Tensorflow_models (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for EEG_Tensorflow_models: filename=EEG_Tensorflow_models-0.2-py3-none-any.whl size=29287 sha256=7c954cf0fe9dabe8dfca04f45b63c0dca943b6eed2059bceda0a036df65bd997\n  Stored in directory: /tmp/pip-ephem-wheel-cache-uukwlven/wheels/ec/2b/bd/488f6c2631523174d34618ee5e61f72194b1389c81838cfd71\nSuccessfully built EEG_Tensorflow_models\nInstalling collected packages: urllib3, typeguard, memory-profiler, tensorflow-addons, skorch, pyriemann, mne-bids, edflib-python, edfio, tf-keras-vis, moabb, braindecode, EEG_Tensorflow_models\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.4.0\n    Uninstalling urllib3-2.4.0:\n      Successfully uninstalled urllib3-2.4.0\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.4.2\n    Uninstalling typeguard-4.4.2:\n      Successfully uninstalled typeguard-4.4.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\nydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ninflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed EEG_Tensorflow_models-0.2 braindecode-0.7 edfio-0.4.9 edflib-python-1.0.8 memory-profiler-0.61.0 mne-bids-0.16.0 moabb-1.2.0 pyriemann-0.7 skorch-1.1.0 tensorflow-addons-0.23.0 tf-keras-vis-0.8.7 typeguard-2.13.3 urllib3-1.26.20\nMI_EEG_ClassMeth.zip\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport os\nimport itertools\nimport random\nimport pickle\nimport mne\nimport h5py\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport matplotlib.pyplot as plt\nimport keras_tuner as kt\n\n\nfrom gcpds.databases.BCI_Competition_IV import Dataset_2a\nfrom typing import Sequence, Tuple\nfrom scipy.signal import iirnotch, filtfilt, butter, freqz\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import distance\nimport networkx as nx\nfrom tqdm import tqdm\nfrom mne.preprocessing import compute_current_source_density\nfrom mne.channels import make_standard_montage, read_custom_montage\nfrom scipy.signal import butter, filtfilt, resample, iirnotch\nfrom gcpds.visualizations.series import plot_eeg\nfrom scipy.stats import norm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score\nfrom tqdm import tqdm\n\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom gcpds.databases import GIGA_MI_ME\nfrom sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom tensorflow.keras.utils import register_keras_serializable\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import LeavePGroupsOut, StratifiedGroupKFold\nfrom tensorflow.keras.models import Model\nfrom scipy.spatial.distance import cdist\nfrom sklearn.model_selection import GroupKFold\nfrom tensorflow.keras.models import load_model\n\nfrom keras_tuner import Objective\nfrom keras_tuner import HyperModel\nfrom keras.layers import Layer, Activation\nfrom keras_tuner import BayesianOptimization\nfrom keras_tuner.engine.hyperparameters import HyperParameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:04:12.723394Z","iopub.execute_input":"2025-06-16T00:04:12.723763Z","iopub.status.idle":"2025-06-16T00:04:42.973022Z","shell.execute_reply.started":"2025-06-16T00:04:12.723728Z","shell.execute_reply":"2025-06-16T00:04:42.972318Z"}},"outputs":[{"name":"stderr","text":"2025-06-16 00:04:19.336398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750032259.807308      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750032259.931499      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def load_BCICIV2a(db, sbj: int, mode: str, fs: float) -> tuple:\n    \"\"\"\n    Carga los datos EEG para un sujeto específico con preprocesamiento, incluyendo filtrado y laplaciano superficial.\n    Se recorta el tiempo entre los segundos 2 y 4.\n    \n    Args:\n        db (Dataset_2a): Objeto del dataset.\n        sbj (int): Identificador del sujeto (1-9).\n        mode (str): 'training' o 'testing'.\n        fs (float): Frecuencia de muestreo.\n\n    Returns:\n        tuple: Datos EEG preprocesados con laplaciano superficial y recortados en el tiempo (X), etiquetas (y).\n    \"\"\"\n    # Cargar los datos del sujeto\n    db.load_subject(sbj, mode=mode)\n    X, y = db.get_data()  # Datos y etiquetas\n    X = X[:, :-3, :]  # Seleccionar solo los canales EEG (22 canales)\n    X = X * 1e6  # Convertir a microvoltios\n\n    # Aplicar filtro Notch (50 Hz)\n    notch_freq = 50.0\n    q_factor = 30.0\n    b_notch, a_notch = iirnotch(w0=notch_freq, Q=q_factor, fs=fs)\n    X = filtfilt(b_notch, a_notch, X, axis=2)\n\n    # Aplicar filtro pasa banda (0.5 - 100 Hz)\n    lowcut = 0.5\n    highcut = 100.0\n    b_band, a_band = butter(N=4, Wn=[lowcut, highcut], btype='bandpass', fs=fs)\n    X = filtfilt(b_band, a_band, X, axis=2)\n\n    # Recortar los datos entre el segundo 2 y el segundo 4\n    start_sample = int(2 * fs)  # Inicio en el segundo 2\n    end_sample = int(4 * fs)    # Fin en el segundo 4\n    X = X[:, :, start_sample:end_sample]\n\n    # Lista de nombres de los 22 canales EEG (sin EOG)\n    eeg_channel_names = [\n        'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4',\n        'C6', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'P1', 'Pz', 'P2', 'POz'\n    ]\n\n    # Crear información para los canales EEG\n    info = mne.create_info(\n        ch_names=eeg_channel_names,\n        sfreq=fs,  # Usar la frecuencia original\n        ch_types=[\"eeg\"] * len(eeg_channel_names)  # Todos los canales son EEG\n    )\n\n    # Cargar un montaje estándar basado en el sistema 10/20\n    montage = mne.channels.make_standard_montage('standard_1020')\n    info.set_montage(montage)\n\n    # Aplicar el cálculo del laplaciano superficial \n    laplacian_X = []\n    for trial in X:\n        # Crear un objeto RawArray para cada prueba\n        raw = mne.io.RawArray(trial, info)\n        # Calcular el laplaciano superficial\n        raw = mne.preprocessing.compute_current_source_density(raw)\n        # Obtener los datos con el laplaciano aplicado\n        laplacian_X.append(raw.get_data())\n\n    # Reconvertir a un array numpy con la misma forma original\n    X = np.stack(laplacian_X)\n\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:04:42.985389Z","iopub.execute_input":"2025-06-16T00:04:42.985630Z","iopub.status.idle":"2025-06-16T00:04:43.052932Z","shell.execute_reply.started":"2025-06-16T00:04:42.985611Z","shell.execute_reply":"2025-06-16T00:04:43.052118Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_BCICIV2a(db, sbj: int, mode: str, fs: float) -> tuple:\n    \"\"\"\n    Carga los datos EEG para un sujeto específico con preprocesamiento, incluyendo filtrado y laplaciano superficial.\n    Se recorta el tiempo entre los segundos 2 y 4 y solo se incluyen las clases 'mano izquierda' (1) y 'mano derecha' (2).\n    \n    Args:\n        db (Dataset_2a): Objeto del dataset.\n        sbj (int): Identificador del sujeto (1-9).\n        mode (str): 'training' o 'testing'.\n        fs (float): Frecuencia de muestreo.\n\n    Returns:\n        tuple: Datos EEG preprocesados con laplaciano superficial y recortados en el tiempo (X), etiquetas (y).\n    \"\"\"\n    # Cargar los datos del sujeto\n    db.load_subject(sbj, mode=mode)\n    X, y = db.get_data()  # Datos y etiquetas\n    X = X[:, :-3, :]  # Seleccionar solo los canales EEG (22 canales)\n    X = X * 1e6  # Convertir a microvoltios\n\n    # Aplicar filtro Notch (50 Hz)\n    notch_freq = 50.0\n    q_factor = 30.0\n    b_notch, a_notch = iirnotch(w0=notch_freq, Q=q_factor, fs=fs)\n    X = filtfilt(b_notch, a_notch, X, axis=2)\n\n    # Aplicar filtro pasa banda (0.5 - 100 Hz)\n    lowcut = 0.5\n    highcut = 100.0\n    b_band, a_band = butter(N=4, Wn=[lowcut, highcut], btype='bandpass', fs=fs)\n    X = filtfilt(b_band, a_band, X, axis=2)\n\n    # Recortar los datos entre el segundo 2 y el segundo 4\n    start_sample = int(2 * fs)  # Inicio en el segundo 2\n    end_sample = int(4 * fs)    # Fin en el segundo 4\n    X = X[:, :, start_sample:end_sample]\n\n    # Filtrar solo las clases de interés (1: mano izquierda, 2: mano derecha)\n    clases = [0, 1]\n    mask = np.isin(y, clases)\n    X = X[mask]\n    y = y[mask]\n\n    # Lista de nombres de los 22 canales EEG (sin EOG)\n    eeg_channel_names = [\n        'Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4',\n        'C6', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'P1', 'Pz', 'P2', 'POz'\n    ]\n\n    # Crear información para los canales EEG\n    info = mne.create_info(\n        ch_names=eeg_channel_names,\n        sfreq=fs,  # Usar la frecuencia original\n        ch_types=[\"eeg\"] * len(eeg_channel_names)  # Todos los canales son EEG\n    )\n\n    # Cargar un montaje estándar basado en el sistema 10/20\n    montage = mne.channels.make_standard_montage('standard_1020')\n    info.set_montage(montage)\n\n    # Aplicar el cálculo del laplaciano superficial \n    laplacian_X = []\n    for trial in X:\n        # Crear un objeto RawArray para cada prueba\n        raw = mne.io.RawArray(trial, info)\n        # Calcular el laplaciano superficial\n        raw = mne.preprocessing.compute_current_source_density(raw)\n        # Obtener los datos con el laplaciano aplicado\n        laplacian_X.append(raw.get_data())\n\n    # Reconvertir a un array numpy con la misma forma original\n    X = np.stack(laplacian_X)\n\n    return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:04:43.053841Z","iopub.execute_input":"2025-06-16T00:04:43.054115Z","iopub.status.idle":"2025-06-16T00:04:43.082409Z","shell.execute_reply.started":"2025-06-16T00:04:43.054095Z","shell.execute_reply":"2025-06-16T00:04:43.081755Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Crear instancia del dataset\ndb = Dataset_2a('/kaggle/input/dataset-2a')\nfs = 250.0 \n\n# Cargar los datos del sujeto 9 en modo 'training'\nX, y = load_BCICIV2a(db, sbj=2, mode='training', fs=fs)\nprint(f'tamaño de X:', X.shape)\nprint(f'tamaño de X:', y.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:53:05.346358Z","iopub.execute_input":"2025-06-16T00:53:05.347020Z","iopub.status.idle":"2025-06-16T00:53:10.395395Z","shell.execute_reply.started":"2025-06-16T00:53:05.346974Z","shell.execute_reply":"2025-06-16T00:53:10.394658Z"}},"outputs":[{"name":"stdout","text":"tamaño de X: (142, 22, 500)\ntamaño de X: (142,)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"@register_keras_serializable(package=\"CustomLayers\")\nclass TakensConv1D(tf.keras.layers.Layer):\n    def __init__(self, dx=4, dy=3, tau=1, mu=4, **kwargs):\n        super().__init__(**kwargs)\n        self.dx = int(dx)\n        self.dy = int(dy)\n        self.tau = int(tau)\n        self.mu = int(mu)\n        self.num_filters = self.dx + self.dy + 1\n\n    def build(self, input_shape):\n        kernel_size = self.mu + (self.dx - 1) * self.tau + 1\n        kernel_shape = (kernel_size, 1, self.num_filters)\n        kernel = tf.zeros(kernel_shape, dtype=tf.float32)\n\n        offsets_x = self.mu + tf.range(self.dx) * self.tau\n        offsets_y = tf.range(1, self.dy + 1) * self.tau\n        offset_y_t = tf.constant([0], dtype=tf.int32)\n\n        filas_x = tf.range(self.dx)\n        filas_y = self.dx + tf.range(self.dy)\n        fila_y_t = tf.constant([self.dx + self.dy])\n\n        cols_x = filas_x\n        cols_y = filas_y\n        col_y_t = fila_y_t\n\n        idx_x = tf.stack([filas_x, offsets_x, cols_x], axis=1)\n        idx_y = tf.stack([filas_y, offsets_y, cols_y], axis=1)\n        idx_yt = tf.stack([fila_y_t, offset_y_t, col_y_t], axis=1)\n\n        indices_total = tf.concat([idx_x, idx_y, idx_yt], axis=0)\n        updates = tf.ones([tf.shape(indices_total)[0]], dtype=tf.float32)\n\n        sort_order = tf.argsort(indices_total[:, 0])\n        indices_sorted = tf.gather(indices_total, sort_order)\n\n        row_for_scatter = tf.cast(indices_sorted[:, 1], tf.int32)\n        col_for_scatter = tf.cast(indices_sorted[:, 2], tf.int32)\n\n        final_indices = tf.stack([row_for_scatter,\n                                  tf.zeros_like(row_for_scatter),\n                                  col_for_scatter], axis=1)\n\n        kernel = tf.scatter_nd(final_indices, updates, kernel_shape)\n        self.kernel = kernel.numpy()[::-1]\n\n        self.conv1d = tf.keras.layers.Conv1D(\n            filters=self.num_filters,\n            kernel_size=kernel_size,\n            strides=self.tau,\n            padding=\"valid\",\n            use_bias=False\n        )\n        self.conv1d.build((None, input_shape[2], 1))\n        self.conv1d.set_weights([self.kernel])\n        self.conv1d.trainable=False\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs)[0]\n        channels = tf.shape(inputs)[1]\n        time_steps = tf.shape(inputs)[2]\n\n        reshaped = tf.reshape(inputs, (-1, time_steps, 1))\n        conv_output = self.conv1d(reshaped)\n        new_time = tf.shape(conv_output)[1]\n\n        output = tf.reshape(conv_output, \n                            (batch_size, channels, new_time, self.num_filters))\n\n        x_sub_t_minus_mu = output[..., :self.dx]\n        y_sub_t_minus_1 = output[..., self.dx:self.dx + self.dy]\n        y_sub_t = output[..., -1:]\n\n        return x_sub_t_minus_mu, y_sub_t_minus_1, y_sub_t\n       \n\n@register_keras_serializable(package=\"CustomLayers\")\nclass KernelLayer(tf.keras.layers.Layer):\n    def __init__(self, \n                 amplitude=1.0,\n                 trainable_amplitude=False, \n                 length_scale=1.0,\n                 trainable_length_scale=True,\n                 alpha=1.0,  # Solo usado para Rational Quadratic\n                 trainable_alpha=True,\n                 kernel_type=\"gaussian\",  # \"gaussian\" o \"rational_quadratic\"\n                 **kwargs):\n        super(KernelLayer, self).__init__(**kwargs)\n\n        self.init_amplitude = amplitude\n        self.trainable_amplitude = trainable_amplitude\n        self.init_length_scale = length_scale\n        self.trainable_length_scale = trainable_length_scale\n        self.init_alpha = alpha\n        self.trainable_alpha = trainable_alpha\n        self.kernel_type = kernel_type.lower()\n\n    def build(self, input_shape):\n        self.amplitude = self.add_weight(\n            name=\"amplitude\",\n            shape=(),\n            initializer=tf.constant_initializer(self.init_amplitude),\n            trainable=self.trainable_amplitude,\n            dtype=self.dtype\n        )\n\n        self.length_scale = self.add_weight(\n            name=\"length_scale\",\n            shape=(),\n            initializer=tf.constant_initializer(self.init_length_scale),\n            trainable=self.trainable_length_scale,\n            dtype=self.dtype\n        )\n\n        if self.kernel_type == \"rational_quadratic\":\n            self.alpha = self.add_weight(\n                name=\"alpha\",\n                shape=(),\n                initializer=tf.constant_initializer(self.init_alpha),\n                trainable=self.trainable_alpha,\n                dtype=self.dtype\n            )\n\n        super(KernelLayer, self).build(input_shape)\n\n    def call(self, X):\n        if self.kernel_type == \"gaussian\":\n            kernel = tfp.math.psd_kernels.ExponentiatedQuadratic(\n                amplitude=self.amplitude,\n                length_scale=self.length_scale\n            )\n        elif self.kernel_type == \"rational_quadratic\":\n            kernel = tfp.math.psd_kernels.RationalQuadratic(\n                amplitude=self.amplitude,\n                length_scale=self.length_scale,\n                scale_mixture_rate=self.alpha\n            )\n        else:\n            raise ValueError(f\"Unsupported kernel_type: {self.kernel_type}\")\n        \n        return kernel.matrix(X, X)\n       \n@register_keras_serializable(package=\"CustomLayers\")\nclass TransferEntropyLayer(tf.keras.layers.Layer):\n    def __init__(self, alpha=2, **kwargs):\n\n        super().__init__(**kwargs)\n        self.alpha = int(alpha)\n\n    def compute_entropy(self, K_hadamard):\n        \n        trace_hadamard = tf.reduce_sum(tf.linalg.diag_part(K_hadamard), axis=-1) \n        trace_hadamard = tf.expand_dims(tf.expand_dims(trace_hadamard, axis=-1), axis=-1)\n        K_normalized = K_hadamard / trace_hadamard\n\n        K_power = tf.linalg.matmul( K_normalized , K_normalized, grad_a=True, grad_b=True ) \n        trace_power = tf.reduce_sum(tf.linalg.diag_part(K_power), axis=-1)  \n        H_alpha = (1 / (1 - self.alpha)) * tf.math.log(trace_power)\n        return H_alpha\n\n    def call(self, K_x, K_y_minus_1, K_y):\n        \n        K_x_exp = tf.expand_dims(K_x, axis=2)\n        \n        K_y_minus_1_exp = tf.expand_dims(K_y_minus_1, axis=1)\n        K_y_exp = tf.expand_dims(K_y, axis=1)\n\n        \n        H_1 = self.compute_entropy(K_y_minus_1_exp * K_x_exp)\n        H_2 = self.compute_entropy(K_y_exp * K_y_minus_1_exp * K_x_exp)\n        H_3 = self.compute_entropy(K_y_exp * K_y_minus_1_exp)\n        H_4 = self.compute_entropy(K_y_minus_1_exp)\n\n        TE = H_1 - H_2 + H_3 - H_4\n        \n        return TE\n        \n@register_keras_serializable(package=\"CustomLayers\")      \nclass RemoveDiagonalFlatten(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n    \n        super().__init__(**kwargs)\n\n    def call(self, inputs):\n        \n        shape_dyn = tf.shape(inputs)  \n        batch_size = shape_dyn[0]\n        c = tf.shape(inputs)[1]\n\n        \n        tf.debugging.assert_equal(\n            tf.shape(inputs)[1], tf.shape(inputs)[2],\n            message=\"RemoveDiagonalFlatten: la matriz de entrada no es cuadrada.\"\n        )  \n        diag_mask = tf.eye(c, dtype=inputs.dtype)  \n        inputs_no_diag = inputs * (1 - diag_mask) \n        flattened = tf.reshape(inputs_no_diag, [batch_size, -1])  \n        non_diag = tf.boolean_mask(flattened, tf.reshape(1 - diag_mask, [-1]), axis=1)\n        num_features = c * (c - 1)  \n        result = tf.reshape(non_diag, [batch_size, num_features])  \n\n        return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:53:17.845531Z","iopub.execute_input":"2025-06-16T00:53:17.846204Z","iopub.status.idle":"2025-06-16T00:53:17.868017Z","shell.execute_reply.started":"2025-06-16T00:53:17.846182Z","shell.execute_reply":"2025-06-16T00:53:17.867198Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# # Crear el modelo\n# model = create_model()\n# model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T22:24:52.275120Z","iopub.execute_input":"2025-06-12T22:24:52.275331Z","iopub.status.idle":"2025-06-12T22:24:52.672245Z","shell.execute_reply.started":"2025-06-12T22:24:52.275314Z","shell.execute_reply":"2025-06-12T22:24:52.671505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Specificity(tf.keras.metrics.Metric):\n    def __init__(self, name='specificity', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tn = tf.keras.metrics.TrueNegatives()\n        self.fp = tf.keras.metrics.FalsePositives()\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tn.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n    def result(self):\n        return self.tn.result() / (self.tn.result() + self.fp.result() + tf.keras.backend.epsilon())\n    def reset_states(self):\n        self.tn.reset_states()\n        self.fp.reset_states()\n\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.tp = tf.keras.metrics.TruePositives()\n        self.fp = tf.keras.metrics.FalsePositives()\n        self.fn = tf.keras.metrics.FalseNegatives()\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tp.update_state(y_true, y_pred, sample_weight)\n        self.fp.update_state(y_true, y_pred, sample_weight)\n        self.fn.update_state(y_true, y_pred, sample_weight)\n    def result(self):\n        precision = self.tp.result() / (self.tp.result() + self.fp.result() + tf.keras.backend.epsilon())\n        recall    = self.tp.result() / (self.tp.result() + self.fn.result() + tf.keras.backend.epsilon())\n        return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n    def reset_states(self):\n        self.tp.reset_states()\n        self.fp.reset_states()\n        self.fn.reset_states()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:53:22.391587Z","iopub.execute_input":"2025-06-16T00:53:22.391857Z","iopub.status.idle":"2025-06-16T00:53:22.400235Z","shell.execute_reply.started":"2025-06-16T00:53:22.391838Z","shell.execute_reply":"2025-06-16T00:53:22.399419Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def create_model(dx, dy, tau, mu, kernel_type, length_scale, alpha):\n    input_eeg = tf.keras.Input(shape=(22, 500), name='input_eeg')\n    x = tf.keras.layers.DepthwiseConv1D(\n        kernel_size=22,\n        strides=1,\n        padding='valid',\n        activation='relu',\n        depth_multiplier=1,\n        data_format=\"channels_first\",\n        name='block1_depthwise_conv1d'\n    )(input_eeg)\n        \n    \n    x_block1 = tf.keras.layers.AveragePooling1D(\n        pool_size=4, \n        strides=4, \n        padding='valid',\n        data_format=\"channels_first\", \n        name='block1_avg_pooling'\n    )(x)\n\n    # Bloque 2 (Takens)\n    x_m, y_m1, y_t = TakensConv1D(dx=dx, dy=dy, tau=tau, mu=mu)(x_block1)\n    x_m = tf.keras.layers.Dense(dx, activation=None, use_bias=False)(x_m)\n    y_m1 = tf.keras.layers.Dense(dy, activation=None, use_bias=False)(y_m1)\n    y_t = tf.keras.layers.Dense(1, activation=None, use_bias=False)(y_t)\n\n    # KernelLayer con elección de tipo\n    Kx = KernelLayer(kernel_type=kernel_type, length_scale=length_scale, alpha=alpha)(x_m)\n    Ky1 = KernelLayer(kernel_type=kernel_type, length_scale=length_scale, alpha=alpha)(y_m1)\n    Ky  = KernelLayer(kernel_type=kernel_type, length_scale=length_scale, alpha=alpha)(y_t)\n\n    # Transfer Entropy\n    TE = TransferEntropyLayer(alpha=2)(Kx, Ky1, Ky)\n    x_flat = RemoveDiagonalFlatten()(TE)\n\n    # Salida\n    x_dense = tf.keras.layers.Dense(10, activation='relu')(x_flat)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(x_dense)\n\n    model = tf.keras.Model(inputs=input_eeg, outputs=out)\n    model.compile(\n        optimizer='adam',\n        loss='binary_crossentropy',\n        metrics=[\n            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n            tf.keras.metrics.Recall(name='sensitivity'),\n            Specificity(),\n            F1Score()\n        ]\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:53:31.102216Z","iopub.execute_input":"2025-06-16T00:53:31.102471Z","iopub.status.idle":"2025-06-16T00:53:31.110551Z","shell.execute_reply.started":"2025-06-16T00:53:31.102452Z","shell.execute_reply":"2025-06-16T00:53:31.109947Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_data, val_data, train_labels, val_labels = train_test_split(\n    X, y,\n    test_size=0.2,\n    random_state=72,\n    stratify=y\n)\n\ndef build_model(hp):\n    # 1) Lee los HP\n    dx  = hp.Int('dx',  1, 10)\n    dy  = hp.Int('dy',  1, 10)\n    tau = hp.Int('tau', 1, 10)\n    mu  = hp.Int('mu',  0, 10)\n\n    # 2) Calcula el kernel_size que usará TakensConv1D\n    kernel_size = mu + (dx - 1) * tau + 1\n\n    # 3) Longitud temporal disponible tras el Bloque 1\n    T_post_block1 = 109\n\n    # 4) Rechaza combos que no encajen\n    if kernel_size > T_post_block1:\n        return None\n\n\n    # Tipo de kernel\n    kernel_type = hp.Choice('kernel_type', ['gaussian', 'rational_quadratic'])\n\n    # Parámetros continuos\n    length_scale = hp.Choice('length_scale', [10.0, 100.0, 1000.0])\n    alpha        = hp.Float('alpha',         0.1, 2.0, sampling='log') if kernel_type=='rational_quadratic' else 0.5\n\n    # Crear modelo con esos HP\n    return create_model(dx, dy, tau, mu, kernel_type, length_scale, alpha)\n\n# tunner\ntuner = kt.BayesianOptimization(\n    build_model,\n    objective=kt.Objective(\"val_f1_score\", direction=\"max\"),\n    max_trials=30, \n    executions_per_trial=2,\n    directory=\"tuner_dir_2\",\n    project_name=\"takens_te_tuning_2\"\n)\n\n# EarlyStopping por si no mejora la val_loss\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ntuner.search(\n    x=train_data,\n    y=train_labels,\n    validation_data=(val_data, val_labels),\n    epochs=50,\n    callbacks=[stop_early]\n)\n\nbest_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n\n# 2) Obtén el Trial ganador desde el oracle\n#    A) Si tu versión ofrece get_best_trials():\ntry:\n    best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\nexcept AttributeError:\n    # B) Si no existe, usa la propiedad best_trials\n    best_trial = tuner.oracle.best_trials[0]\n\n# 3) Extrae la puntuación de val_f1_score\nbest_score = best_trial.score\n\n# 4) Guarda todo en un DataFrame\nimport pandas as pd\n\nbest_dict = {\n    'dx':            best_hp.get('dx'),\n    'dy':            best_hp.get('dy'),\n    'tau':           best_hp.get('tau'),\n    'mu':            best_hp.get('mu'),\n    'kernel_type':   best_hp.get('kernel_type'),\n    'length_scale':  best_hp.get('length_scale'),\n    'alpha':         best_hp.get('alpha'),\n    'val_f1_score':  best_score\n}\n\ndf_best = pd.DataFrame([best_dict])\nprint(df_best)\ndf_best.to_csv('best_hyperparameters_with_score.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:53:48.652257Z","iopub.execute_input":"2025-06-16T00:53:48.652550Z","iopub.status.idle":"2025-06-16T01:26:01.168715Z","shell.execute_reply.started":"2025-06-16T00:53:48.652531Z","shell.execute_reply":"2025-06-16T01:26:01.167946Z"}},"outputs":[{"name":"stdout","text":"Trial 30 Complete [00h 01m 06s]\nval_f1_score: 0.7128919064998627\n\nBest val_f1_score So Far: 0.7507330477237701\nTotal elapsed time: 00h 32m 12s\n   dx  dy  tau  mu         kernel_type  length_scale     alpha  val_f1_score\n0   6   6    7   5  rational_quadratic        1000.0  0.313391      0.750733\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.gaussian_process.kernels import RBF\nfrom sklearn.gaussian_process import GaussianProcessRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T22:27:09.842404Z","iopub.execute_input":"2025-06-15T22:27:09.842636Z","iopub.status.idle":"2025-06-15T22:27:09.846216Z","shell.execute_reply.started":"2025-06-15T22:27:09.842621Z","shell.execute_reply":"2025-06-15T22:27:09.845522Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# # 1) Recolecta tus trials y best_hp (igual que antes)\n# trials = [t for t in tuner.oracle.trials.values() if getattr(t, \"score\", None) is not None]\n# X = np.array([[t.hyperparameters.get(\"length_scale\"),\n#                t.hyperparameters.get(\"alpha\")]\n#               for t in trials])\n# y = np.array([t.score for t in trials])\n# best_ls, best_alpha = best_hp.get(\"length_scale\"), best_hp.get(\"alpha\")\n\n# # 2) Transforma length_scale a log10\n# X_log = np.column_stack([np.log10(X[:,0]), X[:,1]])\n\n# # 3) Kernel anisotrópico RBF\n# kernel = RBF(length_scale=[1.0, 1.0],  # valores iniciales (se optimizan luego)\n#              length_scale_bounds=[(1e-3, 1e3),  # ℓ en [1e-3,1e3]\n#                                   (0.1, 2.0)])  # α en [0.1,2.0]\n# gp = GaussianProcessRegressor(kernel=kernel,\n#                               normalize_y=False)\n# gp.fit(X_log, y)\n\n# # 4) Crea rejilla muy ajustada (+/–10 %)\n# ls_log_min, ls_log_max = X_log[:,0].min(), X_log[:,0].max()\n# a_min,       a_max     = X_log[:,1].min(), X_log[:,1].max()\n# delta_ls = 0.1*(ls_log_max - ls_log_min)\n# delta_a  = 0.1*(a_max       - a_min)\n\n# grid_ls_log = np.linspace(ls_log_min - delta_ls, ls_log_max + delta_ls, 100)\n# grid_a      = np.linspace(a_min      - delta_a,   a_max      + delta_a, 100)\n# Gx, Gy      = np.meshgrid(grid_ls_log, grid_a)\n# XY_log      = np.vstack([Gx.ravel(), Gy.ravel()]).T\n\n# # 5) Predições\n# mean, std = gp.predict(XY_log, return_std=True)\n# M = mean.reshape(Gx.shape)\n# S = std.reshape(Gx.shape)\n\n# # Niveles\n# levels_m = np.linspace(M.min(), M.max(), 6)\n# levels_s = np.linspace(S.min(), S.max(), 6)\n\n# # 6) Dibuja\n# fig, (ax1, ax2) = plt.subplots(1,2, figsize=(14,6), sharey=True)\n\n# # –– Mean\n# cf1 = ax1.contourf(10**Gx, Gy, M, levels=levels_m, cmap='viridis', extend='both')\n# ax1.contour(10**Gx, Gy, M, levels=levels_m, colors='k', linewidths=0.7)\n# ax1.scatter(10**X_log[:,0], X_log[:,1], c='white', edgecolors='k', s=40, label='Trials')\n# ax1.scatter(best_ls, best_alpha, c='red', marker='X', s=100, label='Best HP')\n# ax1.set_xscale('log'); ax1.set_title('Mean Prediction'); ax1.set_xlabel('length_scale'); ax1.set_ylabel('alpha')\n# ax1.legend()\n# cbar1 = fig.colorbar(cf1, ax=ax1, pad=0.02, label='F1 pred')\n# cbar1.formatter.set_powerlimits((0,0)); cbar1.update_ticks()\n\n# # –– Std. Dev.\n# cf2 = ax2.contourf(10**Gx, Gy, S, levels=levels_s, cmap='viridis', extend='both')\n# ax2.contour(10**Gx, Gy, S, levels=levels_s, colors='k', linewidths=0.7)\n# ax2.scatter(10**X_log[:,0], X_log[:,1], c='white', edgecolors='k', s=40, label='Trials')\n# ax2.scatter(best_ls, best_alpha, c='red', marker='X', s=100, label='Best HP')\n# ax2.set_xscale('log'); ax2.set_title('Uncertainty (Std. Dev.)'); ax2.set_xlabel('length_scale')\n# ax2.legend()\n# cbar2 = fig.colorbar(cf2, ax=ax2, pad=0.02, label='Std. dev.')\n# cbar2.formatter.set_powerlimits((0,0)); cbar2.update_ticks()\n\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T22:35:43.782152Z","iopub.execute_input":"2025-06-15T22:35:43.782517Z","iopub.status.idle":"2025-06-15T22:35:43.787138Z","shell.execute_reply.started":"2025-06-15T22:35:43.782496Z","shell.execute_reply":"2025-06-15T22:35:43.786474Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# 1) Recoge todos los trials completados\ntrials = [\n    t for t in tuner.oracle.trials.values()\n    if getattr(t, \"score\", None) is not None\n]\n\n# 2) Monta un DataFrame con las columnas clave\nrecords = []\nfor t in trials:\n    hp = t.hyperparameters\n    records.append({\n        'dx':            hp.get('dx'),\n        'dy':            hp.get('dy'),\n        'tau':           hp.get('tau'),\n        'mu':            hp.get('mu'),\n        'length_scale':  hp.get('length_scale'),\n        # 'alpha':         hp.get('alpha'),\n        'val_f1_score':  t.score\n    })\n\ndf = pd.DataFrame(records)\n\n# 3) Mira los 10 mejores\ndf_top10 = df.sort_values('val_f1_score', ascending=False).head(10)\nprint(df_top10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T01:38:24.340353Z","iopub.execute_input":"2025-06-16T01:38:24.340976Z","iopub.status.idle":"2025-06-16T01:38:24.351162Z","shell.execute_reply.started":"2025-06-16T01:38:24.340954Z","shell.execute_reply":"2025-06-16T01:38:24.350354Z"}},"outputs":[{"name":"stdout","text":"    dx  dy  tau  mu  length_scale  val_f1_score\n24   6   6    7   5        1000.0      0.750733\n29   6   7    6   5        1000.0      0.712892\n22   4   4    6   6         100.0      0.701351\n0    4   5    1   1          10.0      0.694444\n21   7   9    4   3        1000.0      0.684962\n13   1   6    6   5         100.0      0.684685\n28   6   5    7   6        1000.0      0.678523\n26   6   5    5   4        1000.0      0.676933\n3    6   2    6   3          10.0      0.675522\n11   2   5    4   7        1000.0      0.674797\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"df.to_excel('all_trials.xlsx', index=False)\ndf_top10.to_excel('top10_trials.xlsx', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:49:02.093379Z","iopub.execute_input":"2025-06-16T00:49:02.093616Z","iopub.status.idle":"2025-06-16T00:49:02.709341Z","shell.execute_reply.started":"2025-06-16T00:49:02.093600Z","shell.execute_reply":"2025-06-16T00:49:02.708692Z"}},"outputs":[],"execution_count":13}]}